{"title": "A Roadmap on Explainable AI for Insurance", "abstract": "The use of artificial intelligence in the insurance industry has significantly evolved over the past two decades, driven by the search for predictive performance and automation. With an increasing availability of data, opaque AI models enable insurance companies to differentiate more between customers, raising concerns about fairness and trust. Therefore, transparency in AI-driven insurance models is critical for regulatory compliance and consumer trust. Explainable AI is a research field that can enhance transparency and interpretability around AI model decisions. Moreover, XAI can enhance model robustness, bias detection, and overall model performance. This paper provides a systematic literature review on the application of XAI in insurance, examining its adoption across key subdomains. We categorize XAI methods and identify prevalent techniques such as feature importance, SHAP, and PDP plots. The study benchmarks the extent of XAI implementation in the insurance value chain and highlights XAI applications across subdomains such as pricing and underwriting, risk prediction, claims management and fraud detection. Our findings indicate that while XAI adoption is growing, its application remains limited in certain areas, particularly in fraud detection and loss reserving. Furthermore, XAI applications focused on customers and model-users remain limited. Finally, we show a roadmap by providing recommendations for future research areas, as well as touching upon recent developments such as LLMs. Furthermore, we emphasize the need for hybrid XAI techniques and stakeholder-centric explainability approaches."}