<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;22 of 22 results for author: <span class="mathjax">Marija Slavkovik</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Marija Slavkovik">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Marija+Slavkovik&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Marija Slavkovik">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.18284">arXiv:2507.18284</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.18284">pdf</a>, <a href="https://arxiv.org/ps/2507.18284">ps</a>, <a href="https://arxiv.org/format/2507.18284">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Designing Value-Aligned Traffic Agents through Conflict Sensitivity
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rakow%2C+A">Astrid Rakow</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Collenette%2C+J">Joe Collenette</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schwammberger%2C+M">Maike Schwammberger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alves%2C+G+V">Gleifer Vs Alves</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.18284v1-abstract-short" style="display: inline;">
        Autonomous traffic agents (ATAs) are expected to act in ways tat are not only safe, but also aligned with stakeholder values across legal, social, and moral dimensions. In this paper, we adopt an established formal model of conflict from epistemic game theory to support the development of such agents. We focus on value conflicts-situations in which agents face competing goals rooted in value-laden&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18284v1-abstract-full').style.display = 'inline'; document.getElementById('2507.18284v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.18284v1-abstract-full" style="display: none;">
        Autonomous traffic agents (ATAs) are expected to act in ways tat are not only safe, but also aligned with stakeholder values across legal, social, and moral dimensions. In this paper, we adopt an established formal model of conflict from epistemic game theory to support the development of such agents. We focus on value conflicts-situations in which agents face competing goals rooted in value-laden situations and show how conflict analysis can inform key phases of the design process. This includes value elicitation, capability specification, explanation, and adaptive system refinement. We elaborate and apply the concept of Value-Aligned Operational Design Domains (VODDs) to structure autonomy in accordance with contextual value priorities. Our approach shifts the emphasis from solving moral dilemmas at runtime to anticipating and structuring value-sensitive behaviour during development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18284v1-abstract-full').style.display = 'none'; document.getElementById('2507.18284v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Short version of this paper has been accepted at EUMAS 2025 https://euramas.github.io/eumas2025/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2505.17525">arXiv:2505.17525</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2505.17525">pdf</a>, <a href="https://arxiv.org/ps/2505.17525">ps</a>, <a href="https://arxiv.org/format/2505.17525">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Transparency and Proportionality in Post-Processing Algorithmic Bias Correction
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ferreira%2C+J+S">Juliett Suárez Ferreira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casillas%2C+J">Jorge Casillas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2505.17525v1-abstract-short" style="display: inline;">
        Algorithmic decision-making systems sometimes produce errors or skewed predictions toward a particular group, leading to unfair results. Debiasing practices, applied at different stages of the development of such systems, occasionally introduce new forms of unfairness or exacerbate existing inequalities. We focus on post-processing techniques that modify algorithmic predictions to achieve fairness&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.17525v1-abstract-full').style.display = 'inline'; document.getElementById('2505.17525v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2505.17525v1-abstract-full" style="display: none;">
        Algorithmic decision-making systems sometimes produce errors or skewed predictions toward a particular group, leading to unfair results. Debiasing practices, applied at different stages of the development of such systems, occasionally introduce new forms of unfairness or exacerbate existing inequalities. We focus on post-processing techniques that modify algorithmic predictions to achieve fairness in classification tasks, examining the unintended consequences of these interventions. To address this challenge, we develop a set of measures that quantify the disparity in the flips applied to the solution in the post-processing stage. The proposed measures will help practitioners: (1) assess the proportionality of the debiasing strategy used, (2) have transparency to explain the effects of the strategy in each group, and (3) based on those results, analyze the possibility of the use of some other approaches for bias mitigation or to solve the problem. We introduce a methodology for applying the proposed metrics during the post-processing stage and illustrate its practical application through an example. This example demonstrates how analyzing the proportionality of the debiasing strategy complements traditional fairness metrics, providing a deeper perspective to ensure fairer outcomes across all groups.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.17525v1-abstract-full').style.display = 'none'; document.getElementById('2505.17525v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 May, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.05923">arXiv:2504.05923</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.05923">pdf</a>, <a href="https://arxiv.org/format/2504.05923">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Uncovering Fairness through Data Complexity as an Early Indicator
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ferreira%2C+J+S">Juliett Suárez Ferreira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casillas%2C+J">Jorge Casillas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.05923v1-abstract-short" style="display: inline;">
        Fairness constitutes a concern within machine learning (ML) applications. Currently, there is no study on how disparities in classification complexity between privileged and unprivileged groups could influence the fairness of solutions, which serves as a preliminary indicator of potential unfairness. In this work, we investigate this gap, specifically, we focus on synthetic datasets designed to ca&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05923v1-abstract-full').style.display = 'inline'; document.getElementById('2504.05923v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.05923v1-abstract-full" style="display: none;">
        Fairness constitutes a concern within machine learning (ML) applications. Currently, there is no study on how disparities in classification complexity between privileged and unprivileged groups could influence the fairness of solutions, which serves as a preliminary indicator of potential unfairness. In this work, we investigate this gap, specifically, we focus on synthetic datasets designed to capture a variety of biases ranging from historical bias to measurement and representational bias to evaluate how various complexity metrics differences correlate with group fairness metrics. We then apply association rule mining to identify patterns that link disproportionate complexity differences between groups with fairness-related outcomes, offering data-centric indicators to guide bias mitigation. Our findings are also validated by their application in real-world problems, providing evidence that quantifying group-wise classification complexity can uncover early indicators of potential fairness challenges. This investigation helps practitioners to proactively address bias in classification tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.05923v1-abstract-full').style.display = 'none'; document.getElementById('2504.05923v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.02461">arXiv:2504.02461</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.02461">pdf</a>, <a href="https://arxiv.org/format/2504.02461">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ferreira%2C+J+S">Juliett Suárez Ferreira</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casillas%2C+J">Jorge Casillas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.02461v1-abstract-short" style="display: inline;">
        Current fairness metrics and mitigation techniques provide tools for practitioners to asses how non-discriminatory Automatic Decision Making (ADM) systems are. What if I, as an individual facing a decision taken by an ADM system, would like to know: Am I being treated fairly? We explore how to create the affordance for users to be able to ask this question of ADM. In this paper, we argue for the r&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02461v1-abstract-full').style.display = 'inline'; document.getElementById('2504.02461v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.02461v1-abstract-full" style="display: none;">
        Current fairness metrics and mitigation techniques provide tools for practitioners to asses how non-discriminatory Automatic Decision Making (ADM) systems are. What if I, as an individual facing a decision taken by an ADM system, would like to know: Am I being treated fairly? We explore how to create the affordance for users to be able to ask this question of ADM. In this paper, we argue for the reification of fairness not only as a property of ADM, but also as an epistemic right of an individual to acquire information about the decisions that affect them and use that information to contest and seek effective redress against those decisions, in case they are proven to be discriminatory. We examine key concepts from existing research not only in algorithmic fairness but also in explainable artificial intelligence, accountability, and contestability. Integrating notions from these domains, we propose a conceptual framework to ascertain fairness by combining different tools that empower the end-users of ADM systems. Our framework shifts the focus from technical solutions aimed at practitioners to mechanisms that enable individuals to understand, challenge, and verify the fairness of decisions, and also serves as a blueprint for organizations and policymakers, bridging the gap between technical requirements and practical, user-centered accountability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.02461v1-abstract-full').style.display = 'none'; document.getElementById('2504.02461v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 5 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2; J.4
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.02425">arXiv:2407.02425</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.02425">pdf</a>, <a href="https://arxiv.org/format/2407.02425">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reinforcement Learning and Machine ethics:a systematic review
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vishwanath%2C+A">Ajay Vishwanath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dennis%2C+L+A">Louise A. Dennis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.02425v1-abstract-short" style="display: inline;">
        Machine ethics is the field that studies how ethical behaviour can be accomplished by autonomous systems. While there exist some systematic reviews aiming to consolidate the state of the art in machine ethics prior to 2020, these tend to not include work that uses reinforcement learning agents as entities whose ethical behaviour is to be achieved. The reason for this is that only in the last years&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.02425v1-abstract-full').style.display = 'inline'; document.getElementById('2407.02425v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.02425v1-abstract-full" style="display: none;">
        Machine ethics is the field that studies how ethical behaviour can be accomplished by autonomous systems. While there exist some systematic reviews aiming to consolidate the state of the art in machine ethics prior to 2020, these tend to not include work that uses reinforcement learning agents as entities whose ethical behaviour is to be achieved. The reason for this is that only in the last years we have witnessed an increase in machine ethics studies within reinforcement learning. We present here a systematic review of reinforcement learning for machine ethics and machine ethics within reinforcement learning. Additionally, we highlight trends in terms of ethics specifications, components and frameworks of reinforcement learning, and environments used to result in ethical behaviour. Our systematic review aims to consolidate the work in machine ethics and reinforcement learning thus completing the gap in the state of the art machine ethics landscape
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.02425v1-abstract-full').style.display = 'none'; document.getElementById('2407.02425v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2302.08759">arXiv:2302.08759</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2302.08759">pdf</a>, <a href="https://arxiv.org/format/2302.08759">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Value Engineering for Autonomous Agents
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Montes%2C+N">Nieves Montes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Osman%2C+N">Nardine Osman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sierra%2C+C">Carles Sierra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2302.08759v1-abstract-short" style="display: inline;">
        Machine Ethics (ME) is concerned with the design of Artificial Moral Agents (AMAs), i.e. autonomous agents capable of reasoning and behaving according to moral values. Previous approaches have treated values as labels associated with some actions or states of the world, rather than as integral components of agent reasoning. It is also common to disregard that a value-guided agent operates alongsid&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.08759v1-abstract-full').style.display = 'inline'; document.getElementById('2302.08759v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2302.08759v1-abstract-full" style="display: none;">
        Machine Ethics (ME) is concerned with the design of Artificial Moral Agents (AMAs), i.e. autonomous agents capable of reasoning and behaving according to moral values. Previous approaches have treated values as labels associated with some actions or states of the world, rather than as integral components of agent reasoning. It is also common to disregard that a value-guided agent operates alongside other value-guided agents in an environment governed by norms, thus omitting the social dimension of AMAs. In this blue sky paper, we propose a new AMA paradigm grounded in moral and social psychology, where values are instilled into agents as context-dependent goals. These goals intricately connect values at individual levels to norms at a collective level by evaluating the outcomes most incentivized by the norms in place. We argue that this type of normative reasoning, where agents are endowed with an understanding of norms&#39; moral implications, leads to value-awareness in autonomous agents. Additionally, this capability paves the way for agents to align the norms enforced in their societies with respect to the human values instilled in them, by complementing the value-based reasoning on norms with agreement mechanisms to help agents collectively agree on the best set of norms that suit their human values. Overall, our agent model goes beyond the treatment of values as inert labels by connecting them to normative reasoning and to the social functionalities needed to integrate value-aware agents into our modern hybrid human-computer societies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.08759v1-abstract-full').style.display = 'none'; document.getElementById('2302.08759v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 February, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2301.04993">arXiv:2301.04993</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2301.04993">pdf</a>, <a href="https://arxiv.org/format/2301.04993">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Against Algorithmic Exploitation of Human Vulnerabilities
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Str%C3%BCmke%2C+I">Inga Strümke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stachl%2C+C">Clemens Stachl</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2301.04993v1-abstract-short" style="display: inline;">
        Decisions such as which movie to watch next, which song to listen to, or which product to buy online, are increasingly influenced by recommender systems and user models that incorporate information on users&#39; past behaviours, preferences, and digitally created content. Machine learning models that enable recommendations and that are trained on user data may unintentionally leverage information on h&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.04993v1-abstract-full').style.display = 'inline'; document.getElementById('2301.04993v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2301.04993v1-abstract-full" style="display: none;">
        Decisions such as which movie to watch next, which song to listen to, or which product to buy online, are increasingly influenced by recommender systems and user models that incorporate information on users&#39; past behaviours, preferences, and digitally created content. Machine learning models that enable recommendations and that are trained on user data may unintentionally leverage information on human characteristics that are considered vulnerabilities, such as depression, young age, or gambling addiction. The use of algorithmic decisions based on latent vulnerable state representations could be considered manipulative and could have a deteriorating impact on the condition of vulnerable individuals. In this paper, we are concerned with the problem of machine learning models inadvertently modelling vulnerabilities, and want to raise awareness for this issue to be considered in legislation and AI ethics. Hence, we define and describe common vulnerabilities, and illustrate cases where they are likely to play a role in algorithmic decision-making. We propose a set of requirements for methods to detect the potential for vulnerability modelling, detect whether vulnerable groups are treated differently by a model, and detect whether a model has created an internal representation of vulnerability. We conclude that explainable artificial intelligence methods may be necessary for detecting vulnerability exploitation by machine learning-based recommendation systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.04993v1-abstract-full').style.display = 'none'; document.getElementById('2301.04993v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 January, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: text overlap with arXiv:2203.00317</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2209.06455">arXiv:2209.06455</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2209.06455">pdf</a>, <a href="https://arxiv.org/format/2209.06455">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Finding Common Ground for Incoherent Horn Expressions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ozaki%2C+A">Ana Ozaki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rehman%2C+A">Anum Rehman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Turk%2C+P">Philip Turk</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2209.06455v1-abstract-short" style="display: inline;">
        Autonomous systems that operate in a shared environment with people need to be able to follow the rules of the society they occupy. While laws are unique for one society, different people and institutions may use different rules to guide their conduct. We study the problem of reaching a common ground among possibly incoherent rules of conduct. We formally define a notion of common ground and discu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.06455v1-abstract-full').style.display = 'inline'; document.getElementById('2209.06455v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2209.06455v1-abstract-full" style="display: none;">
        Autonomous systems that operate in a shared environment with people need to be able to follow the rules of the society they occupy. While laws are unique for one society, different people and institutions may use different rules to guide their conduct. We study the problem of reaching a common ground among possibly incoherent rules of conduct. We formally define a notion of common ground and discuss the main properties of this notion. Then, we identify three sufficient conditions on the class of Horn expressions for which common grounds are guaranteed to exist. We provide a polynomial time algorithm that computes common grounds, under these conditions. We also show that if any of the three conditions is removed then common grounds for the resulting (larger) class may not exist.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2209.06455v1-abstract-full').style.display = 'none'; document.getElementById('2209.06455v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 September, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.11836">arXiv:2204.11836</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.11836">pdf</a>, <a href="https://arxiv.org/format/2204.11836">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Automated detection of dark patterns in cookie banners: how to do it poorly and why it is hard to do it any other way
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Soe%2C+T+H">Than Htut Soe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Santos%2C+C+T">Cristiana Teixeira Santos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.11836v1-abstract-short" style="display: inline;">
        Cookie banners, the pop ups that appear to collect your consent for data collection, are a tempting ground for dark patterns. Dark patterns are design elements that are used to influence the user&#39;s choice towards an option that is not in their interest. The use of dark patterns renders consent elicitation meaningless and voids the attempts to improve a fair collection and use of data. Can machine&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.11836v1-abstract-full').style.display = 'inline'; document.getElementById('2204.11836v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.11836v1-abstract-full" style="display: none;">
        Cookie banners, the pop ups that appear to collect your consent for data collection, are a tempting ground for dark patterns. Dark patterns are design elements that are used to influence the user&#39;s choice towards an option that is not in their interest. The use of dark patterns renders consent elicitation meaningless and voids the attempts to improve a fair collection and use of data. Can machine learning be used to automatically detect the presence of dark patterns in cookie banners? In this work, a dataset of cookie banners of 300 news websites was used to train a prediction model that does exactly that. The machine learning pipeline we used includes feature engineering, parameter search, training a Gradient Boosted Tree classifier and evaluation. The accuracy of the trained model is promising, but allows a lot of room for improvement. We provide an in-depth analysis of the interdisciplinary challenges that automated dark pattern detection poses to artificial intelligence. The dataset and all the code created using machine learning is available at the url to repository removed for review.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.11836v1-abstract-full').style.display = 'none'; document.getElementById('2204.11836v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.00317">arXiv:2203.00317</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Explainability for identification of vulnerable groups in machine learning models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Str%C3%BCmke%2C+I">Inga Strümke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.00317v2-abstract-short" style="display: inline;">
        If a prediction model identifies vulnerable individuals or groups, the use of that model may become an ethical issue. But can we know that this is what a model does? Machine learning fairness as a field is focused on the just treatment of individuals and groups under information processing with machine learning methods. While considerable attention has been given to mitigating discrimination of pr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.00317v2-abstract-full').style.display = 'inline'; document.getElementById('2203.00317v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.00317v2-abstract-full" style="display: none;">
        If a prediction model identifies vulnerable individuals or groups, the use of that model may become an ethical issue. But can we know that this is what a model does? Machine learning fairness as a field is focused on the just treatment of individuals and groups under information processing with machine learning methods. While considerable attention has been given to mitigating discrimination of protected groups, vulnerable groups have not received the same attention. Unlike protected groups, which can be regarded as always vulnerable, a vulnerable group may be vulnerable in one context but not in another. This raises new challenges on how and when to protect vulnerable individuals and groups under machine learning. Methods from explainable artificial intelligence (XAI), in contrast, do consider more contextual issues and are concerned with answering the question &#34;why was this decision made?&#34;. Neither existing fairness nor existing explainability methods allow us to ascertain if a prediction model identifies vulnerability. We discuss this problem and propose approaches for analysing prediction models in this respect.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.00317v2-abstract-full').style.display = 'none'; document.getElementById('2203.00317v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 September, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 March, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">The statements about existing methods are outdated and the authors are still working on updating the text</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.12977">arXiv:2107.12977</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.12977">pdf</a>, <a href="https://arxiv.org/format/2107.12977">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s43681-021-00120-w">10.1007/s43681-021-00120-w <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The social dilemma in artificial intelligence development and why we have to solve it
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Str%C3%BCmke%2C+I">Inga Strümke</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Madai%2C+V+I">Vince I. Madai</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.12977v3-abstract-short" style="display: inline;">
        While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for A&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.12977v3-abstract-full').style.display = 'inline'; document.getElementById('2107.12977v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.12977v3-abstract-full" style="display: none;">
        While the demand for ethical artificial intelligence (AI) systems increases, the number of unethical uses of AI accelerates, even though there is no shortage of ethical guidelines. We argue that a possible underlying cause for this is that AI developers face a social dilemma in AI development ethics, preventing the widespread adaptation of ethical best practices. We define the social dilemma for AI development and describe why the current crisis in AI development ethics cannot be solved without relieving AI developers of their social dilemma. We argue that AI development must be professionalised to overcome the social dilemma, and discuss how medicine can be used as a template in this process.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.12977v3-abstract-full').style.display = 'none'; document.getElementById('2107.12977v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 27 July, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2105.02738">arXiv:2105.02738</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2105.02738">pdf</a>, <a href="https://arxiv.org/format/2105.02738">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3461702.3462626">10.1145/3461702.3462626 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Digital Voodoo Dolls
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stachl%2C+C">Clemens Stachl</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pitman%2C+C">Caroline Pitman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Askonas%2C+J">Jonathan Askonas</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2105.02738v2-abstract-short" style="display: inline;">
        An institution, be it a body of government, commercial enterprise, or a service, cannot interact directly with a person. Instead, a model is created to represent us. We argue the existence of a new high-fidelity type of person model which we call a digital voodoo doll. We conceptualize it and compare its features with existing models of persons. Digital voodoo dolls are distinguished by existing c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02738v2-abstract-full').style.display = 'inline'; document.getElementById('2105.02738v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2105.02738v2-abstract-full" style="display: none;">
        An institution, be it a body of government, commercial enterprise, or a service, cannot interact directly with a person. Instead, a model is created to represent us. We argue the existence of a new high-fidelity type of person model which we call a digital voodoo doll. We conceptualize it and compare its features with existing models of persons. Digital voodoo dolls are distinguished by existing completely beyond the influence and control of the person they represent. We discuss the ethical issues that such a lack of accountability creates and argue how these concerns can be mitigated.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2105.02738v2-abstract-full').style.display = 'none'; document.getElementById('2105.02738v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 May, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication at Artificial Intelligence, Ethics and Society (AIES-2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.02785">arXiv:2102.02785</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.02785">pdf</a>, <a href="https://arxiv.org/ps/2102.02785">ps</a>, <a href="https://arxiv.org/format/2102.02785">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Egalitarian Judgment Aggregation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Botan%2C+S">Sirin Botan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Haan%2C+R">Ronald de Haan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Terzopoulou%2C+Z">Zoi Terzopoulou</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.02785v2-abstract-short" style="display: inline;">
        Egalitarian considerations play a central role in many areas of social choice theory. Applications of egalitarian principles range from ensuring everyone gets an equal share of a cake when deciding how to divide it, to guaranteeing balance with respect to gender or ethnicity in committee elections. Yet, the egalitarian approach has received little attention in judgment aggregation -- a powerful fr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.02785v2-abstract-full').style.display = 'inline'; document.getElementById('2102.02785v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.02785v2-abstract-full" style="display: none;">
        Egalitarian considerations play a central role in many areas of social choice theory. Applications of egalitarian principles range from ensuring everyone gets an equal share of a cake when deciding how to divide it, to guaranteeing balance with respect to gender or ethnicity in committee elections. Yet, the egalitarian approach has received little attention in judgment aggregation -- a powerful framework for aggregating logically interconnected issues. We make the first steps towards filling that gap. We introduce axioms capturing two classical interpretations of egalitarianism in judgment aggregation and situate these within the context of existing axioms in the pertinent framework of belief merging. We then explore the relationship between these axioms and several notions of strategyproofness from social choice theory at large. Finally, a novel egalitarian judgment aggregation rule stems from our analysis; we present complexity results concerning both outcome determination and strategic manipulation for that rule.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.02785v2-abstract-full').style.display = 'none'; document.getElementById('2102.02785v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Extended version of paper in proceedings of the 20th International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.13985">arXiv:2006.13985</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.13985">pdf</a>, <a href="https://arxiv.org/format/2006.13985">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Circumvention by design -- dark patterns in cookie consents for online news outlets
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Soe%2C+T+H">Than Htut Soe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nordberg%2C+O+E">Oda Elise Nordberg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guribye%2C+F">Frode Guribye</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.13985v1-abstract-short" style="display: inline;">
        To ensure that users of online services understand what data are collected and how they are used in algorithmic decision-making, the European Union&#39;s General Data Protection Regulation (GDPR) specifies informed consent as a minimal requirement. For online news outlets consent is commonly elicited through interface design elements in the form of a pop-up. We have manually analyzed 300 data collecti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13985v1-abstract-full').style.display = 'inline'; document.getElementById('2006.13985v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.13985v1-abstract-full" style="display: none;">
        To ensure that users of online services understand what data are collected and how they are used in algorithmic decision-making, the European Union&#39;s General Data Protection Regulation (GDPR) specifies informed consent as a minimal requirement. For online news outlets consent is commonly elicited through interface design elements in the form of a pop-up. We have manually analyzed 300 data collection consent notices from news outlets that are built to ensure compliance with GDPR. The analysis uncovered a variety of strategies or dark patterns that circumvent the intent of GDPR by design. We further study the presence and variety of these dark patterns in these &#34;cookie consents&#34; and use our observations to specify the concept of dark pattern in the context of consent elicitation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.13985v1-abstract-full').style.display = 'none'; document.getElementById('2006.13985v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication at NordiCHI 2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1907.09111">arXiv:1907.09111</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1907.09111">pdf</a>, <a href="https://arxiv.org/format/1907.09111">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.4204/EPTCS.297.18">10.4204/EPTCS.297.18 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Aggregating Probabilistic Judgments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ivanovska%2C+M">Magdalena Ivanovska</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1907.09111v1-abstract-short" style="display: inline;">
        In this paper we explore the application of methods for classical judgment aggregation in pooling probabilistic opinions on logically related issues. For this reason, we first modify the Boolean judgment aggregation framework in the way that allows handling probabilistic judgments and then define probabilistic aggregation functions obtained by generalization of the classical ones. In addition, we&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.09111v1-abstract-full').style.display = 'inline'; document.getElementById('1907.09111v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1907.09111v1-abstract-full" style="display: none;">
        In this paper we explore the application of methods for classical judgment aggregation in pooling probabilistic opinions on logically related issues. For this reason, we first modify the Boolean judgment aggregation framework in the way that allows handling probabilistic judgments and then define probabilistic aggregation functions obtained by generalization of the classical ones. In addition, we discuss essential desirable properties for the aggregation functions and explore impossibility results. 
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.09111v1-abstract-full').style.display = 'none'; document.getElementById('1907.09111v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 July, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Proceedings TARK 2019, arXiv:1907.08335</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EPTCS 297, 2019, pp. 273-292
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1812.04741">arXiv:1812.04741</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1812.04741">pdf</a>, <a href="https://arxiv.org/format/1812.04741">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1613/jair.1.14368">10.1613/jair.1.14368 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Jiminy Advisor: Moral Agreements Among Stakeholders Based on Norms and Argumentation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+B">Beishui Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pardo%2C+P">Pere Pardo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=van+der+Torre%2C+L">Leendert van der Torre</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1812.04741v4-abstract-short" style="display: inline;">
        An autonomous system is constructed by a manufacturer, operates in a society subject to norms and laws, and interacts with end users. All of these actors are stakeholders affected by the behavior of the autonomous system. We address the challenge of how the ethical views of such stakeholders can be integrated in the behavior of an autonomous system. We propose an ethical recommendation component c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1812.04741v4-abstract-full').style.display = 'inline'; document.getElementById('1812.04741v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1812.04741v4-abstract-full" style="display: none;">
        An autonomous system is constructed by a manufacturer, operates in a society subject to norms and laws, and interacts with end users. All of these actors are stakeholders affected by the behavior of the autonomous system. We address the challenge of how the ethical views of such stakeholders can be integrated in the behavior of an autonomous system. We propose an ethical recommendation component called Jiminy which uses techniques from normative systems and formal argumentation to reach moral agreements among stakeholders. A Jiminy represents the ethical views of each stakeholder by using normative systems, and has three ways of resolving moral dilemmas that involve the opinions of the stakeholders. First, the Jiminy considers how the arguments of the stakeholders relate to one another, which may already resolve the dilemma. Secondly, the Jiminy combines the normative systems of the stakeholders such that the combined expertise of the stakeholders may resolve the dilemma. Thirdly, and only if these two other methods have failed, the Jiminy uses context-sensitive rules to decide which of the stakeholders take preference over the others. At the abstract level, these three methods are characterized by adding arguments, adding attacks between arguments, and revising attacks between arguments. We show how a Jiminy can be used not only for ethical reasoning and collaborative decision-making, but also to provide explanations about ethical behavior.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1812.04741v4-abstract-full').style.display = 'none'; document.getElementById('1812.04741v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 December, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication with JAIR</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Journal of Artificial Intelligence Research 77: 737 - 792 (2023)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1703.04741">arXiv:1703.04741</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1703.04741">pdf</a>, <a href="https://arxiv.org/format/1703.04741">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Moral Autonomous Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Charisi%2C+V">Vicky Charisi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dennis%2C+L">Louise Dennis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fisher%2C+M">Michael Fisher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lieck%2C+R">Robert Lieck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matthias%2C+A">Andreas Matthias</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sombetzki%2C+J">Janina Sombetzki</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Winfield%2C+A+F+T">Alan F. T. Winfield</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yampolskiy%2C+R">Roman Yampolskiy</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1703.04741v3-abstract-short" style="display: inline;">
        Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.04741v3-abstract-full').style.display = 'inline'; document.getElementById('1703.04741v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1703.04741v3-abstract-full" style="display: none;">
        Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss the main challenges which, in our view, machine ethics posses to moral philosophy. We them consider different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.04741v3-abstract-full').style.display = 'none'; document.getElementById('1703.04741v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 October, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 March, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1607.03307">arXiv:1607.03307</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1607.03307">pdf</a>, <a href="https://arxiv.org/format/1607.03307">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Introductory Course to Judgment Aggregation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1607.03307v1-abstract-short" style="display: inline;">
        Reaching some form of consensus is often necessary for autonomous agents that want to coordinate their actions or otherwise engage in joint activities. One way to reach a consensus is by aggregating individual information, such as decisions, beliefs, preferences and constraints. Judgment aggregation is a social choice method, which generalises voting, that studies the aggregation of individual jud&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.03307v1-abstract-full').style.display = 'inline'; document.getElementById('1607.03307v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1607.03307v1-abstract-full" style="display: none;">
        Reaching some form of consensus is often necessary for autonomous agents that want to coordinate their actions or otherwise engage in joint activities. One way to reach a consensus is by aggregating individual information, such as decisions, beliefs, preferences and constraints. Judgment aggregation is a social choice method, which generalises voting, that studies the aggregation of individual judgments regarding the truth-value of logically related propositions. As such, judgment aggregation is applicable for consensus reaching problems in multi agent systems. As other social choice theory, judgment aggregation research is abundant with impossibility results. However, the aim of this tutorial is to give an introduction to the methods of judgment aggregation, not the impossibility results. In particular, the tutorial will introduce the basic frameworks that model judgment aggregation problems and give an overview of the judgment aggregation functions so far developed as well as their social theoretic and computational complexity properties. The focus of the tutorial are consensus reaching problems in multi agent systems that can be modelled as judgment aggregation problems. The desirable properties of a judgment aggregation method applied to these problems are not necessarily the same as properties desirable in legal or political contexts, which is considered to be the native domain of judgment aggregation. After this tutorial the participants are expected to be able to read and understand judgment aggregation literature and have a grasp on the state-of-the-art and open questions in judgment aggregation research of interest to multi agent systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.03307v1-abstract-full').style.display = 'none'; document.getElementById('1607.03307v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 July, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">These lecture notes accompany the course &#34;An Introduction to Judgment Aggregation for Multi Agent Systems&#34; given at the 18th European Agent Systems Summer School</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1604.06614">arXiv:1604.06614</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1604.06614">pdf</a>, <a href="https://arxiv.org/ps/1604.06614">ps</a>, <a href="https://arxiv.org/format/1604.06614">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Agenda Separability in Judgment Aggregation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lang%2C+J">Jérôme Lang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vesic%2C+S">Srdjan Vesic</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1604.06614v1-abstract-short" style="display: inline;">
        One of the better studied properties for operators in judgment aggregation is independence, which essentially dictates that the collective judgment on one issue should not depend on the individual judgments given on some other issue(s) in the same agenda. Independence, although considered a desirable property, is too strong, because together with mild additional conditions it implies dictatorship.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.06614v1-abstract-full').style.display = 'inline'; document.getElementById('1604.06614v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1604.06614v1-abstract-full" style="display: none;">
        One of the better studied properties for operators in judgment aggregation is independence, which essentially dictates that the collective judgment on one issue should not depend on the individual judgments given on some other issue(s) in the same agenda. Independence, although considered a desirable property, is too strong, because together with mild additional conditions it implies dictatorship. We propose here a weakening of independence, named agenda separability: a judgment aggregation rule satisfies it if, whenever the agenda is composed of several independent sub-agendas, the resulting collective judgment sets can be computed separately for each sub-agenda and then put together. We show that this property is discriminant, in the sense that among judgment aggregation rules so far studied in the literature, some satisfy it and some do not. We briefly discuss the implications of agenda separability on the computation of judgment aggregation rules.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.06614v1-abstract-full').style.display = 'none'; document.getElementById('1604.06614v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 April, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1604.06356">arXiv:1604.06356</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1604.06356">pdf</a>, <a href="https://arxiv.org/ps/1604.06356">ps</a>, <a href="https://arxiv.org/format/1604.06356">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3233/978-1-61499-672-9-1528">10.3233/978-1-61499-672-9-1528 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Iterative Judgment Aggregation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jamroga%2C+W">Wojciech Jamroga</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1604.06356v3-abstract-short" style="display: inline;">
        Judgment aggregation problems form a class of collective decision-making problems represented in an abstract way, subsuming some well known problems such as voting. A collective decision can be reached in many ways, but a direct one-step aggregation of individual decisions is arguably most studied. Another way to reach collective decisions is by iterative consensus building -- allowing each decisi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.06356v3-abstract-full').style.display = 'inline'; document.getElementById('1604.06356v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1604.06356v3-abstract-full" style="display: none;">
        Judgment aggregation problems form a class of collective decision-making problems represented in an abstract way, subsuming some well known problems such as voting. A collective decision can be reached in many ways, but a direct one-step aggregation of individual decisions is arguably most studied. Another way to reach collective decisions is by iterative consensus building -- allowing each decision-maker to change their individual decision in response to the choices of the other agents until a consensus is reached. Iterative consensus building has so far only been studied for voting problems. Here we propose an iterative judgment aggregation algorithm, based on movements in an undirected graph, and we study for which instances it terminates with a consensus. We also compare the computational complexity of our iterative procedure with that of related judgment aggregation operators.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.06356v3-abstract-full').style.display = 'none'; document.getElementById('1604.06356v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 July, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 April, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1502.05888">arXiv:1502.05888</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1502.05888">pdf</a>, <a href="https://arxiv.org/ps/1502.05888">ps</a>, <a href="https://arxiv.org/format/1502.05888">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s00355-016-1006-8">10.1007/s00355-016-1006-8 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A partial taxonomy of judgment aggregation rules, and their properties
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lang%2C+J">Jerôme Lang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pigozzi%2C+G">Gabriella Pigozzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=van+der+Torre%2C+L">Leendert van der Torre</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vesic%2C+S">Srdjan Vesic</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1502.05888v3-abstract-short" style="display: inline;">
        The literature on judgment aggregation is moving from studying impossibility results regarding aggregation rules towards studying specific judgment aggregation rules. Here we give a structured list of most rules that have been proposed and studied recently in the literature, together with various properties of such rules. We first focus on the majority-preservation property, which generalizes Cond&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1502.05888v3-abstract-full').style.display = 'inline'; document.getElementById('1502.05888v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1502.05888v3-abstract-full" style="display: none;">
        The literature on judgment aggregation is moving from studying impossibility results regarding aggregation rules towards studying specific judgment aggregation rules. Here we give a structured list of most rules that have been proposed and studied recently in the literature, together with various properties of such rules. We first focus on the majority-preservation property, which generalizes Condorcet-consistency, and identify which of the rules satisfy it. We study the inclusion relationships that hold between the rules. Finally, we consider two forms of unanimity, monotonicity, homogeneity, and reinforcement, and we identify which of the rules satisfy these properties.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1502.05888v3-abstract-full').style.display = 'none'; document.getElementById('1502.05888v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 September, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 February, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2015.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1408.1592">arXiv:1408.1592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1408.1592">pdf</a>, <a href="https://arxiv.org/ps/1408.1592">ps</a>, <a href="https://arxiv.org/format/1408.1592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/s10619-014-7161-y">10.1007/s10619-014-7161-y <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An Abstract Formal Basis for Digital Crowds
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Slavkovik%2C+M">Marija Slavkovik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dennis%2C+L+A">Louise A. Dennis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fisher%2C+M">Michael Fisher</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1408.1592v1-abstract-short" style="display: inline;">
        Crowdsourcing, together with its related approaches, has become very popular in recent years. All crowdsourcing processes involve the participation of a digital crowd, a large number of people that access a single Internet platform or shared service. In this paper we explore the possibility of applying formal methods, typically used for the verification of software and hardware systems, in analysi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1408.1592v1-abstract-full').style.display = 'inline'; document.getElementById('1408.1592v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1408.1592v1-abstract-full" style="display: none;">
        Crowdsourcing, together with its related approaches, has become very popular in recent years. All crowdsourcing processes involve the participation of a digital crowd, a large number of people that access a single Internet platform or shared service. In this paper we explore the possibility of applying formal methods, typically used for the verification of software and hardware systems, in analysing the behaviour of a digital crowd. More precisely, we provide a formal description language for specifying digital crowds. We represent digital crowds in which the agents do not directly communicate with each other. We further show how this specification can provide the basis for sophisticated formal methods, in particular formal verification.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1408.1592v1-abstract-full').style.display = 'none'; document.getElementById('1408.1592v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2014; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">32 pages, 4 figures</span>
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>