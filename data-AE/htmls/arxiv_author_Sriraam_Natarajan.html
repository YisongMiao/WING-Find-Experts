<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;47 of 47 results for author: <span class="mathjax">Sriraam Natarajan</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Sriraam Natarajan">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Sriraam+Natarajan&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Sriraam Natarajan">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2509.02007">arXiv:2509.02007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2509.02007">pdf</a>, <a href="https://arxiv.org/ps/2509.02007">ps</a>, <a href="https://arxiv.org/format/2509.02007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Adappanavar%2C+S">Shreyash Adappanavar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shailya%2C+K">Krithi Shailya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krishnan%2C+G+S">Gokul S Krishnan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ravindran%2C+B">Balaraman Ravindran</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2509.02007v1-abstract-short" style="display: inline;">
        The deployment of Large Language Models (LLMs) in high-stakes medical settings poses a critical AI alignment challenge, as models can inherit and amplify societal biases, leading to significant disparities. Existing fairness evaluation methods fall short in these contexts as they typically use simplistic metrics that overlook the multi-dimensional nature of medical harms. This also promotes models&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.02007v1-abstract-full').style.display = 'inline'; document.getElementById('2509.02007v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2509.02007v1-abstract-full" style="display: none;">
        The deployment of Large Language Models (LLMs) in high-stakes medical settings poses a critical AI alignment challenge, as models can inherit and amplify societal biases, leading to significant disparities. Existing fairness evaluation methods fall short in these contexts as they typically use simplistic metrics that overlook the multi-dimensional nature of medical harms. This also promotes models that are fair only because they are clinically inert, defaulting to safe but potentially inaccurate outputs. To address this gap, our contributions are mainly two-fold: first, we construct two large-scale, controlled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from MIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and three context tiers. Second, we propose a multi-metric framework - Multi-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness for three distinct dimensions of disparity (Allocational, Stability, and Latent) and aggregate them into an $mFARM$ score. We also present an aggregated Fairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs between fairness and prediction accuracy. We empirically evaluate four open-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and their finetuned versions under quantization and context variations. Our findings showcase that the proposed $mFARM$ metrics capture subtle biases more effectively under various settings. We find that most models maintain robust performance in terms of $mFARM$ score across varying levels of quantization but deteriorate significantly when the context is reduced. Our benchmarks and evaluation code are publicly released to enhance research in aligned AI for healthcare.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.02007v1-abstract-full').style.display = 'none'; document.getElementById('2509.02007v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 September, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.05537">arXiv:2508.05537</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.05537">pdf</a>, <a href="https://arxiv.org/ps/2508.05537">ps</a>, <a href="https://arxiv.org/format/2508.05537">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tractable Sharpness-Aware Learning of Probabilistic Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Suresh%2C+H">Hrithik Suresh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=P%2C+V+S+M">Vishnu Shreeram M. P</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krishnan%2C+N+C">Narayanan C. Krishnan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.05537v1-abstract-short" style="display: inline;">
        Probabilistic Circuits (PCs) are a class of generative models that allow exact and tractable inference for a wide range of queries. While recent developments have enabled the learning of deep and expressive PCs, this increased capacity can often lead to overfitting, especially when data is limited. We analyze PC overfitting from a log-likelihood-landscape perspective and show that it is often caus&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05537v1-abstract-full').style.display = 'inline'; document.getElementById('2508.05537v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.05537v1-abstract-full" style="display: none;">
        Probabilistic Circuits (PCs) are a class of generative models that allow exact and tractable inference for a wide range of queries. While recent developments have enabled the learning of deep and expressive PCs, this increased capacity can often lead to overfitting, especially when data is limited. We analyze PC overfitting from a log-likelihood-landscape perspective and show that it is often caused by convergence to sharp optima that generalize poorly. Inspired by sharpness aware minimization in neural networks, we propose a Hessian-based regularizer for training PCs. As a key contribution, we show that the trace of the Hessian of the log-likelihood-a sharpness proxy that is typically intractable in deep neural networks-can be computed efficiently for PCs. Minimizing this Hessian trace induces a gradient-norm-based regularizer that yields simple closed-form parameter updates for EM, and integrates seamlessly with gradient based learning methods. Experiments on synthetic and real-world datasets demonstrate that our method consistently guides PCs toward flatter minima, improves generalization performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05537v1-abstract-full').style.display = 'none'; document.getElementById('2508.05537v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.04385">arXiv:2507.04385</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.04385">pdf</a>, <a href="https://arxiv.org/ps/2507.04385">ps</a>, <a href="https://arxiv.org/format/2507.04385">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tractable Representation Learning with Probabilistic Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Braun%2C+S">Steven Braun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vergari%2C+A">Antonio Vergari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mundt%2C+M">Martin Mundt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.04385v2-abstract-short" style="display: inline;">
        Probabilistic circuits (PCs) are powerful probabilistic models that enable exact and tractable inference, making them highly suitable for probabilistic reasoning and inference tasks. While dominant in neural networks, representation learning with PCs remains underexplored, with prior approaches relying on external neural embeddings or activation-based encodings. To address this gap, we introduce a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.04385v2-abstract-full').style.display = 'inline'; document.getElementById('2507.04385v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.04385v2-abstract-full" style="display: none;">
        Probabilistic circuits (PCs) are powerful probabilistic models that enable exact and tractable inference, making them highly suitable for probabilistic reasoning and inference tasks. While dominant in neural networks, representation learning with PCs remains underexplored, with prior approaches relying on external neural embeddings or activation-based encodings. To address this gap, we introduce autoencoding probabilistic circuits (APCs), a novel framework leveraging the tractability of PCs to model probabilistic embeddings explicitly. APCs extend PCs by jointly modeling data and embeddings, obtaining embedding representations through tractable probabilistic inference. The PC encoder allows the framework to natively handle arbitrary missing data and is seamlessly integrated with a neural decoder in a hybrid, end-to-end trainable architecture enabled by differentiable sampling. Our empirical evaluation demonstrates that APCs outperform existing PC-based autoencoding methods in reconstruction quality, generate embeddings competitive with, and exhibit superior robustness in handling missing data compared to neural autoencoders. These results highlight APCs as a powerful and flexible representation learning method that exploits the probabilistic inference capabilities of PCs, showing promising directions for robust inference, out-of-distribution detection, and knowledge distillation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.04385v2-abstract-full').style.display = 'none'; document.getElementById('2507.04385v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 July, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2506.12103">arXiv:2506.12103</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2506.12103">pdf</a>, <a href="https://arxiv.org/format/2506.12103">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Amazon Nova Family of Models: Technical Report and Model Card
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=AGI%2C+A">Amazon AGI</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Langford%2C+A">Aaron Langford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+A">Aayush Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+A">Abhanshu Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhatter%2C+A">Abhimanyu Bhatter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Goyal%2C+A">Abhinav Goyal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mathur%2C+A">Abhinav Mathur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mohanty%2C+A">Abhinav Mohanty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+A">Abhishek Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sethi%2C+A">Abhishek Sethi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Komma%2C+A">Abi Komma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pena%2C+A">Abner Pena</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jain%2C+A">Achin Jain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunysz%2C+A">Adam Kunysz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Opyrchal%2C+A">Adam Opyrchal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+A">Adarsh Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rawal%2C+A">Aditya Rawal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prasad%2C+A+A+B">Adok Achar Budihal Prasad</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Gispert%2C+A">Adrià de Gispert</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+A">Agnika Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aryamane%2C+A">Aishwarya Aryamane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nair%2C+A">Ajay Nair</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%2C+A">Akilan M</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iyengar%2C+A">Akshaya Iyengar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shanbhogue%2C+A+V+K">Akshaya Vishnu Kudlu Shanbhogue</a>
      , et al. (761 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2506.12103v1-abstract-short" style="display: inline;">
        We present Amazon Nova, a new generation of state-of-the-art foundation models that deliver frontier intelligence and industry-leading price performance. Amazon Nova Pro is a highly-capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks. Amazon Nova Lite is a low-cost multimodal model that is lightning fast for processing images, video, documents&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2506.12103v1-abstract-full').style.display = 'inline'; document.getElementById('2506.12103v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2506.12103v1-abstract-full" style="display: none;">
        We present Amazon Nova, a new generation of state-of-the-art foundation models that deliver frontier intelligence and industry-leading price performance. Amazon Nova Pro is a highly-capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks. Amazon Nova Lite is a low-cost multimodal model that is lightning fast for processing images, video, documents and text. Amazon Nova Micro is a text-only model that delivers our lowest-latency responses at very low cost. Amazon Nova Canvas is an image generation model that creates professional grade images with rich customization controls. Amazon Nova Reel is a video generation model offering high-quality outputs, customization, and motion control. Our models were built responsibly and with a commitment to customer trust, security, and reliability. We report benchmarking results for core capabilities, agentic performance, long context, functional adaptation, runtime performance, and human evaluation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2506.12103v1-abstract-full').style.display = 'none'; document.getElementById('2506.12103v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">48 pages, 10 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        
          <span class="has-text-black-bis has-text-weight-semibold">Report number:</span>
          20250317
        

        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.19297">arXiv:2502.19297</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.19297">pdf</a>, <a href="https://arxiv.org/format/2502.19297">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Prabhakar%2C+N">Nikhilesh Prabhakar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Singh%2C+R">Ranveer Singh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kokel%2C+H">Harsha Kokel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tadepalli%2C+P">Prasad Tadepalli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.19297v1-abstract-short" style="display: inline;">
        Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments. This results in notable sample inefficiency and hinders generalization across diverse tasks. The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.19297v1-abstract-full').style.display = 'inline'; document.getElementById('2502.19297v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.19297v1-abstract-full" style="display: none;">
        Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments. This results in notable sample inefficiency and hinders generalization across diverse tasks. The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by existing MARL algorithms. To overcome these hurdles, we propose integrating relational planners as centralized controllers with efficient state abstractions and reinforcement learning. This approach proves to be sample-efficient and facilitates effective task transfer and generalization.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.19297v1-abstract-full').style.display = 'none'; document.getElementById('2502.19297v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 February, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.14232">arXiv:2412.14232</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.14232">pdf</a>, <a href="https://arxiv.org/format/2412.14232">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human-in-the-loop or AI-in-the-loop? Automate or Collaborate?
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mathur%2C+S">Saurabh Mathur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stammer%2C+W">Wolfgang Stammer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.14232v1-abstract-short" style="display: inline;">
        Human-in-the-loop (HIL) systems have emerged as a promising approach for combining the strengths of data-driven machine learning models with the contextual understanding of human experts. However, a deeper look into several of these systems reveals that calling them HIL would be a misnomer, as they are quite the opposite, namely AI-in-the-loop ($AI^2L$) systems, where the human is in control of th&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.14232v1-abstract-full').style.display = 'inline'; document.getElementById('2412.14232v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.14232v1-abstract-full" style="display: none;">
        Human-in-the-loop (HIL) systems have emerged as a promising approach for combining the strengths of data-driven machine learning models with the contextual understanding of human experts. However, a deeper look into several of these systems reveals that calling them HIL would be a misnomer, as they are quite the opposite, namely AI-in-the-loop ($AI^2L$) systems, where the human is in control of the system, while the AI is there to support the human. We argue that existing evaluation methods often overemphasize the machine (learning) component&#39;s performance, neglecting the human expert&#39;s critical role. Consequently, we propose an $AI^2L$ perspective, which recognizes that the human expert is an active participant in the system, significantly influencing its overall performance. By adopting an $AI^2L$ approach, we can develop more comprehensive systems that faithfully model the intricate interplay between the human and machine components, leading to more effective and robust AI systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.14232v1-abstract-full').style.display = 'none'; document.getElementById('2412.14232v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 December, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.02413">arXiv:2405.02413</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.02413">pdf</a>, <a href="https://arxiv.org/format/2405.02413">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Unified Framework for Human-Allied Learning of Probabilistic Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Karanam%2C+A">Athresh Karanam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mathur%2C+S">Saurabh Mathur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.02413v2-abstract-short" style="display: inline;">
        Probabilistic Circuits (PCs) have emerged as an efficient framework for representing and learning complex probability distributions. Nevertheless, the existing body of research on PCs predominantly concentrates on data-driven parameter learning, often neglecting the potential of knowledge-intensive learning, a particular issue in data-scarce/knowledge-rich domains such as healthcare. To bridge thi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.02413v2-abstract-full').style.display = 'inline'; document.getElementById('2405.02413v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.02413v2-abstract-full" style="display: none;">
        Probabilistic Circuits (PCs) have emerged as an efficient framework for representing and learning complex probability distributions. Nevertheless, the existing body of research on PCs predominantly concentrates on data-driven parameter learning, often neglecting the potential of knowledge-intensive learning, a particular issue in data-scarce/knowledge-rich domains such as healthcare. To bridge this gap, we propose a novel unified framework that can systematically integrate diverse domain knowledge into the parameter learning process of PCs. Experiments on several benchmarks as well as real world datasets show that our proposed framework can both effectively and efficiently leverage domain knowledge to achieve superior performance compared to purely data-driven learning approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.02413v2-abstract-full').style.display = 'none'; document.getElementById('2405.02413v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 May, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2403.03281">arXiv:2403.03281</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2403.03281">pdf</a>, <a href="https://arxiv.org/format/2403.03281">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Credibility-Aware Multi-Modal Fusion Using Probabilistic Circuits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tenali%2C+P">Pranuthi Tenali</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mathur%2C+S">Saurabh Mathur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Blasch%2C+E">Erik Blasch</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2403.03281v2-abstract-short" style="display: inline;">
        We consider the problem of late multi-modal fusion for discriminative learning. Motivated by noisy, multi-source domains that require understanding the reliability of each data source, we explore the notion of credibility in the context of multi-modal fusion. We propose a combination function that uses probabilistic circuits (PCs) to combine predictive distributions over individual modalities. We&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.03281v2-abstract-full').style.display = 'inline'; document.getElementById('2403.03281v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2403.03281v2-abstract-full" style="display: none;">
        We consider the problem of late multi-modal fusion for discriminative learning. Motivated by noisy, multi-source domains that require understanding the reliability of each data source, we explore the notion of credibility in the context of multi-modal fusion. We propose a combination function that uses probabilistic circuits (PCs) to combine predictive distributions over individual modalities. We also define a probabilistic measure to evaluate the credibility of each modality via inference queries over the PC. Our experimental evaluation demonstrates that our fusion method can reliably infer credibility while maintaining competitive performance with the state-of-the-art.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.03281v2-abstract-full').style.display = 'none'; document.getElementById('2403.03281v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 July, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 March, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.00759">arXiv:2402.00759</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.00759">pdf</a>, <a href="https://arxiv.org/format/2402.00759">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Building Expressive and Tractable Probabilistic Generative Models: A Review
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sidheekh%2C+S">Sahil Sidheekh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.00759v3-abstract-short" style="display: inline;">
        We present a comprehensive survey of the advancements and techniques in the field of tractable probabilistic generative modeling, primarily focusing on Probabilistic Circuits (PCs). We provide a unified perspective on the inherent trade-offs between expressivity and tractability, highlighting the design principles and algorithmic extensions that have enabled building expressive and efficient PCs,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.00759v3-abstract-full').style.display = 'inline'; document.getElementById('2402.00759v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.00759v3-abstract-full" style="display: none;">
        We present a comprehensive survey of the advancements and techniques in the field of tractable probabilistic generative modeling, primarily focusing on Probabilistic Circuits (PCs). We provide a unified perspective on the inherent trade-offs between expressivity and tractability, highlighting the design principles and algorithmic extensions that have enabled building expressive and efficient PCs, and provide a taxonomy of the field. We also discuss recent efforts to build deep and hybrid PCs by fusing notions from deep neural models, and outline the challenges and open questions that can guide future research in this evolving field.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.00759v3-abstract-full').style.display = 'none'; document.getElementById('2402.00759v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 June, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 February, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.15516">arXiv:2311.15516</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.15516">pdf</a>, <a href="https://arxiv.org/format/2311.15516">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Active Foundational Models for Fault Diagnosis of Electrical Motors
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Anbalagan%2C+S">Sriram Anbalagan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=GP%2C+S+S">Sai Shashank GP</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+D">Deepesh Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+B">Balasubramaniam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srinivasan%2C+B">Babji Srinivasan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.15516v1-abstract-short" style="display: inline;">
        Fault detection and diagnosis of electrical motors are of utmost importance in ensuring the safe and reliable operation of several industrial systems. Detection and diagnosis of faults at the incipient stage allows corrective actions to be taken in order to reduce the severity of faults. The existing data-driven deep learning approaches for machine fault diagnosis rely extensively on huge amounts&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.15516v1-abstract-full').style.display = 'inline'; document.getElementById('2311.15516v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.15516v1-abstract-full" style="display: none;">
        Fault detection and diagnosis of electrical motors are of utmost importance in ensuring the safe and reliable operation of several industrial systems. Detection and diagnosis of faults at the incipient stage allows corrective actions to be taken in order to reduce the severity of faults. The existing data-driven deep learning approaches for machine fault diagnosis rely extensively on huge amounts of labeled samples, where annotations are expensive and time-consuming. However, a major portion of unlabeled condition monitoring data is not exploited in the training process. To overcome this limitation, we propose a foundational model-based Active Learning framework that utilizes less amount of labeled samples, which are most informative and harnesses a large amount of available unlabeled data by effectively combining Active Learning and Contrastive Self-Supervised Learning techniques. It consists of a transformer network-based backbone model trained using an advanced nearest-neighbor contrastive self-supervised learning method. This approach empowers the backbone to learn improved representations of samples derived from raw, unlabeled vibration data. Subsequently, the backbone can undergo fine-tuning to address a range of downstream tasks, both within the same machines and across different machines. The effectiveness of the proposed methodology has been assessed through the fine-tuning of the backbone for multiple target tasks using three distinct machine-bearing fault datasets. The experimental evaluation demonstrates a superior performance as compared to existing state-of-the-art fault diagnosis methods with less amount of labeled data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.15516v1-abstract-full').style.display = 'none'; document.getElementById('2311.15516v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 November, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">30 pages, 2 figures, 7 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2309.12938">arXiv:2309.12938</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2309.12938">pdf</a>, <a href="https://arxiv.org/format/2309.12938">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Frustrated with Code Quality Issues? LLMs can Help!
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wadhwa%2C+N">Nalin Wadhwa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pradhan%2C+J">Jui Pradhan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sonwane%2C+A">Atharv Sonwane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sahu%2C+S+P">Surya Prakash Sahu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kanade%2C+A">Aditya Kanade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parthasarathy%2C+S">Suresh Parthasarathy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamani%2C+S">Sriram Rajamani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2309.12938v1-abstract-short" style="display: inline;">
        As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the u&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.12938v1-abstract-full').style.display = 'inline'; document.getElementById('2309.12938v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2309.12938v1-abstract-full" style="display: none;">
        As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues. We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The \emph{proposer LLM} of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The \emph{ranker LLM} evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer. CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM is able to reduce false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.12938v1-abstract-full').style.display = 'none'; document.getElementById('2309.12938v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 September, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2309.09404">arXiv:2309.09404</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2309.09404">pdf</a>, <a href="https://arxiv.org/format/2309.09404">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Promoting Research Collaboration with Open Data Driven Team Recommendation in Response to Call for Proposals
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Valluru%2C+S+L">Siva Likitha Valluru</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srivastava%2C+B">Biplav Srivastava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paladi%2C+S+T">Sai Teja Paladi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2309.09404v5-abstract-short" style="display: inline;">
        Building teams and promoting collaboration are two very common business activities. An example of these are seen in the TeamingForFunding problem, where research institutions and researchers are interested to identify collaborative opportunities when applying to funding agencies in response to latter&#39;s calls for proposals. We describe a novel system to recommend teams using a variety of AI methods&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.09404v5-abstract-full').style.display = 'inline'; document.getElementById('2309.09404v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2309.09404v5-abstract-full" style="display: none;">
        Building teams and promoting collaboration are two very common business activities. An example of these are seen in the TeamingForFunding problem, where research institutions and researchers are interested to identify collaborative opportunities when applying to funding agencies in response to latter&#39;s calls for proposals. We describe a novel system to recommend teams using a variety of AI methods, such that (1) each team achieves the highest possible skill coverage that is demanded by the opportunity, and (2) the workload of distributing the opportunities is balanced amongst the candidate members. We address these questions by extracting skills latent in open data of proposal calls (demand) and researcher profiles (supply), normalizing them using taxonomies, and creating efficient algorithms that match demand to supply. We create teams to maximize goodness along a novel metric balancing short- and long-term objectives. We validate the success of our algorithms (1) quantitatively, by evaluating the recommended teams using a goodness score and find that more informed methods lead to recommendations of smaller number of teams but higher goodness, and (2) qualitatively, by conducting a large-scale user study at a college-wide level, and demonstrate that users overall found the tool very useful and relevant. Lastly, we evaluate our system in two diverse settings in US and India (of researchers and proposal calls) to establish generality of our approach, and deploy it at a major US university for routine use.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.09404v5-abstract-full').style.display = 'none'; document.getElementById('2309.09404v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 January, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 September, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 2 figures, 3 tables, Accepted to The Thirty-Sixth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI/AAAI-24)</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          H.3.3; I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2309.05681">arXiv:2309.05681</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2309.05681">pdf</a>, <a href="https://arxiv.org/format/2309.05681">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Digital Libraries">cs.DL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge-based Refinement of Scientific Publication Knowledge Graphs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Odom%2C+P">Phillip Odom</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2309.05681v1-abstract-short" style="display: inline;">
        We consider the problem of identifying authorship by posing it as a knowledge graph construction and refinement. To this effect, we model this problem as learning a probabilistic logic model in the presence of human guidance (knowledge-based learning). Specifically, we learn relational regression trees using functional gradient boosting that outputs explainable rules. To incorporate human knowledg&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.05681v1-abstract-full').style.display = 'inline'; document.getElementById('2309.05681v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2309.05681v1-abstract-full" style="display: none;">
        We consider the problem of identifying authorship by posing it as a knowledge graph construction and refinement. To this effect, we model this problem as learning a probabilistic logic model in the presence of human guidance (knowledge-based learning). Specifically, we learn relational regression trees using functional gradient boosting that outputs explainable rules. To incorporate human knowledge, advice in the form of first-order clauses is injected to refine the trees. We demonstrate the usefulness of human knowledge both quantitatively and qualitatively in seven authorship domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.05681v1-abstract-full').style.display = 'none'; document.getElementById('2309.05681v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 September, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 14 figures, 2 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.16891">arXiv:2307.16891</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.16891">pdf</a>, <a href="https://arxiv.org/format/2307.16891">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Foundational Models for Fault Diagnosis of Electrical Motors
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Anbalagan%2C+S">Sriram Anbalagan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+D">Deepesh Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+B">Balasubramaniam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Srinivasan%2C+B">Babji Srinivasan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.16891v1-abstract-short" style="display: inline;">
        A majority of recent advancements related to the fault diagnosis of electrical motors are based on the assumption that training and testing data are drawn from the same distribution. However, the data distribution can vary across different operating conditions during real-world operating scenarios of electrical motors. Consequently, this assumption limits the practical implementation of existing s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.16891v1-abstract-full').style.display = 'inline'; document.getElementById('2307.16891v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.16891v1-abstract-full" style="display: none;">
        A majority of recent advancements related to the fault diagnosis of electrical motors are based on the assumption that training and testing data are drawn from the same distribution. However, the data distribution can vary across different operating conditions during real-world operating scenarios of electrical motors. Consequently, this assumption limits the practical implementation of existing studies for fault diagnosis, as they rely on fully labelled training data spanning all operating conditions and assume a consistent distribution. This is because obtaining a large number of labelled samples for several machines across different fault cases and operating scenarios may be unfeasible. In order to overcome the aforementioned limitations, this work proposes a framework to develop a foundational model for fault diagnosis of electrical motors. It involves building a neural network-based backbone to learn high-level features using self-supervised learning, and then fine-tuning the backbone to achieve specific objectives. The primary advantage of such an approach is that the backbone can be fine-tuned to achieve a wide variety of target tasks using very less amount of training data as compared to traditional supervised learning methodologies. The empirical evaluation demonstrates the effectiveness of the proposed approach by obtaining more than 90\% classification accuracy by fine-tuning the backbone not only across different types of fault scenarios or operating conditions, but also across different machines. This illustrates the promising potential of the proposed approach for cross-machine fault diagnosis tasks in real-world applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.16891v1-abstract-full').style.display = 'none'; document.getElementById('2307.16891v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 1 figure, 5 tables, submitted to IEEE PESGRE 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.12465">arXiv:2307.12465</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.12465">pdf</a>, <a href="https://arxiv.org/format/2307.12465">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        StaticFixer: From Static Analysis to Static Repair
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jain%2C+N">Naman Jain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gandhi%2C+S">Shubham Gandhi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sonwane%2C+A">Atharv Sonwane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kanade%2C+A">Aditya Kanade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parthasarathy%2C+S">Suresh Parthasarathy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamani%2C+S">Sriram Rajamani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+R">Rahul Sharma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.12465v1-abstract-short" style="display: inline;">
        Static analysis tools are traditionally used to detect and flag programs that violate properties. We show that static analysis tools can also be used to perturb programs that satisfy a property to construct variants that violate the property. Using this insight we can construct paired data sets of unsafe-safe program pairs, and learn strategies to automatically repair property violations. We prese&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.12465v1-abstract-full').style.display = 'inline'; document.getElementById('2307.12465v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.12465v1-abstract-full" style="display: none;">
        Static analysis tools are traditionally used to detect and flag programs that violate properties. We show that static analysis tools can also be used to perturb programs that satisfy a property to construct variants that violate the property. Using this insight we can construct paired data sets of unsafe-safe program pairs, and learn strategies to automatically repair property violations. We present a system called \sysname, which automatically repairs information flow vulnerabilities using this approach. Since information flow properties are non-local (both to check and repair), \sysname also introduces a novel domain specific language (DSL) and strategy learning algorithms for synthesizing non-local repairs. We use \sysname to synthesize strategies for repairing two types of information flow vulnerabilities, unvalidated dynamic calls and cross-site scripting, and show that \sysname successfully repairs several hundred vulnerabilities from open source {\sc JavaScript} repositories, outperforming neural baselines built using {\sc CodeT5} and {\sc Codex}. Our datasets can be downloaded from \url{http://aka.ms/StaticFixer}.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.12465v1-abstract-full').style.display = 'none'; document.getElementById('2307.12465v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2302.03800">arXiv:2302.03800</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2302.03800">pdf</a>, <a href="https://arxiv.org/format/2302.03800">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        MACOptions: Multi-Agent Learning with Centralized Controller and Options Framework
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Aggarwal%2C+A">Alakh Aggarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bansal%2C+R">Rishita Bansal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Padalkar%2C+P">Parth Padalkar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2302.03800v1-abstract-short" style="display: inline;">
        These days automation is being applied everywhere. In every environment, planning for the actions to be taken by the agents is an important aspect. In this paper, we plan to implement planning for multi-agents with a centralized controller. We compare three approaches: random policy, Q-learning, and Q-learning with Options Framework. We also show the effectiveness of planners by showing performanc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.03800v1-abstract-full').style.display = 'inline'; document.getElementById('2302.03800v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2302.03800v1-abstract-full" style="display: none;">
        These days automation is being applied everywhere. In every environment, planning for the actions to be taken by the agents is an important aspect. In this paper, we plan to implement planning for multi-agents with a centralized controller. We compare three approaches: random policy, Q-learning, and Q-learning with Options Framework. We also show the effectiveness of planners by showing performance comparison between Q-Learning with Planner and without Planner.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.03800v1-abstract-full').style.display = 'none'; document.getElementById('2302.03800v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2207.09566">arXiv:2207.09566</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2207.09566">pdf</a>, <a href="https://arxiv.org/format/2207.09566">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human-guided Collaborative Problem Solving: A Natural Language based Framework
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kokel%2C+H">Harsha Kokel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Islam%2C+R">Rakibul Islam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonn%2C+J">Julia Bonn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+J">Jon Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dan%2C+S">Soham Dan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Narayan-Chen%2C+A">Anjali Narayan-Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jayannavar%2C+P">Prashant Jayannavar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hockenmaier%2C+J">Julia Hockenmaier</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Palmer%2C+M">Martha Palmer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roth%2C+D">Dan Roth</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2207.09566v1-abstract-short" style="display: inline;">
        We consider the problem of human-machine collaborative problem solving as a planning task coupled with natural language communication. Our framework consists of three components -- a natural language engine that parses the language utterances to a formal representation and vice-versa, a concept learner that induces generalized concepts for plans based on limited interactions with the user, and an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.09566v1-abstract-full').style.display = 'inline'; document.getElementById('2207.09566v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2207.09566v1-abstract-full" style="display: none;">
        We consider the problem of human-machine collaborative problem solving as a planning task coupled with natural language communication. Our framework consists of three components -- a natural language engine that parses the language utterances to a formal representation and vice-versa, a concept learner that induces generalized concepts for plans based on limited interactions with the user, and an HTN planner that solves the task based on human interaction. We illustrate the ability of this framework to address the key challenges of collaborative problem solving by demonstrating it on a collaborative building task in a Minecraft-based blocksworld domain. The accompanied demo video is available at https://youtu.be/q1pWe4aahF0.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.09566v1-abstract-full').style.display = 'none'; document.getElementById('2207.09566v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 July, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ICAPS 2021 (demo track)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2206.07904">arXiv:2206.07904</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2206.07904">pdf</a>, <a href="https://arxiv.org/format/2206.07904">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Explainable Models via Compression of Tree Ensembles
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joshi%2C+S">Saket Joshi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khardon%2C+R">Roni Khardon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tadepalli%2C+P">Prasad Tadepalli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2206.07904v1-abstract-short" style="display: inline;">
        Ensemble models (bagging and gradient-boosting) of relational decision trees have proved to be one of the most effective learning methods in the area of probabilistic logic models (PLMs). While effective, they lose one of the most important aspect of PLMs -- interpretability. In this paper we consider the problem of compressing a large set of learned trees into a single explainable model. To this&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.07904v1-abstract-full').style.display = 'inline'; document.getElementById('2206.07904v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2206.07904v1-abstract-full" style="display: none;">
        Ensemble models (bagging and gradient-boosting) of relational decision trees have proved to be one of the most effective learning methods in the area of probabilistic logic models (PLMs). While effective, they lose one of the most important aspect of PLMs -- interpretability. In this paper we consider the problem of compressing a large set of learned trees into a single explainable model. To this effect, we propose CoTE -- Compression of Tree Ensembles -- that produces a single small decision list as a compressed representation. CoTE first converts the trees to decision lists and then performs the combination and compression with the aid of the original training set. An experimental evaluation demonstrates the effectiveness of CoTE in several benchmark relational data sets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.07904v1-abstract-full').style.display = 'none'; document.getElementById('2206.07904v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 June, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages, 14 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2202.13870">arXiv:2202.13870</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2202.13870">pdf</a>, <a href="https://arxiv.org/format/2202.13870">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Simulating Network Paths with Recurrent Buffering Units
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Anshumaan%2C+D">Divyam Anshumaan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balasubramanian%2C+S">Sriram Balasubramanian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tiwari%2C+S">Shubham Tiwari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sellamanickam%2C+S">Sundararajan Sellamanickam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Padmanabhan%2C+V+N">Venkata N. Padmanabhan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2202.13870v3-abstract-short" style="display: inline;">
        Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. The problem setting is unique, and renders the state-of-the-art text and time-series&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.13870v3-abstract-full').style.display = 'inline'; document.getElementById('2202.13870v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2202.13870v3-abstract-full" style="display: none;">
        Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. The problem setting is unique, and renders the state-of-the-art text and time-series generative models inapplicable or ineffective. We formulate an ML problem at the intersection of dynamical systems, sequential decision making, and time-series modeling. We propose a novel grey-box approach to network simulation that embeds the semantics of physical network path in a new RNN-style model called RBU, providing the interpretability of standard network simulator tools, the power of neural models, the efficiency of SGD-based techniques for learning, and yielding promising results on synthetic and real-world network traces.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2202.13870v3-abstract-full').style.display = 'none'; document.getElementById('2202.13870v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 December, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 February, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in AAAI 2023, 19 pages, 14 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.02969">arXiv:2112.02969</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.02969">pdf</a>, <a href="https://arxiv.org/format/2112.02969">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Jigsaw: Large Language Models meet Program Synthesis
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jain%2C+N">Naman Jain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vaidyanath%2C+S">Skanda Vaidyanath</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iyer%2C+A">Arun Iyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parthasarathy%2C+S">Suresh Parthasarathy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamani%2C+S">Sriram Rajamani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+R">Rahul Sharma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.02969v1-abstract-short" style="display: inline;">
        Large pre-trained language models such as GPT-3, Codex, and Google&#39;s language model are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every progra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.02969v1-abstract-full').style.display = 'inline'; document.getElementById('2112.02969v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.02969v1-abstract-full" style="display: none;">
        Large pre-trained language models such as GPT-3, Codex, and Google&#39;s language model are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every programmer in the world. On the cautionary side, since these large language models do not understand program semantics, they offer no guarantees about quality of the suggested code. In this paper, we present an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs. Further, we show that such techniques can make use of user feedback and improve with usage. We present our experiences from building and evaluating such a tool jigsaw, targeted at synthesizing code for using Python Pandas API using multi-modal inputs. Our experience suggests that as these large language models evolve for synthesizing code from intent, jigsaw has an important role to play in improving the accuracy of the systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.02969v1-abstract-full').style.display = 'none'; document.getElementById('2112.02969v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ICSE&#39;22</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.09778">arXiv:2110.09778</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.09778">pdf</a>, <a href="https://arxiv.org/format/2110.09778">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Explaining Deep Tractable Probabilistic Models: The sum-product network case
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Karanam%2C+A">Athresh Karanam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mathur%2C+S">Saurabh Mathur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Radivojac%2C+P">Predrag Radivojac</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Haas%2C+D+M">David M. Haas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.09778v2-abstract-short" style="display: inline;">
        We consider the problem of explaining a class of tractable deep probabilistic models, the Sum-Product Networks (SPNs) and present an algorithm ExSPN to generate explanations. To this effect, we define the notion of a context-specific independence tree(CSI-tree) and present an iterative algorithm that converts an SPN to a CSI-tree. The resulting CSI-tree is both interpretable and explainable to the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.09778v2-abstract-full').style.display = 'inline'; document.getElementById('2110.09778v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.09778v2-abstract-full" style="display: none;">
        We consider the problem of explaining a class of tractable deep probabilistic models, the Sum-Product Networks (SPNs) and present an algorithm ExSPN to generate explanations. To this effect, we define the notion of a context-specific independence tree(CSI-tree) and present an iterative algorithm that converts an SPN to a CSI-tree. The resulting CSI-tree is both interpretable and explainable to the domain expert. We achieve this by extracting the conditional independencies encoded by the SPN and approximating the local context specified by the structure of the SPN. Our extensive empirical evaluations on synthetic, standard, and real-world clinical data sets demonstrate that the CSI-tree exhibits superior explainability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.09778v2-abstract-full').style.display = 'none'; document.getElementById('2110.09778v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 September, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 October, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Main paper: 8 pages, references: 1 page. Main paper: 4 figures</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        PMLR 186:325-336 (2022)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.09647">arXiv:2110.09647</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.09647">pdf</a>, <a href="https://arxiv.org/format/2110.09647">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Relational Neural Markov Random Fields
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yuqiao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruozzi%2C+N">Nicholas Ruozzi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.09647v1-abstract-short" style="display: inline;">
        Statistical Relational Learning (SRL) models have attracted significant attention due to their ability to model complex data while handling uncertainty. However, most of these models have been limited to discrete domains due to their limited potential functions. We introduce Relational Neural Markov Random Fields (RN-MRFs) which allow for handling of complex relational hybrid domains. The key adva&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.09647v1-abstract-full').style.display = 'inline'; document.getElementById('2110.09647v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.09647v1-abstract-full" style="display: none;">
        Statistical Relational Learning (SRL) models have attracted significant attention due to their ability to model complex data while handling uncertainty. However, most of these models have been limited to discrete domains due to their limited potential functions. We introduce Relational Neural Markov Random Fields (RN-MRFs) which allow for handling of complex relational hybrid domains. The key advantage of our model is that it makes minimal data distributional assumptions and can seamlessly allow for human knowledge through potentials or relational rules. We propose a maximum pseudolikelihood estimation-based learning algorithm with importance sampling for training the neural potential parameters. Our empirical evaluations across diverse domains such as image processing and relational object mapping, clearly demonstrate its effectiveness against non-neural counterparts.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.09647v1-abstract-full').style.display = 'none'; document.getElementById('2110.09647v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">StarAI 2021 workshop on IJCLR 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.08318">arXiv:2110.08318</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.08318">pdf</a>, <a href="https://arxiv.org/format/2110.08318">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Dynamic probabilistic logic models for effective abstractions in RL
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kokel%2C+H">Harsha Kokel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Manoharan%2C+A">Arjun Manoharan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ravindran%2C+B">Balaraman Ravindran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tadepalli%2C+P">Prasad Tadepalli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.08318v1-abstract-short" style="display: inline;">
        State abstraction enables sample-efficient learning and better task transfer in complex reinforcement learning environments. Recently, we proposed RePReL (Kokel et al. 2021), a hierarchical framework that leverages a relational planner to provide useful state abstractions for learning. We present a brief overview of this framework and the use of a dynamic probabilistic logic model to design these&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.08318v1-abstract-full').style.display = 'inline'; document.getElementById('2110.08318v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.08318v1-abstract-full" style="display: none;">
        State abstraction enables sample-efficient learning and better task transfer in complex reinforcement learning environments. Recently, we proposed RePReL (Kokel et al. 2021), a hierarchical framework that leverages a relational planner to provide useful state abstractions for learning. We present a brief overview of this framework and the use of a dynamic probabilistic logic model to design these state abstractions. Our experiments show that RePReL not only achieves better performance and efficient learning on the task at hand but also demonstrates better generalization to unseen tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.08318v1-abstract-full').style.display = 'none'; document.getElementById('2110.08318v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at StarAI 2021 (held in conjunction with IJCLR 2021)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2103.10916">arXiv:2103.10916</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2103.10916">pdf</a>, <a href="https://arxiv.org/format/2103.10916">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Predicting Drug-Drug Interactions from Heterogeneous Data: An Embedding Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Page%2C+D">David Page</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2103.10916v1-abstract-short" style="display: inline;">
        Predicting and discovering drug-drug interactions (DDIs) using machine learning has been studied extensively. However, most of the approaches have focused on text data or textual representation of the drug structures. We present the first work that uses multiple data sources such as drug structure images, drug structure string representation and relational representation of drug relationships as t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10916v1-abstract-full').style.display = 'inline'; document.getElementById('2103.10916v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2103.10916v1-abstract-full" style="display: none;">
        Predicting and discovering drug-drug interactions (DDIs) using machine learning has been studied extensively. However, most of the approaches have focused on text data or textual representation of the drug structures. We present the first work that uses multiple data sources such as drug structure images, drug structure string representation and relational representation of drug relationships as the input. To this effect, we exploit the recent advances in deep networks to integrate these varied sources of inputs in predicting DDIs. Our empirical evaluation against several state-of-the-art methods using standalone different data types for drugs clearly demonstrate the efficacy of combining heterogeneous data in predicting DDIs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2103.10916v1-abstract-full').style.display = 'none'; document.getElementById('2103.10916v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 March, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 6 figures, Accepted as a short paper to &#39;Artificial Intelligence in Medicine 2021&#39;</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10440">arXiv:2102.10440</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10440">pdf</a>, <a href="https://arxiv.org/format/2102.10440">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Interventional Sum-Product Networks: Causal Inference with Tractable Probabilistic Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ze%C4%8Devi%C4%87%2C+M">Matej Zečević</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karanam%2C+A">Athresh Karanam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10440v5-abstract-short" style="display: inline;">
        While probabilistic models are an important tool for studying causality, doing so suffers from the intractability of inference. As a step towards tractable causal models, we consider the problem of learning interventional distributions using sum-product networks (SPNs) that are over-parameterized by gate functions, e.g., neural networks. Providing an arbitrarily intervened causal graph as input, e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10440v5-abstract-full').style.display = 'inline'; document.getElementById('2102.10440v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10440v5-abstract-full" style="display: none;">
        While probabilistic models are an important tool for studying causality, doing so suffers from the intractability of inference. As a step towards tractable causal models, we consider the problem of learning interventional distributions using sum-product networks (SPNs) that are over-parameterized by gate functions, e.g., neural networks. Providing an arbitrarily intervened causal graph as input, effectively subsuming Pearl&#39;s do-operator, the gate function predicts the parameters of the SPN. The resulting interventional SPNs are motivated and illustrated by a structural causal model themed around personal health. Our empirical evaluation on three benchmark data sets as well as a synthetic health data set clearly demonstrates that interventional SPNs indeed are both expressive in modelling and flexible in adapting to the interventions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10440v5-abstract-full').style.display = 'none'; document.getElementById('2102.10440v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 October, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Main paper: 10 pages, References: 3 pages, Appendix: 8 pages. Main paper: 6 figures, Appendix: 5 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.07007">arXiv:2102.07007</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.07007">pdf</a>, <a href="https://arxiv.org/format/2102.07007">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Statistical Relational Approach to Learning Distance-based GCNs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.07007v4-abstract-short" style="display: inline;">
        We consider the problem of learning distance-based Graph Convolutional Networks (GCNs) for relational data. Specifically, we first embed the original graph into the Euclidean space $\mathbb{R}^m$ using a relational density estimation technique thereby constructing a secondary Euclidean graph. The graph vertices correspond to the target triples and edges denote the Euclidean distances between the t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07007v4-abstract-full').style.display = 'inline'; document.getElementById('2102.07007v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.07007v4-abstract-full" style="display: none;">
        We consider the problem of learning distance-based Graph Convolutional Networks (GCNs) for relational data. Specifically, we first embed the original graph into the Euclidean space $\mathbb{R}^m$ using a relational density estimation technique thereby constructing a secondary Euclidean graph. The graph vertices correspond to the target triples and edges denote the Euclidean distances between the target triples. We emphasize the importance of learning the secondary Euclidean graph and the advantages of employing a distance matrix over the typically used adjacency matrix. Our comprehensive empirical evaluation demonstrates the superiority of our approach over $12$ different GCN models, relational embedding techniques and rule learning techniques.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.07007v4-abstract-full').style.display = 'none'; document.getElementById('2102.07007v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 October, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 5 figures, 4 tables; accepted to STARAI workshop</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.09220">arXiv:2012.09220</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.09220">pdf</a>, <a href="https://arxiv.org/format/2012.09220">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Relational Boosted Bandits
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kakadiya%2C+A">Ashutosh Kakadiya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ravindran%2C+B">Balaraman Ravindran</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.09220v1-abstract-short" style="display: inline;">
        Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms rely on context as attribute value representation, which makes them unfeasible for real-world domains like social networks are inherently relational. We propose Relational Boosted Bandits(RB2), acontextual bandits algorithm for relational domains based on (relation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.09220v1-abstract-full').style.display = 'inline'; document.getElementById('2012.09220v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.09220v1-abstract-full" style="display: none;">
        Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms rely on context as attribute value representation, which makes them unfeasible for real-world domains like social networks are inherently relational. We propose Relational Boosted Bandits(RB2), acontextual bandits algorithm for relational domains based on (relational) boosted trees. RB2 enables us to learn interpretable and explainable models due to the more descriptive nature of the relational representation. We empirically demonstrate the effectiveness and interpretability of RB2 on tasks such as link prediction, relational classification, and recommendations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.09220v1-abstract-full').style.display = 'none'; document.getElementById('2012.09220v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 3 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2007.06835">arXiv:2007.06835</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2007.06835">pdf</a>, <a href="https://arxiv.org/format/2007.06835">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Programming Languages">cs.PL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Programming by Rewards
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+N">Nagarajan Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Karthikeyan%2C+A">Ajaykrishna Karthikeyan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jain%2C+P">Prateek Jain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Radicek%2C+I">Ivan Radicek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rajamani%2C+S">Sriram Rajamani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gulwani%2C+S">Sumit Gulwani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gehrke%2C+J">Johannes Gehrke</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2007.06835v1-abstract-short" style="display: inline;">
        We formalize and study ``programming by rewards&#39;&#39; (PBR), a new approach for specifying and synthesizing subroutines for optimizing some quantitative metric such as performance, resource utilization, or correctness over a benchmark. A PBR specification consists of (1) input features $x$, and (2) a reward function $r$, modeled as a black-box component (which we can only run), that assigns a reward f&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.06835v1-abstract-full').style.display = 'inline'; document.getElementById('2007.06835v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2007.06835v1-abstract-full" style="display: none;">
        We formalize and study ``programming by rewards&#39;&#39; (PBR), a new approach for specifying and synthesizing subroutines for optimizing some quantitative metric such as performance, resource utilization, or correctness over a benchmark. A PBR specification consists of (1) input features $x$, and (2) a reward function $r$, modeled as a black-box component (which we can only run), that assigns a reward for each execution. The goal of the synthesizer is to synthesize a &#34;decision function&#34; $f$ which transforms the features to a decision value for the black-box component so as to maximize the expected reward $E[r \circ f (x)]$ for executing decisions $f(x)$ for various values of $x$. We consider a space of decision functions in a DSL of loop-free if-then-else programs, which can branch on linear functions of the input features in a tree-structure and compute a linear function of the inputs in the leaves of the tree. We find that this DSL captures decision functions that are manually written in practice by programmers. Our technical contribution is the use of continuous-optimization techniques to perform synthesis of such decision functions as if-then-else programs. We also show that the framework is theoretically-founded ---in cases when the rewards satisfy nice properties, the synthesized code is optimal in a precise sense.
  We have leveraged PBR to synthesize non-trivial decision functions related to search and ranking heuristics in the PROSE codebase (an industrial strength program synthesis framework) and achieve competitive results to manually written procedures over multiple man years of tuning. We present empirical evaluation against other baseline techniques over real-world case studies (including PROSE) as well on simple synthetic benchmarks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2007.06835v1-abstract-full').style.display = 'none'; document.getElementById('2007.06835v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 July, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.05595">arXiv:2006.05595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.05595">pdf</a>, <a href="https://arxiv.org/format/2006.05595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fitted Q-Learning for Relational Domains
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+S">Srijita Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roy%2C+K">Kaushik Roy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parr%2C+R">Ronald Parr</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.05595v1-abstract-short" style="display: inline;">
        We consider the problem of Approximate Dynamic Programming in relational domains. Inspired by the success of fitted Q-learning methods in propositional settings, we develop the first relational fitted Q-learning algorithms by representing the value function and Bellman residuals. When we fit the Q-functions, we show how the two steps of Bellman operator; application and projection steps can be per&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.05595v1-abstract-full').style.display = 'inline'; document.getElementById('2006.05595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.05595v1-abstract-full" style="display: none;">
        We consider the problem of Approximate Dynamic Programming in relational domains. Inspired by the success of fitted Q-learning methods in propositional settings, we develop the first relational fitted Q-learning algorithms by representing the value function and Bellman residuals. When we fit the Q-functions, we show how the two steps of Bellman operator; application and projection steps can be performed using a gradient-boosting technique. Our proposed framework performs reasonably well on standard domains without using domain models and using fewer training trajectories.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.05595v1-abstract-full').style.display = 'none'; document.getElementById('2006.05595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, 12 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.12145">arXiv:2003.12145</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.12145">pdf</a>, <a href="https://arxiv.org/format/2003.12145">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge Graph Alignment using String Edit Distance
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kaur%2C+N">Navdeep Kaur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.12145v2-abstract-short" style="display: inline;">
        In this work, we propose a novel knowledge graph alignment technique based upon string edit distance that exploits the type information between entities and can find similarity between relations of any arity
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.12145v2-abstract-full" style="display: none;">
        In this work, we propose a novel knowledge graph alignment technique based upon string edit distance that exploits the type information between entities and can find similarity between relations of any arity
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.12145v2-abstract-full').style.display = 'none'; document.getElementById('2003.12145v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 March, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Position Paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.10070">arXiv:2001.10070</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.10070">pdf</a>, <a href="https://arxiv.org/format/2001.10070">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Non-Parametric Learning of Lifted Restricted Boltzmann Machines
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kaur%2C+N">Navdeep Kaur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.10070v1-abstract-short" style="display: inline;">
        We consider the problem of discriminatively learning restricted Boltzmann machines in the presence of relational data. Unlike previous approaches that employ a rule learner (for structure learning) and a weight learner (for parameter learning) sequentially, we develop a gradient-boosted approach that performs both simultaneously. Our approach learns a set of weak relational regression trees, whose&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.10070v1-abstract-full').style.display = 'inline'; document.getElementById('2001.10070v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.10070v1-abstract-full" style="display: none;">
        We consider the problem of discriminatively learning restricted Boltzmann machines in the presence of relational data. Unlike previous approaches that employ a rule learner (for structure learning) and a weight learner (for parameter learning) sequentially, we develop a gradient-boosted approach that performs both simultaneously. Our approach learns a set of weak relational regression trees, whose paths from root to leaf are conjunctive clauses and represent the structure, and whose leaf values represent the parameters. When the learned relational regression trees are transformed into a lifted RBM, its hidden nodes are precisely the conjunctive clauses derived from the relational regression trees. This leads to a more interpretable and explainable model. Our empirical evaluations clearly demonstrate this aspect, while displaying no loss in effectiveness of the learned models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.10070v1-abstract-full').style.display = 'none'; document.getElementById('2001.10070v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 January, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">33 pages, 12 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.04432">arXiv:2001.04432</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.04432">pdf</a>, <a href="https://arxiv.org/format/2001.04432">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Preliminary Approach for Learning Relational Policies for the Management of Critically Ill Children
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Skinner%2C+M+A">Michael A. Skinner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raman%2C+L">Lakshmi Raman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+N">Neel Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farhat%2C+A">Abdelaziz Farhat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.04432v1-abstract-short" style="display: inline;">
        The increased use of electronic health records has made possible the automated extraction of medical policies from patient records to aid in the development of clinical decision support systems. We adapted a boosted Statistical Relational Learning (SRL) framework to learn probabilistic rules from clinical hospital records for the management of physiologic parameters of children with severe cardiac&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.04432v1-abstract-full').style.display = 'inline'; document.getElementById('2001.04432v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.04432v1-abstract-full" style="display: none;">
        The increased use of electronic health records has made possible the automated extraction of medical policies from patient records to aid in the development of clinical decision support systems. We adapted a boosted Statistical Relational Learning (SRL) framework to learn probabilistic rules from clinical hospital records for the management of physiologic parameters of children with severe cardiac or respiratory failure who were managed with extracorporeal membrane oxygenation. In this preliminary study, the results were promising. In particular, the algorithm returned logic rules for medical actions that are consistent with medical reasoning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.04432v1-abstract-full').style.display = 'none'; document.getElementById('2001.04432v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 January, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 1 figure, presented at the 2020 AAAI StarAI workshop</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.02773">arXiv:2001.02773</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.02773">pdf</a>, <a href="https://arxiv.org/format/2001.02773">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lifted Hybrid Variational Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yuqiao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">Yibo Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ruozzi%2C+N">Nicholas Ruozzi</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.02773v2-abstract-short" style="display: inline;">
        A variety of lifted inference algorithms, which exploit model symmetry to reduce computational cost, have been proposed to render inference tractable in probabilistic relational models. Most existing lifted inference algorithms operate only over discrete domains or continuous domains with restricted potential functions, e.g., Gaussian. We investigate two approximate lifted variational approaches t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.02773v2-abstract-full').style.display = 'inline'; document.getElementById('2001.02773v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.02773v2-abstract-full" style="display: none;">
        A variety of lifted inference algorithms, which exploit model symmetry to reduce computational cost, have been proposed to render inference tractable in probabilistic relational models. Most existing lifted inference algorithms operate only over discrete domains or continuous domains with restricted potential functions, e.g., Gaussian. We investigate two approximate lifted variational approaches that are applicable to hybrid domains and expressive enough to capture multi-modality. We demonstrate that the proposed variational methods are both scalable and can take advantage of approximate model symmetries, even in the presence of a large amount of continuous evidence. We demonstrate that our approach compares favorably against existing message-passing based approaches in a variety of settings. Finally, we present a sufficient condition for the Bethe approximation to yield a non-trivial estimate over the marginal polytope.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.02773v2-abstract-full').style.display = 'none'; document.getElementById('2001.02773v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 January, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">AAAI 2020 Workshop on Statistical Relational AI (StarAI 2020)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2001.00528">arXiv:2001.00528</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2001.00528">pdf</a>, <a href="https://arxiv.org/format/2001.00528">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Non-Parametric Learning of Gaifman Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2001.00528v2-abstract-short" style="display: inline;">
        We consider the problem of structure learning for Gaifman models and learn relational features that can be used to derive feature representations from a knowledge base. These relational features are first-order rules that are then partially grounded and counted over local neighborhoods of a Gaifman model to obtain the feature representations. We propose a method for learning these relational featu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.00528v2-abstract-full').style.display = 'inline'; document.getElementById('2001.00528v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2001.00528v2-abstract-full" style="display: none;">
        We consider the problem of structure learning for Gaifman models and learn relational features that can be used to derive feature representations from a knowledge base. These relational features are first-order rules that are then partially grounded and counted over local neighborhoods of a Gaifman model to obtain the feature representations. We propose a method for learning these relational features for a Gaifman model by using relational tree distances. Our empirical evaluation on real data sets demonstrates the superiority of our approach over classical rule-learning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2001.00528v2-abstract-full').style.display = 'none'; document.getElementById('2001.00528v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 January, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 January, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1912.07650">arXiv:1912.07650</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1912.07650">pdf</a>, <a href="https://arxiv.org/format/1912.07650">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3148011.3148027">10.1145/3148011.3148027 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        User Friendly Automatic Construction of Background Knowledge: Mode Construction from ER Diagrams
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hayes%2C+A+L">Alexander L. Hayes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Odom%2C+P">Phillip Odom</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1912.07650v1-abstract-short" style="display: inline;">
        One of the key advantages of Inductive Logic Programming systems is the ability of the domain experts to provide background knowledge as modes that allow for efficient search through the space of hypotheses. However, there is an inherent assumption that this expert should also be an ILP expert to provide effective modes. We relax this assumption by designing a graphical user interface that allows&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.07650v1-abstract-full').style.display = 'inline'; document.getElementById('1912.07650v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1912.07650v1-abstract-full" style="display: none;">
        One of the key advantages of Inductive Logic Programming systems is the ability of the domain experts to provide background knowledge as modes that allow for efficient search through the space of hypotheses. However, there is an inherent assumption that this expert should also be an ILP expert to provide effective modes. We relax this assumption by designing a graphical user interface that allows the domain expert to interact with the system using Entity Relationship diagrams. These interactions are used to construct modes for the learning system. We evaluate our algorithm on a probabilistic logic learning system where we demonstrate that the user is able to construct effective background knowledge on par with the expert-encoded knowledge on five data sets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.07650v1-abstract-full').style.display = 'none'; document.getElementById('1912.07650v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages. Published in Proceedings of the Knowledge Capture Conference, 2017</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the Knowledge Capture Conference (2017) 30:1-30:8
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1912.07060">arXiv:1912.07060</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1912.07060">pdf</a>, <a href="https://arxiv.org/format/1912.07060">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        One-Shot Induction of Generalized Logical Concepts via Human Guidance
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ramanan%2C+N">Nandini Ramanan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1912.07060v1-abstract-short" style="display: inline;">
        We consider the problem of learning generalized first-order representations of concepts from a single example. To address this challenging problem, we augment an inductive logic programming learner with two novel algorithmic contributions. First, we define a distance measure between candidate concept representations that improves the efficiency of search for target concept and generalization. Seco&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.07060v1-abstract-full').style.display = 'inline'; document.getElementById('1912.07060v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1912.07060v1-abstract-full" style="display: none;">
        We consider the problem of learning generalized first-order representations of concepts from a single example. To address this challenging problem, we augment an inductive logic programming learner with two novel algorithmic contributions. First, we define a distance measure between candidate concept representations that improves the efficiency of search for target concept and generalization. Second, we leverage richer human inputs in the form of advice to improve the sample-efficiency of learning. We prove that the proposed distance measure is semantically valid and use that to derive a PAC bound. Our experimental analysis on diverse concept learning tasks demonstrates both the effectiveness and efficiency of the proposed approach over a first-order concept learner using only examples.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.07060v1-abstract-full').style.display = 'none'; document.getElementById('1912.07060v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 December, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">STARAI &#39;20, Workshop version</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.06356">arXiv:1911.06356</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.06356">pdf</a>, <a href="https://arxiv.org/format/1911.06356">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Beyond Textual Data: Predicting Drug-Drug Interactions from Molecular Structure Images using Siamese Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Siwen Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Page%2C+D">David Page</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.06356v2-abstract-short" style="display: inline;">
        Predicting and discovering drug-drug interactions (DDIs) is an important problem and has been studied extensively both from medical and machine learning point of view. Almost all of the machine learning approaches have focused on text data or textual representation of the structural data of drugs. We present the first work that uses drug structure images as the input and utilizes a Siamese convolu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.06356v2-abstract-full').style.display = 'inline'; document.getElementById('1911.06356v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.06356v2-abstract-full" style="display: none;">
        Predicting and discovering drug-drug interactions (DDIs) is an important problem and has been studied extensively both from medical and machine learning point of view. Almost all of the machine learning approaches have focused on text data or textual representation of the structural data of drugs. We present the first work that uses drug structure images as the input and utilizes a Siamese convolutional network architecture to predict DDIs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.06356v2-abstract-full').style.display = 'none'; document.getElementById('1911.06356v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 June, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 November, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 9 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1909.04723">arXiv:1909.04723</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1909.04723">pdf</a>, <a href="https://arxiv.org/format/1909.04723">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Neural Networks for Relational Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kaur%2C+N">Navdeep Kaur</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joshi%2C+S">Saket Joshi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1909.04723v3-abstract-short" style="display: inline;">
        While deep networks have been enormously successful over the last decade, they rely on flat-feature vector representations, which makes them unsuitable for richly structured domains such as those arising in applications like social network analysis. Such domains rely on relational representations to capture complex relationships between entities and their attributes. Thus, we consider the problem&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.04723v3-abstract-full').style.display = 'inline'; document.getElementById('1909.04723v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1909.04723v3-abstract-full" style="display: none;">
        While deep networks have been enormously successful over the last decade, they rely on flat-feature vector representations, which makes them unsuitable for richly structured domains such as those arising in applications like social network analysis. Such domains rely on relational representations to capture complex relationships between entities and their attributes. Thus, we consider the problem of learning neural networks for relational data. We distinguish ourselves from current approaches that rely on expert hand-coded rules by learning relational random-walk-based features to capture local structural interactions and the resulting network architecture. We further exploit parameter tying of the network weights of the resulting relational neural network, where instances of the same type share parameters. Our experimental results across several standard relational data sets demonstrate the effectiveness of the proposed approach over multiple neural net baselines as well as state-of-the-art statistical relational models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1909.04723v3-abstract-full').style.display = 'none'; document.getElementById('1909.04723v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 January, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 August, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages, 2 figures. To appear in the proceedings of 29th International Conference on Inductive Logic Programming (2019)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.01432">arXiv:1906.01432</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.01432">pdf</a>, <a href="https://arxiv.org/format/1906.01432">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge-augmented Column Networks: Guiding Deep Learning with Advice
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.01432v1-abstract-short" style="display: inline;">
        Recently, deep models have had considerable success in several tasks, especially with low-level representations. However, effective learning from sparse noisy samples is a major challenge in most deep models, especially in domains with structured representations. Inspired by the proven success of human guided machine learning, we propose Knowledge-augmented Column Networks, a relational deep learn&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.01432v1-abstract-full').style.display = 'inline'; document.getElementById('1906.01432v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.01432v1-abstract-full" style="display: none;">
        Recently, deep models have had considerable success in several tasks, especially with low-level representations. However, effective learning from sparse noisy samples is a major challenge in most deep models, especially in domains with structured representations. Inspired by the proven success of human guided machine learning, we propose Knowledge-augmented Column Networks, a relational deep learning framework that leverages human advice/knowledge to learn better models in presence of sparsity and systematic noise.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.01432v1-abstract-full').style.display = 'none'; document.getElementById('1906.01432v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 May, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL 2019), Long Beach, USA. arXiv admin note: substantial text overlap with arXiv:1904.06950</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1904.06950">arXiv:1904.06950</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1904.06950">pdf</a>, <a href="https://arxiv.org/format/1904.06950">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Human-Guided Learning of Column Networks: Augmenting Deep Learning with Advice
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+Y">Yang Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dhami%2C+D+S">Devendra Singh Dhami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1904.06950v1-abstract-short" style="display: inline;">
        Recently, deep models have been successfully applied in several applications, especially with low-level representations. However, sparse, noisy samples and structured domains (with multiple objects and interactions) are some of the open challenges in most deep models. Column Networks, a deep architecture, can succinctly capture such domain structure and interactions, but may still be prone to sub-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.06950v1-abstract-full').style.display = 'inline'; document.getElementById('1904.06950v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1904.06950v1-abstract-full" style="display: none;">
        Recently, deep models have been successfully applied in several applications, especially with low-level representations. However, sparse, noisy samples and structured domains (with multiple objects and interactions) are some of the open challenges in most deep models. Column Networks, a deep architecture, can succinctly capture such domain structure and interactions, but may still be prone to sub-optimal learning from sparse and noisy samples. Inspired by the success of human-advice guided learning in AI, especially in data-scarce domains, we propose Knowledge-augmented Column Networks that leverage human advice/knowledge for better learning with noisy/sparse samples. Our experiments demonstrate that our approach leads to either superior overall performance or faster convergence (i.e., both effective and efficient).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1904.06950v1-abstract-full').style.display = 'none'; document.getElementById('1904.06950v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 April, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Under Review at &#39;Machine Learning Journal&#39; (MLJ)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1810.01403">arXiv:1810.01403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1810.01403">pdf</a>, <a href="https://arxiv.org/format/1810.01403">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GLAD: GLocalized Anomaly Detection via Human-in-the-Loop Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Islam%2C+M+R">Md Rakibul Islam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+S">Shubhomoy Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa%2C+J+R">Janardhan Rao Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1810.01403v4-abstract-short" style="display: inline;">
        Human analysts that use anomaly detection systems in practice want to retain the use of simple and explainable global anomaly detectors. In this paper, we propose a novel human-in-the-loop learning algorithm called GLAD (GLocalized Anomaly Detection) that supports global anomaly detectors. GLAD automatically learns their local relevance to specific data instances using label feedback from human an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.01403v4-abstract-full').style.display = 'inline'; document.getElementById('1810.01403v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1810.01403v4-abstract-full" style="display: none;">
        Human analysts that use anomaly detection systems in practice want to retain the use of simple and explainable global anomaly detectors. In this paper, we propose a novel human-in-the-loop learning algorithm called GLAD (GLocalized Anomaly Detection) that supports global anomaly detectors. GLAD automatically learns their local relevance to specific data instances using label feedback from human analysts. The key idea is to place a uniform prior on the relevance of each member of the anomaly detection ensemble over the input feature space via a neural network trained on unlabeled instances. Subsequently, weights of the neural network are tuned to adjust the local relevance of each ensemble member using all labeled instances. GLAD also provides explanations which can improve the understanding of end-users about anomalies. Our experiments on synthetic and real-world data show the effectiveness of GLAD in learning the local relevance of ensemble members and discovering anomalies via label feedback.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1810.01403v4-abstract-full').style.display = 'none'; document.getElementById('1810.01403v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 July, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 October, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at the ICML-2020 Workshop on Human in the Loop Learning; 8 pages, 8 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1808.02123">arXiv:1808.02123</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1808.02123">pdf</a>, <a href="https://arxiv.org/format/1808.02123">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Structure Learning for Relational Logistic Regression: An Ensemble Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ramanan%2C+N">Nandini Ramanan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunapuli%2C+G">Gautam Kunapuli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khot%2C+T">Tushar Khot</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fatemi%2C+B">Bahare Fatemi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kazemi%2C+S+M">Seyed Mehran Kazemi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poole%2C+D">David Poole</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1808.02123v1-abstract-short" style="display: inline;">
        We consider the problem of learning Relational Logistic Regression (RLR). Unlike standard logistic regression, the features of RLRs are first-order formulae with associated weight vectors instead of scalar weights. We turn the problem of learning RLR to learning these vector-weighted formulae and develop a learning algorithm based on the recently successful functional-gradient boosting methods for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1808.02123v1-abstract-full').style.display = 'inline'; document.getElementById('1808.02123v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1808.02123v1-abstract-full" style="display: none;">
        We consider the problem of learning Relational Logistic Regression (RLR). Unlike standard logistic regression, the features of RLRs are first-order formulae with associated weight vectors instead of scalar weights. We turn the problem of learning RLR to learning these vector-weighted formulae and develop a learning algorithm based on the recently successful functional-gradient boosting methods for probabilistic logic models. We derive the functional gradients and show how weights can be learned simultaneously in an efficient manner. Our empirical evaluation on standard and novel data sets demonstrates the superiority of our approach over other methods for learning RLR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1808.02123v1-abstract-full').style.display = 'none'; document.getElementById('1808.02123v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 August, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1804.07404">arXiv:1804.07404</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1804.07404">pdf</a>, <a href="https://arxiv.org/format/1804.07404">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Preference-Guided Planning: An Active Elicitation Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Das%2C+M">Mayukh Das</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Odom%2C+P">Phillip Odom</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Islam%2C+M+R">Md. Rakibul Islam</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rao%2C+J">Janardhan Rao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Doppa"> Doppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roth%2C+D">Dan Roth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1804.07404v1-abstract-short" style="display: inline;">
        Planning with preferences has been employed extensively to quickly generate high-quality plans. However, it may be difficult for the human expert to supply this information without knowledge of the reasoning employed by the planner and the distribution of planning problems. We consider the problem of actively eliciting preferences from a human expert during the planning process. Specifically, we s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.07404v1-abstract-full').style.display = 'inline'; document.getElementById('1804.07404v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1804.07404v1-abstract-full" style="display: none;">
        Planning with preferences has been employed extensively to quickly generate high-quality plans. However, it may be difficult for the human expert to supply this information without knowledge of the reasoning employed by the planner and the distribution of planning problems. We consider the problem of actively eliciting preferences from a human expert during the planning process. Specifically, we study this problem in the context of the Hierarchical Task Network (HTN) planning framework as it allows easy interaction with the human. Our experimental results on several diverse planning domains show that the preferences gathered using the proposed approach improve the quality and speed of the planner, while reducing the burden on the human expert.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.07404v1-abstract-full').style.display = 'none'; document.getElementById('1804.07404v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Under Review at Knowledge-Based Systems (Elsevier); &#34;Extended Abstract&#34; accepted and to appear at AAMAS 2018</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1710.03297">arXiv:1710.03297</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1710.03297">pdf</a>, <a href="https://arxiv.org/format/1710.03297">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sum-Product Networks for Hybrid Domains
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Molina%2C+A">Alejandro Molina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vergari%2C+A">Antonio Vergari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Mauro%2C+N">Nicola Di Mauro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Esposito%2C+F">Floriana Esposito</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1710.03297v3-abstract-short" style="display: inline;">
        While all kinds of mixed data -from personal data, over panel and scientific data, to public and commercial data- are collected and stored, building probabilistic graphical models for these hybrid domains becomes more difficult. Users spend significant amounts of time in identifying the parametric form of the random variables (Gaussian, Poisson, Logit, etc.) involved and learning the mixed models.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.03297v3-abstract-full').style.display = 'inline'; document.getElementById('1710.03297v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1710.03297v3-abstract-full" style="display: none;">
        While all kinds of mixed data -from personal data, over panel and scientific data, to public and commercial data- are collected and stored, building probabilistic graphical models for these hybrid domains becomes more difficult. Users spend significant amounts of time in identifying the parametric form of the random variables (Gaussian, Poisson, Logit, etc.) involved and learning the mixed models. To make this difficult task easier, we propose the first trainable probabilistic deep architecture for hybrid domains that features tractable queries. It is based on Sum-Product Networks (SPNs) with piecewise polynomial leave distributions together with novel nonparametric decomposition and conditioning steps using the Hirschfeld-Gebelein-Rényi Maximum Correlation Coefficient. This relieves the user from deciding a-priori the parametric form of the random variables but is still expressive enough to effectively approximate any continuous distribution and permits efficient learning and inference. Our empirical evidence shows that the architecture, called Mixed SPNs, can indeed capture complex distributions across a wide range of hybrid domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.03297v3-abstract-full').style.display = 'none'; document.getElementById('1710.03297v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 November, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 October, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">16 Pages, 5 Figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1607.01050">arXiv:1607.01050</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1607.01050">pdf</a>, <a href="https://arxiv.org/format/1607.01050">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Application of Statistical Relational Learning to Hybrid Recommendation Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+S">Shuo Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Korayem%2C+M">Mohammed Korayem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=AlJadda%2C+K">Khalifeh AlJadda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Grainger%2C+T">Trey Grainger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1607.01050v1-abstract-short" style="display: inline;">
        Recommendation systems usually involve exploiting the relations among known features and content that describe items (content-based filtering) or the overlap of similar users who interacted with or rated the target item (collaborative filtering). To combine these two filtering approaches, current model-based hybrid recommendation systems typically require extensive feature engineering to construct&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.01050v1-abstract-full').style.display = 'inline'; document.getElementById('1607.01050v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1607.01050v1-abstract-full" style="display: none;">
        Recommendation systems usually involve exploiting the relations among known features and content that describe items (content-based filtering) or the overlap of similar users who interacted with or rated the target item (collaborative filtering). To combine these two filtering approaches, current model-based hybrid recommendation systems typically require extensive feature engineering to construct a user profile. Statistical Relational Learning (SRL) provides a straightforward way to combine the two approaches. However, due to the large scale of the data used in real world recommendation systems, little research exists on applying SRL models to hybrid recommendation systems, and essentially none of that research has been applied on real big-data-scale systems. In this paper, we proposed a way to adapt the state-of-the-art in SRL learning approaches to construct a real hybrid recommendation system. Furthermore, in order to satisfy a common requirement in recommendation systems (i.e. that false positives are more undesirable and therefore penalized more harshly than false negatives), our approach can also allow tuning the trade-off between the precision and recall of the system in a principled way. Our experimental results demonstrate the efficiency of our proposed approach as well as its improved performance on recommendation precision.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.01050v1-abstract-full').style.display = 'none'; document.getElementById('1607.01050v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 July, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Statistical Relational AI 2016</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1607.00424">arXiv:1607.00424</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1607.00424">pdf</a>, <a href="https://arxiv.org/format/1607.00424">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Relational Dependency Networks for Relation Extraction
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Viswanathan%2C+D">Dileep Viswanathan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soni%2C+A">Ameet Soni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shavlik%2C+J">Jude Shavlik</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1607.00424v1-abstract-short" style="display: inline;">
        We consider the task of KBP slot filling -- extracting relation information from newswire documents for knowledge base construction. We present our pipeline, which employs Relational Dependency Networks (RDNs) to learn linguistic patterns for relation extraction. Additionally, we demonstrate how several components such as weak supervision, word2vec features, joint learning and the use of human adv&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.00424v1-abstract-full').style.display = 'inline'; document.getElementById('1607.00424v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1607.00424v1-abstract-full" style="display: none;">
        We consider the task of KBP slot filling -- extracting relation information from newswire documents for knowledge base construction. We present our pipeline, which employs Relational Dependency Networks (RDNs) to learn linguistic patterns for relation extraction. Additionally, we demonstrate how several components such as weak supervision, word2vec features, joint learning and the use of human advice, can be incorporated in this relational framework. We evaluate the different components in the benchmark KBP 2015 task and show that RDNs effectively model a diverse set of features and perform competitively with current state-of-the-art relation extraction.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1607.00424v1-abstract-full').style.display = 'none'; document.getElementById('1607.00424v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 July, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In Proceedings of Sixth International Workshop on Statistical Relational AI at the 25th International Joint Conference on Artificial Intelligence (IJCAI)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1205.2637">arXiv:1205.2637</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1205.2637">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Counting Belief Propagation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kersting%2C+K">Kristian Kersting</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmadi%2C+B">Babak Ahmadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natarajan%2C+S">Sriraam Natarajan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1205.2637v1-abstract-short" style="display: inline;">
        A major benefit of graphical models is that most knowledge is captured in the model structure. Many models, however, produce inference problems with a lot of symmetries not reflected in the graphical structure and hence not exploitable by efficient inference techniques such as belief propagation (BP). In this paper, we present a new and simple BP algorithm, called counting BP, that exploits such a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1205.2637v1-abstract-full').style.display = 'inline'; document.getElementById('1205.2637v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1205.2637v1-abstract-full" style="display: none;">
        A major benefit of graphical models is that most knowledge is captured in the model structure. Many models, however, produce inference problems with a lot of symmetries not reflected in the graphical structure and hence not exploitable by efficient inference techniques such as belief propagation (BP). In this paper, we present a new and simple BP algorithm, called counting BP, that exploits such additional symmetries. Starting from a given factor graph, counting BP first constructs a compressed factor graph of clusternodes and clusterfactors, corresponding to sets of nodes and factors that are indistinguishable given the evidence. Then it runs a modified BP algorithm on the compressed graph that is equivalent to running BP on the original factor graph. Our experiments show that counting BP is applicable to a variety of important AI tasks such as (dynamic) relational models and boolean model counting, and that significant efficiency gains are obtainable, often by orders of magnitude.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1205.2637v1-abstract-full').style.display = 'none'; document.getElementById('1205.2637v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 May, 2012; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2012.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009)</span>
    </p>
    

    
      <p class="comments is-size-7">
        
          <span class="has-text-black-bis has-text-weight-semibold">Report number:</span>
          UAI-P-2009-PG-277-284
        

        

        
      </p>
    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>