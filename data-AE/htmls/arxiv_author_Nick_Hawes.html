<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;42 of 42 results for author: <span class="mathjax">Nick Hawes</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Nick Hawes">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Nick+Hawes&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Nick Hawes">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.21595">arXiv:2508.21595</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.21595">pdf</a>, <a href="https://arxiv.org/ps/2508.21595">ps</a>, <a href="https://arxiv.org/format/2508.21595">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=You%2C+Y">Yang You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schutz%2C+A">Alex Schutz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zhikun Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Skilton%2C+R">Robert Skilton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.21595v1-abstract-short" style="display: inline;">
        Many high-level multi-agent planning problems, including multi-robot navigation and path planning, can be effectively modeled using deterministic actions and observations.
  In this work, we focus on such domains and introduce the class of Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of Dec-POMDPs characterized by deterministic transitions and observations conditioned on&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.21595v1-abstract-full').style.display = 'inline'; document.getElementById('2508.21595v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.21595v1-abstract-full" style="display: none;">
        Many high-level multi-agent planning problems, including multi-robot navigation and path planning, can be effectively modeled using deterministic actions and observations.
  In this work, we focus on such domains and introduce the class of Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of Dec-POMDPs characterized by deterministic transitions and observations conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP Planning (IDPP). This method builds on the classic Joint Equilibrium Search for Policies framework and is specifically optimized to handle large-scale Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address efficiently.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.21595v1-abstract-full').style.display = 'none'; document.getElementById('2508.21595v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.03293">arXiv:2508.03293</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.03293">pdf</a>, <a href="https://arxiv.org/ps/2508.03293">ps</a>, <a href="https://arxiv.org/format/2508.03293">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enhancing Joint Human-AI Inference in Robot Missions: A Confidence-Based Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+D">Duc-An Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Colombatto%2C+C">Clara Colombatto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fleming%2C+S">Steve Fleming</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharyya%2C+R">Raunak Bhattacharyya</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.03293v1-abstract-short" style="display: inline;">
        Joint human-AI inference holds immense potential to improve outcomes in human-supervised robot missions. Current day missions are generally in the AI-assisted setting, where the human operator makes the final inference based on the AI recommendation. However, due to failures in human judgement on when to accept or reject the AI recommendation, complementarity is rarely achieved. We investigate joi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03293v1-abstract-full').style.display = 'inline'; document.getElementById('2508.03293v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.03293v1-abstract-full" style="display: none;">
        Joint human-AI inference holds immense potential to improve outcomes in human-supervised robot missions. Current day missions are generally in the AI-assisted setting, where the human operator makes the final inference based on the AI recommendation. However, due to failures in human judgement on when to accept or reject the AI recommendation, complementarity is rarely achieved. We investigate joint human-AI inference where the inference made with higher confidence is selected. Through a user study with N=100 participants on a representative simulated robot teleoperation task, specifically studying the inference of robots&#39; control delays we show that: a) Joint inference accuracy is higher and its extent is regulated by the confidence calibration of the AI agent, and b) Humans change their inferences based on AI recommendations and the extent and direction of this change is also regulated by the confidence calibration of the AI agent. Interestingly, our results show that pairing poorly-calibrated AI-DSS with humans hurts performance instead of helping the team, reiterating the need for AI-based decision support systems with good metacognitive sensitivity. To the best of our knowledge, our study presents the first application of a maximum-confidence-based heuristic for joint human-AI inference within a simulated robot teleoperation task.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03293v1-abstract-full').style.display = 'none'; document.getElementById('2508.03293v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.20951">arXiv:2507.20951</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.20951">pdf</a>, <a href="https://arxiv.org/ps/2507.20951">ps</a>, <a href="https://arxiv.org/format/2507.20951">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Partially Observable Monte-Carlo Graph Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=You%2C+Y">Yang You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Thomas%2C+V">Vincent Thomas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schutz%2C+A">Alex Schutz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Skilton%2C+R">Robert Skilton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buffet%2C+O">Olivier Buffet</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.20951v1-abstract-short" style="display: inline;">
        Currently, large partially observable Markov decision processes (POMDPs) are often solved by sampling-based online methods which interleave planning and execution phases. However, a pre-computed offline policy is more desirable in POMDP applications with time or energy constraints. But previous offline algorithms are not able to scale up to large POMDPs. In this article, we propose a new sampling-&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20951v1-abstract-full').style.display = 'inline'; document.getElementById('2507.20951v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.20951v1-abstract-full" style="display: none;">
        Currently, large partially observable Markov decision processes (POMDPs) are often solved by sampling-based online methods which interleave planning and execution phases. However, a pre-computed offline policy is more desirable in POMDP applications with time or energy constraints. But previous offline algorithms are not able to scale up to large POMDPs. In this article, we propose a new sampling-based algorithm, the partially observable Monte-Carlo graph search (POMCGS) to solve large POMDPs offline. Different from many online POMDP methods, which progressively develop a tree while performing (Monte-Carlo) simulations, POMCGS folds this search tree on the fly to construct a policy graph, so that computations can be drastically reduced, and users can analyze and validate the policy prior to embedding and executing it. Moreover, POMCGS, together with action progressive widening and observation clustering methods provided in this article, is able to address certain continuous POMDPs. Through experiments, we demonstrate that POMCGS can generate policies on the most challenging POMDPs, which cannot be computed by previous offline algorithms, and these policies&#39; values are competitive compared with the state-of-the-art online POMDP algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20951v1-abstract-full').style.display = 'none'; document.getElementById('2507.20951v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To be published in Proceedings of ICAPS 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2505.00596">arXiv:2505.00596</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2505.00596">pdf</a>, <a href="https://arxiv.org/format/2505.00596">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Finite-State Controller Based Offline Solver for Deterministic POMDPs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Schutz%2C+A">Alex Schutz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+Y">Yang You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mattamala%2C+M">Matias Mattamala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caliskanelli%2C+I">Ipek Caliskanelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2505.00596v1-abstract-short" style="display: inline;">
        Deterministic partially observable Markov decision processes (DetPOMDPs) often arise in planning problems where the agent is uncertain about its environmental state but can act and observe deterministically. In this paper, we propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI) algorithm for DetPOMDPs, which builds policies in the form of finite-state controllers (FSCs). DetMCV&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.00596v1-abstract-full').style.display = 'inline'; document.getElementById('2505.00596v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2505.00596v1-abstract-full" style="display: none;">
        Deterministic partially observable Markov decision processes (DetPOMDPs) often arise in planning problems where the agent is uncertain about its environmental state but can act and observe deterministically. In this paper, we propose DetMCVI, an adaptation of the Monte Carlo Value Iteration (MCVI) algorithm for DetPOMDPs, which builds policies in the form of finite-state controllers (FSCs). DetMCVI solves large problems with a high success rate, outperforming existing baselines for DetPOMDPs. We also verify the performance of the algorithm in a real-world mobile robot forest mapping scenario.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.00596v1-abstract-full').style.display = 'none'; document.getElementById('2505.00596v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 May, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 6 figures. Appendix attached. To be published in Proceedings of IJCAI 2025. For code see http://github.com/ori-goals/DetMCVI</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.8; I.2.9
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.20887">arXiv:2504.20887</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.20887">pdf</a>, <a href="https://arxiv.org/ps/2504.20887">ps</a>, <a href="https://arxiv.org/format/2504.20887">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Return Capping: Sample-Efficient CVaR Policy Gradient Optimisation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mead%2C+H">Harry Mead</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Costen%2C+C">Clarissa Costen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.20887v2-abstract-short" style="display: inline;">
        When optimising for conditional value at risk (CVaR) using policy gradients (PG), current methods rely on discarding a large proportion of trajectories, resulting in poor sample efficiency. We propose a reformulation of the CVaR optimisation problem by capping the total return of trajectories used in training, rather than simply discarding them, and show that this is equivalent to the original pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.20887v2-abstract-full').style.display = 'inline'; document.getElementById('2504.20887v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.20887v2-abstract-full" style="display: none;">
        When optimising for conditional value at risk (CVaR) using policy gradients (PG), current methods rely on discarding a large proportion of trajectories, resulting in poor sample efficiency. We propose a reformulation of the CVaR optimisation problem by capping the total return of trajectories used in training, rather than simply discarding them, and show that this is equivalent to the original problem if the cap is set appropriately. We show, with empirical results in an number of environments, that this reformulation of the problem results in consistently improved performance compared to baselines. We have made all our code available here: https://github.com/HarryMJMead/cvar-return-capping.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.20887v2-abstract-full').style.display = 'none'; document.getElementById('2504.20887v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 July, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 April, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.00698">arXiv:2504.00698</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.00698">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Command A: An Enterprise-Ready Large Language Model
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cohere%2C+T">Team Cohere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=%3A"> :</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aakanksha"> Aakanksha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmadian%2C+A">Arash Ahmadian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmed%2C+M">Marwan Ahmed</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alammar%2C+J">Jay Alammar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alizadeh%2C+M">Milad Alizadeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alnumay%2C+Y">Yazeed Alnumay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Althammer%2C+S">Sophia Althammer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Arkhangorodsky%2C+A">Arkady Arkhangorodsky</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aryabumi%2C+V">Viraat Aryabumi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aumiller%2C+D">Dennis Aumiller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Avalos%2C+R">Raphaël Avalos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aviv%2C+Z">Zahara Aviv</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bae%2C+S">Sammie Bae</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baji%2C+S">Saurabh Baji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barbet%2C+A">Alexandre Barbet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bartolo%2C+M">Max Bartolo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bebensee%2C+B">Björn Bebensee</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Beladia%2C+N">Neeral Beladia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Beller-Morales%2C+W">Walter Beller-Morales</a>, 
      
      <a href="/search/?searchtype=author&amp;query=B%C3%A9rard%2C+A">Alexandre Bérard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berneshawi%2C+A">Andrew Berneshawi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bialas%2C+A">Anna Bialas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Blunsom%2C+P">Phil Blunsom</a>
      , et al. (205 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.00698v2-abstract-short" style="display: inline;">
        In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Genera&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.00698v2-abstract-full').style.display = 'inline'; document.getElementById('2504.00698v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.00698v2-abstract-full" style="display: none;">
        In this report we describe the development of Command A, a powerful large language model purpose-built to excel at real-world enterprise use cases. Command A is an agent-optimised and multilingual-capable model, with support for 23 languages of global business, and a novel hybrid architecture balancing efficiency with top of the range performance. It offers best-in-class Retrieval Augmented Generation (RAG) capabilities with grounding and tool use to automate sophisticated business processes. These abilities are achieved through a decentralised training approach, including self-refinement algorithms and model merging techniques. We also include results for Command R7B which shares capability and architectural similarities to Command A. Weights for both models have been released for research purposes. This technical report details our original training pipeline and presents an extensive evaluation of our models across a suite of enterprise-relevant tasks and public benchmarks, demonstrating excellent performance and efficiency.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.00698v2-abstract-full').style.display = 'none'; document.getElementById('2504.00698v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 April, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 April, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">55 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.20521">arXiv:2503.20521</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.20521">pdf</a>, <a href="https://arxiv.org/format/2503.20521">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Decremental Dynamics Planning for Robot Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Y">Yuanjie Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+T">Tong Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+L">Linji Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+X">Xuesu Xiao</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.20521v1-abstract-short" style="display: inline;">
        Most, if not all, robot navigation systems employ a decomposed planning framework that includes global and local planning. To trade-off onboard computation and plan quality, current systems have to limit all robot dynamics considerations only within the local planner, while leveraging an extremely simplified robot representation (e.g., a point-mass holonomic model without dynamics) in the global l&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.20521v1-abstract-full').style.display = 'inline'; document.getElementById('2503.20521v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.20521v1-abstract-full" style="display: none;">
        Most, if not all, robot navigation systems employ a decomposed planning framework that includes global and local planning. To trade-off onboard computation and plan quality, current systems have to limit all robot dynamics considerations only within the local planner, while leveraging an extremely simplified robot representation (e.g., a point-mass holonomic model without dynamics) in the global level. However, such an artificial decomposition based on either full or zero consideration of robot dynamics can lead to gaps between the two levels, e.g., a global path based on a holonomic point-mass model may not be realizable by a non-holonomic robot, especially in highly constrained obstacle environments. Motivated by such a limitation, we propose a novel paradigm, Decremental Dynamics Planning that integrates dynamic constraints into the entire planning process, with a focus on high-fidelity dynamics modeling at the beginning and a gradual fidelity reduction as the planning progresses. To validate the effectiveness of this paradigm, we augment three different planners with DDP and show overall improved planning performance. We also develop a new DDP-based navigation system, which achieves first place in the simulation phase of the 2025 BARN Challenge. Both simulated and physical experiments validate DDP&#39;s hypothesized benefits.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.20521v1-abstract-full').style.display = 'none'; document.getElementById('2503.20521v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages. 2025 International Conference on Intelligent Robots and Systems (IROS 2025)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.15510">arXiv:2503.15510</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.15510">pdf</a>, <a href="https://arxiv.org/format/2503.15510">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint Decision-Making in Robot Teleoperation: When are Two Heads Better Than One?
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nguyen%2C+D">Duc-An Nguyen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharyya%2C+R">Raunak Bhattacharyya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Colombatto%2C+C">Clara Colombatto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fleming%2C+S">Steve Fleming</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.15510v1-abstract-short" style="display: inline;">
        Operators working with robots in safety-critical domains have to make decisions under uncertainty, which remains a challenging problem for a single human operator. An open question is whether two human operators can make better decisions jointly, as compared to a single operator alone. While prior work has shown that two heads are better than one, such studies have been mostly limited to static an&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.15510v1-abstract-full').style.display = 'inline'; document.getElementById('2503.15510v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.15510v1-abstract-full" style="display: none;">
        Operators working with robots in safety-critical domains have to make decisions under uncertainty, which remains a challenging problem for a single human operator. An open question is whether two human operators can make better decisions jointly, as compared to a single operator alone. While prior work has shown that two heads are better than one, such studies have been mostly limited to static and passive tasks. We investigate joint decision-making in a dynamic task involving humans teleoperating robots. We conduct a human-subject experiment with $N=100$ participants where each participant performed a navigation task with two mobiles robots in simulation. We find that joint decision-making through confidence sharing improves dyad performance beyond the better-performing individual (p&lt;0.0001). Further, we find that the extent of this benefit is regulated both by the skill level of each individual, as well as how well-calibrated their confidence estimates are. Finally, we present findings on characterising the human-human dyad&#39;s confidence calibration based on the individuals constituting the dyad. Our findings demonstrate for the first time that two heads are better than one, even on a spatiotemporal task which includes active operator control of robots.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.15510v1-abstract-full').style.display = 'none'; document.getElementById('2503.15510v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To be published in the 2025 20th ACM/IEEE International Conference on Human-Robot Interaction (HRI)</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.9
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.14557">arXiv:2503.14557</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.14557">pdf</a>, <a href="https://arxiv.org/format/2503.14557">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Generating Causal Explanations of Vehicular Agent Behavioural Interactions with Learnt Reward Profiles
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Howard%2C+R">Rhys Howard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.14557v1-abstract-short" style="display: inline;">
        Transparency and explainability are important features that responsible autonomous vehicles should possess, particularly when interacting with humans, and causal reasoning offers a strong basis to provide these qualities. However, even if one assumes agents act to maximise some concept of reward, it is difficult to make accurate causal inferences of agent planning without capturing what is of impo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.14557v1-abstract-full').style.display = 'inline'; document.getElementById('2503.14557v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.14557v1-abstract-full" style="display: none;">
        Transparency and explainability are important features that responsible autonomous vehicles should possess, particularly when interacting with humans, and causal reasoning offers a strong basis to provide these qualities. However, even if one assumes agents act to maximise some concept of reward, it is difficult to make accurate causal inferences of agent planning without capturing what is of importance to the agent. Thus our work aims to learn a weighting of reward metrics for agents such that explanations for agent interactions can be causally inferred. We validate our approach quantitatively and qualitatively across three real-world driving datasets, demonstrating a functional improvement over previous methods and competitive performance across evaluation metrics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.14557v1-abstract-full').style.display = 'none'; document.getElementById('2503.14557v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 Pages, 5 Figures, To be published in the Proceedings of the 2025 IEEE International Conference on Robotics &amp; Automation, Initial upload of accepted paper</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.0; I.2.6; I.2.9; I.2.11; I.6.0
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.10370">arXiv:2503.10370</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.10370">pdf</a>, <a href="https://arxiv.org/format/2503.10370">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LUMOS: Language-Conditioned Imitation Learning with World Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nematollahi%2C+I">Iman Nematollahi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=DeMoss%2C+B">Branton DeMoss</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chandra%2C+A+L">Akshay L Chandra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burgard%2C+W">Wolfram Burgard</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.10370v1-abstract-short" style="display: inline;">
        We introduce LUMOS, a language-conditioned multi-task imitation learning framework for robotics. LUMOS learns skills by practicing them over many long-horizon rollouts in the latent space of a learned world model and transfers these skills zero-shot to a real robot. By learning on-policy in the latent space of the learned world model, our algorithm mitigates policy-induced distribution shift which&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.10370v1-abstract-full').style.display = 'inline'; document.getElementById('2503.10370v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.10370v1-abstract-full" style="display: none;">
        We introduce LUMOS, a language-conditioned multi-task imitation learning framework for robotics. LUMOS learns skills by practicing them over many long-horizon rollouts in the latent space of a learned world model and transfers these skills zero-shot to a real robot. By learning on-policy in the latent space of the learned world model, our algorithm mitigates policy-induced distribution shift which most offline imitation learning methods suffer from. LUMOS learns from unstructured play data with fewer than 1% hindsight language annotations but is steerable with language commands at test time. We achieve this coherent long-horizon performance by combining latent planning with both image- and language-based hindsight goal relabeling during training, and by optimizing an intrinsic reward defined in the latent space of the world model over multiple time steps, effectively reducing covariate shift. In experiments on the difficult long-horizon CALVIN benchmark, LUMOS outperforms prior learning-based methods with comparable approaches on chained multi-task evaluations. To the best of our knowledge, we are the first to learn a language-conditioned continuous visuomotor control for a real-world robot within an offline world model. Videos, dataset and code are available at http://lumos.cs.uni-freiburg.de.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.10370v1-abstract-full').style.display = 'none'; document.getElementById('2503.10370v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 2025 IEEE International Conference on Robotics and Automation (ICRA)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.05792">arXiv:2503.05792</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.05792">pdf</a>, <a href="https://arxiv.org/format/2503.05792">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ro-To-Go! Robust Reactive Control with Signal Temporal Logic
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ilyes%2C+R">Roland Ilyes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bruderm%C3%BCller%2C+L">Lara Brudermüller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.05792v2-abstract-short" style="display: inline;">
        Signal Temporal Logic (STL) robustness is a common objective for optimal robot control, but its dependence on history limits the robot&#39;s decision-making capabilities when used in Model Predictive Control (MPC) approaches. In this work, we introduce Signal Temporal Logic robustness-to-go (Ro-To-Go), a new quantitative semantics for the logic that isolates the contributions of suffix trajectories. W&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.05792v2-abstract-full').style.display = 'inline'; document.getElementById('2503.05792v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.05792v2-abstract-full" style="display: none;">
        Signal Temporal Logic (STL) robustness is a common objective for optimal robot control, but its dependence on history limits the robot&#39;s decision-making capabilities when used in Model Predictive Control (MPC) approaches. In this work, we introduce Signal Temporal Logic robustness-to-go (Ro-To-Go), a new quantitative semantics for the logic that isolates the contributions of suffix trajectories. We prove its relationship to formula progression for Metric Temporal Logic, and show that the robustness-to-go depends only on the suffix trajectory and progressed formula. We implement robustness-to-go as the objective in an MPC algorithm and use formula progression to efficiently evaluate it online. We test the algorithm in simulation and compare it to MPC using traditional STL robustness. Our experiments show that using robustness-to-go results in a higher success rate.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.05792v2-abstract-full').style.display = 'none'; document.getElementById('2503.05792v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 February, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.09810">arXiv:2412.09810</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.09810">pdf</a>, <a href="https://arxiv.org/ps/2412.09810">ps</a>, <a href="https://arxiv.org/format/2412.09810">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1016/j.physd.2025.134859">10.1016/j.physd.2025.134859 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Complexity Dynamics of Grokking
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=DeMoss%2C+B">Branton DeMoss</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sapora%2C+S">Silvia Sapora</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Foerster%2C+J">Jakob Foerster</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.09810v2-abstract-short" style="display: inline;">
        We demonstrate the existence of a complexity phase transition in neural networks by studying the grokking phenomenon, where networks suddenly transition from memorization to generalization long after overfitting their training data. To characterize this phase transition, we introduce a theoretical framework for measuring complexity based on rate-distortion theory and Kolmogorov complexity, which c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.09810v2-abstract-full').style.display = 'inline'; document.getElementById('2412.09810v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.09810v2-abstract-full" style="display: none;">
        We demonstrate the existence of a complexity phase transition in neural networks by studying the grokking phenomenon, where networks suddenly transition from memorization to generalization long after overfitting their training data. To characterize this phase transition, we introduce a theoretical framework for measuring complexity based on rate-distortion theory and Kolmogorov complexity, which can be understood as principled lossy compression for networks. We find that properly regularized networks exhibit a sharp phase transition: complexity rises during memorization, then falls as the network discovers a simpler underlying pattern that generalizes. In contrast, unregularized networks remain trapped in a high-complexity memorization phase. We establish an explicit connection between our complexity measure and generalization bounds, providing a theoretical foundation for the link between lossy compression and generalization. Our framework achieves compression ratios 30-40x better than naïve approaches, enabling precise tracking of complexity dynamics. Finally, we introduce a regularization method based on spectral entropy that encourages networks toward low-complexity representations by penalizing their intrinsic dimension.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.09810v2-abstract-full').style.display = 'none'; document.getElementById('2412.09810v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 December, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Physica D: Nonlinear Phenomena 482 (2025) 134859
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.15099">arXiv:2408.15099</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.15099">pdf</a>, <a href="https://arxiv.org/format/2408.15099">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        No Regrets: Investigating and Improving Regret Approximations for Curriculum Discovery
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rutherford%2C+A">Alexander Rutherford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Beukman%2C+M">Michael Beukman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Willi%2C+T">Timon Willi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Foerster%2C+J">Jakob Foerster</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.15099v3-abstract-short" style="display: inline;">
        What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning. In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula promise to enable agents to be robust to in- and out-of-distribution tasks. This work investigates how existing UED methods select&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.15099v3-abstract-full').style.display = 'inline'; document.getElementById('2408.15099v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.15099v3-abstract-full" style="display: none;">
        What data or environments to use for training to improve downstream performance is a longstanding and very topical question in reinforcement learning. In particular, Unsupervised Environment Design (UED) methods have gained recent attention as their adaptive curricula promise to enable agents to be robust to in- and out-of-distribution tasks. This work investigates how existing UED methods select training environments, focusing on task prioritisation metrics. Surprisingly, despite methods aiming to maximise regret in theory, the practical approximations do not correlate with regret but with success rate. As a result, a significant portion of an agent&#39;s experience comes from environments it has already mastered, offering little to no contribution toward enhancing its abilities. Put differently, current methods fail to predict intuitive measures of ``learnability.&#39;&#39; Specifically, they are unable to consistently identify those scenarios that the agent can sometimes solve, but not always. Based on our analysis, we develop a method that directly trains on scenarios with high learnability. This simple and intuitive approach outperforms existing UED methods in several binary-outcome environments, including the standard domain of Minigrid and a novel setting closely inspired by a real-world robotics problem. We further introduce a new adversarial evaluation procedure for directly measuring robustness, closely mirroring the conditional value at risk (CVaR). We open-source all our code and present visualisations of final policies here: https://github.com/amacrutherford/sampling-for-learnability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.15099v3-abstract-full').style.display = 'none'; document.getElementById('2408.15099v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 October, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 27 August, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.08785">arXiv:2408.08785</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.08785">pdf</a>, <a href="https://arxiv.org/format/2408.08785">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Transparency Paradox? Investigating the Impact of Explanation Specificity and Autonomous Vehicle Perceptual Inaccuracies on Passengers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Omeiza%2C+D">Daniel Omeiza</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharyya%2C+R">Raunak Bhattacharyya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jirotka%2C+M">Marina Jirotka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.08785v1-abstract-short" style="display: inline;">
        Transparency in automated systems could be afforded through the provision of intelligible explanations. While transparency is desirable, might it lead to catastrophic outcomes (such as anxiety), that could outweigh its benefits? It&#39;s quite unclear how the specificity of explanations (level of transparency) influences recipients, especially in autonomous driving (AD). In this work, we examined the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.08785v1-abstract-full').style.display = 'inline'; document.getElementById('2408.08785v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.08785v1-abstract-full" style="display: none;">
        Transparency in automated systems could be afforded through the provision of intelligible explanations. While transparency is desirable, might it lead to catastrophic outcomes (such as anxiety), that could outweigh its benefits? It&#39;s quite unclear how the specificity of explanations (level of transparency) influences recipients, especially in autonomous driving (AD). In this work, we examined the effects of transparency mediated through varying levels of explanation specificity in AD. We first extended a data-driven explainer model by adding a rule-based option for explanation generation in AD, and then conducted a within-subject lab study with 39 participants in an immersive driving simulator to study the effect of the resulting explanations. Specifically, our investigation focused on: (1) how different types of explanations (specific vs. abstract) affect passengers&#39; perceived safety, anxiety, and willingness to take control of the vehicle when the vehicle perception system makes erroneous predictions; and (2) the relationship between passengers&#39; behavioural cues and their feelings during the autonomous drives. Our findings showed that passengers felt safer with specific explanations when the vehicle&#39;s perception system had minimal errors, while abstract explanations that hid perception errors led to lower feelings of safety. Anxiety levels increased when specific explanations revealed perception system errors (high transparency). We found no significant link between passengers&#39; visual patterns and their anxiety levels. Our study suggests that passengers prefer clear and specific explanations (high transparency) when they originate from autonomous vehicles (AVs) with optimal perceptual accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.08785v1-abstract-full').style.display = 'none'; document.getElementById('2408.08785v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 August, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to Transportation Research Part F: Traffic Psychology and Behaviour. arXiv admin note: text overlap with arXiv:2307.00633</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.12785">arXiv:2404.12785</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.12785">pdf</a>, <a href="https://arxiv.org/format/2404.12785">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AutoInspect: Towards Long-Term Autonomous Industrial Inspection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Staniaszek%2C+M">Michal Staniaszek</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Flatscher%2C+T">Tobit Flatscher</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rowell%2C+J">Joseph Rowell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Niu%2C+H">Hanlin Niu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+W">Wenxing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+Y">Yang You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Skilton%2C+R">Robert Skilton</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fallon%2C+M">Maurice Fallon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.12785v3-abstract-short" style="display: inline;">
        We give an overview of AutoInspect, a ROS-based software system for robust and extensible mission-level autonomy. Over the past three years AutoInspect has been deployed in a variety of environments, including at a mine, a chemical plant, a mock oil rig, decommissioned nuclear power plants, and a fusion reactor for durations ranging from hours to weeks. The system combines robust mapping and local&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.12785v3-abstract-full').style.display = 'inline'; document.getElementById('2404.12785v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.12785v3-abstract-full" style="display: none;">
        We give an overview of AutoInspect, a ROS-based software system for robust and extensible mission-level autonomy. Over the past three years AutoInspect has been deployed in a variety of environments, including at a mine, a chemical plant, a mock oil rig, decommissioned nuclear power plants, and a fusion reactor for durations ranging from hours to weeks. The system combines robust mapping and localisation with graph-based autonomous navigation, mission execution, and scheduling to achieve a complete autonomous inspection system. The time from arrival at a new site to autonomous mission execution can be under an hour. It is deployed on a Boston Dynamics Spot robot using a custom sensing and compute payload called Frontier. In this work we go into detail of the system&#39;s performance in two long-term deployments of 49 days at a robotics test facility, and 35 days at the Joint European Torus (JET) fusion reactor in Oxfordshire, UK.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.12785v3-abstract-full').style.display = 'none'; document.getElementById('2404.12785v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 19 April, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to the IEEE ICRA Workshop on Field Robotics 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.10446">arXiv:2404.10446</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.10446">pdf</a>, <a href="https://arxiv.org/format/2404.10446">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Watching Grass Grow: Long-term Visual Navigation and Mission Planning for Autonomous Biodiversity Monitoring
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gadd%2C+M">Matthew Gadd</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Martini%2C+D">Daniele De Martini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pitt%2C+L">Luke Pitt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tubby%2C+W">Wayne Tubby</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Towlson%2C+M">Matthew Towlson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Prahacs%2C+C">Chris Prahacs</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bartlett%2C+O">Oliver Bartlett</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jackson%2C+J">John Jackson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qi%2C+M">Man Qi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Newman%2C+P">Paul Newman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hector%2C+A">Andrew Hector</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Salguero-G%C3%B3mez%2C+R">Roberto Salguero-Gómez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.10446v2-abstract-short" style="display: inline;">
        We describe a challenging robotics deployment in a complex ecosystem to monitor a rich plant community. The study site is dominated by dynamic grassland vegetation and is thus visually ambiguous and liable to drastic appearance change over the course of a day and especially through the growing season. This dynamism and complexity in appearance seriously impact the stability of the robotics platfor&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.10446v2-abstract-full').style.display = 'inline'; document.getElementById('2404.10446v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.10446v2-abstract-full" style="display: none;">
        We describe a challenging robotics deployment in a complex ecosystem to monitor a rich plant community. The study site is dominated by dynamic grassland vegetation and is thus visually ambiguous and liable to drastic appearance change over the course of a day and especially through the growing season. This dynamism and complexity in appearance seriously impact the stability of the robotics platform, as localisation is a foundational part of that control loop, and so routes must be carefully taught and retaught until autonomy is robust and repeatable. Our system is demonstrated over a 6-week period monitoring the response of grass species to experimental climate change manipulations. We also discuss the applicability of our pipeline to monitor biodiversity in other complex natural settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.10446v2-abstract-full').style.display = 'none'; document.getElementById('2404.10446v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 May, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 April, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">to be presented at the Workshop on Field Robotics - ICRA 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.07732">arXiv:2404.07732</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.07732">pdf</a>, <a href="https://arxiv.org/format/2404.07732">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Monte Carlo Tree Search with Boltzmann Exploration
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Painter%2C+M">Michael Painter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.07732v1-abstract-short" style="display: inline;">
        Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound applied to Trees (UCT), are instrumental to automated planning techniques. However, UCT can be slow to explore an optimal action when it initially appears inferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the maximum entropy principle into an MCTS approach, utilising Boltzmann policies to sample action&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.07732v1-abstract-full').style.display = 'inline'; document.getElementById('2404.07732v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.07732v1-abstract-full" style="display: none;">
        Monte-Carlo Tree Search (MCTS) methods, such as Upper Confidence Bound applied to Trees (UCT), are instrumental to automated planning techniques. However, UCT can be slow to explore an optimal action when it initially appears inferior to other actions. Maximum ENtropy Tree-Search (MENTS) incorporates the maximum entropy principle into an MCTS approach, utilising Boltzmann policies to sample actions, naturally encouraging more exploration. In this paper, we highlight a major limitation of MENTS: optimal actions for the maximum entropy objective do not necessarily correspond to optimal actions for the original objective. We introduce two algorithms, Boltzmann Tree Search (BTS) and Decaying ENtropy Tree-Search (DENTS), that address these limitations and preserve the benefits of Boltzmann policies, such as allowing actions to be sampled faster by using the Alias method. Our empirical analysis shows that our algorithms show consistent high performance across several benchmark domains, including the game of Go.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.07732v1-abstract-full').style.display = 'none'; document.getElementById('2404.07732v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Camera ready version of NeurIPS2023 paper</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Advances in Neural Information Processing Systems 36 (2024)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.02795">arXiv:2404.02795</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.02795">pdf</a>, <a href="https://arxiv.org/format/2404.02795">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Robust Pushing: Exploiting Quasi-static Belief Dynamics and Contact-informed Optimization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jankowski%2C+J">Julius Jankowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bruderm%C3%BCller%2C+L">Lara Brudermüller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Calinon%2C+S">Sylvain Calinon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.02795v2-abstract-short" style="display: inline;">
        Non-prehensile manipulation such as pushing is typically subject to uncertain, non-smooth dynamics. However, modeling the uncertainty of the dynamics typically results in intractable belief dynamics, making data-efficient planning under uncertainty difficult. This article focuses on the problem of efficiently generating robust open-loop pushing plans. First, we investigate how the belief over obje&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.02795v2-abstract-full').style.display = 'inline'; document.getElementById('2404.02795v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.02795v2-abstract-full" style="display: none;">
        Non-prehensile manipulation such as pushing is typically subject to uncertain, non-smooth dynamics. However, modeling the uncertainty of the dynamics typically results in intractable belief dynamics, making data-efficient planning under uncertainty difficult. This article focuses on the problem of efficiently generating robust open-loop pushing plans. First, we investigate how the belief over object configurations propagates through quasi-static contact dynamics. We exploit the simplified dynamics to predict the variance of the object configuration without sampling from a perturbation distribution. In a sampling-based trajectory optimization algorithm, the gain of the variance is constrained in order to enforce robustness of the plan. Second, we propose an informed trajectory sampling mechanism for drawing robot trajectories that are likely to make contact with the object. This sampling mechanism is shown to significantly improve chances of finding robust solutions, especially when making-and-breaking contacts is required. We demonstrate that the proposed approach is able to synthesize bi-manual pushing trajectories, resulting in successful long-horizon pushing maneuvers without exteroceptive feedback such as vision or tactile feedback. We furthermore deploy the proposed approach in a model-predictive control scheme, demonstrating additional robustness against unmodeled perturbations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.02795v2-abstract-full').style.display = 'none'; document.getElementById('2404.02795v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 June, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 3 April, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">submitted to the International Journal of Robotics Research (IJRR)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.01370">arXiv:2402.01370</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.01370">pdf</a>, <a href="https://arxiv.org/format/2402.01370">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CC-VPSTO: Chance-Constrained Via-Point-based Stochastic Trajectory Optimisation for Safe and Efficient Online Robot Motion Planning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bruderm%C3%BCller%2C+L">Lara Brudermüller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+G">Guillaume Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jankowski%2C+J">Julius Jankowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharyya%2C+R">Raunak Bhattacharyya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jungers%2C+R">Raphaël Jungers</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.01370v3-abstract-short" style="display: inline;">
        Safety in the face of uncertainty is a key challenge in robotics. We introduce a real-time capable framework to generate safe and task-efficient robot motions for stochastic control problems. We frame this as a chance-constrained optimisation problem constraining the probability of the controlled system to violate a safety constraint to be below a set threshold. To estimate this probability we pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.01370v3-abstract-full').style.display = 'inline'; document.getElementById('2402.01370v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.01370v3-abstract-full" style="display: none;">
        Safety in the face of uncertainty is a key challenge in robotics. We introduce a real-time capable framework to generate safe and task-efficient robot motions for stochastic control problems. We frame this as a chance-constrained optimisation problem constraining the probability of the controlled system to violate a safety constraint to be below a set threshold. To estimate this probability we propose a Monte--Carlo approximation. We suggest several ways to construct the problem given a fixed number of uncertainty samples, such that it is a reliable over-approximation of the original problem, i.e. any solution to the sample-based problem adheres to the original chance-constraint with high confidence. To solve the resulting problem, we integrate it into our motion planner VP-STO and name the enhanced framework Chance-Constrained (CC)-VPSTO. The strengths of our approach lie in i) its generality, without assumptions on the underlying uncertainty distribution, system dynamics, cost function, or the form of inequality constraints; and ii) its applicability to MPC-settings. We demonstrate the validity and efficiency of our approach on both simulation and real-world robot experiments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.01370v3-abstract-full').style.display = 'none'; document.getElementById('2402.01370v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 April, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 February, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">17 pages, 11 figures, submitted to IEEE Transactions on Robotics</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.10090">arXiv:2311.10090</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.10090">pdf</a>, <a href="https://arxiv.org/format/2311.10090">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        JaxMARL: Multi-Agent RL Environments and Algorithms in JAX
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rutherford%2C+A">Alexander Rutherford</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ellis%2C+B">Benjamin Ellis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gallici%2C+M">Matteo Gallici</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cook%2C+J">Jonathan Cook</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lupu%2C+A">Andrei Lupu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ingvarsson%2C+G">Gardar Ingvarsson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Willi%2C+T">Timon Willi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hammond%2C+R">Ravi Hammond</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Khan%2C+A">Akbir Khan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=de+Witt%2C+C+S">Christian Schroeder de Witt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Souly%2C+A">Alexandra Souly</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bandyopadhyay%2C+S">Saptarashmi Bandyopadhyay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Samvelyan%2C+M">Mikayel Samvelyan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+M">Minqi Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lange%2C+R+T">Robert Tjarko Lange</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Whiteson%2C+S">Shimon Whiteson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rocktaschel%2C+T">Tim Rocktaschel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+C">Chris Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Foerster%2C+J+N">Jakob Nicolaus Foerster</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.10090v5-abstract-short" style="display: inline;">
        Benchmarks are crucial in the development of machine learning algorithms, with available environments significantly influencing reinforcement learning (RL) research. Traditionally, RL environments run on the CPU, which limits their scalability with typical academic compute. However, recent advancements in JAX have enabled the wider use of hardware acceleration, enabling massively parallel RL train&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.10090v5-abstract-full').style.display = 'inline'; document.getElementById('2311.10090v5-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.10090v5-abstract-full" style="display: none;">
        Benchmarks are crucial in the development of machine learning algorithms, with available environments significantly influencing reinforcement learning (RL) research. Traditionally, RL environments run on the CPU, which limits their scalability with typical academic compute. However, recent advancements in JAX have enabled the wider use of hardware acceleration, enabling massively parallel RL training pipelines and environments. While this has been successfully applied to single-agent RL, it has not yet been widely adopted for multi-agent scenarios. In this paper, we present JaxMARL, the first open-source, Python-based library that combines GPU-enabled efficiency with support for a large number of commonly used MARL environments and popular baseline algorithms. Our experiments show that, in terms of wall clock time, our JAX-based training pipeline is around 14 times faster than existing approaches, and up to 12500x when multiple training runs are vectorized. This enables efficient and thorough evaluations, potentially alleviating the evaluation crisis in the field. We also introduce and benchmark SMAX, a JAX-based approximate reimplementation of the popular StarCraft Multi-Agent Challenge, which removes the need to run the StarCraft II game engine. This not only enables GPU acceleration, but also provides a more flexible MARL environment, unlocking the potential for self-play, meta-learning, and other future applications in MARL. The code is available at https://github.com/flairox/jaxmarl.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.10090v5-abstract-full').style.display = 'none'; document.getElementById('2311.10090v5-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 November, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 November, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2307.00633">arXiv:2307.00633</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2307.00633">pdf</a>, <a href="https://arxiv.org/format/2307.00633">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computers and Society">cs.CY</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Effects of Explanation Specificity on Passengers in Autonomous Driving
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Omeiza%2C+D">Daniel Omeiza</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bhattacharyya%2C+R">Raunak Bhattacharyya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jirotka%2C+M">Marina Jirotka</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2307.00633v1-abstract-short" style="display: inline;">
        The nature of explanations provided by an explainable AI algorithm has been a topic of interest in the explainable AI and human-computer interaction community. In this paper, we investigate the effects of natural language explanations&#39; specificity on passengers in autonomous driving. We extended an existing data-driven tree-based explainer algorithm by adding a rule-based option for explanation ge&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.00633v1-abstract-full').style.display = 'inline'; document.getElementById('2307.00633v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2307.00633v1-abstract-full" style="display: none;">
        The nature of explanations provided by an explainable AI algorithm has been a topic of interest in the explainable AI and human-computer interaction community. In this paper, we investigate the effects of natural language explanations&#39; specificity on passengers in autonomous driving. We extended an existing data-driven tree-based explainer algorithm by adding a rule-based option for explanation generation. We generated auditory natural language explanations with different levels of specificity (abstract and specific) and tested these explanations in a within-subject user study (N=39) using an immersive physical driving simulation setup. Our results showed that both abstract and specific explanations had similar positive effects on passengers&#39; perceived safety and the feeling of anxiety. However, the specific explanations influenced the desire of passengers to takeover driving control from the autonomous vehicle (AV), while the abstract explanations did not. We conclude that natural language auditory explanations are useful for passengers in autonomous driving, and their specificity levels could influence how much in-vehicle participants would wish to be in control of the driving activity.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2307.00633v1-abstract-full').style.display = 'none'; document.getElementById('2307.00633v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 July, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.09211">arXiv:2306.09211</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.09211">pdf</a>, <a href="https://arxiv.org/format/2306.09211">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Framework for Learning from Demonstration with Minimal Human Effort
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.09211v1-abstract-short" style="display: inline;">
        We consider robot learning in the context of shared autonomy, where control of the system can switch between a human teleoperator and autonomous control. In this setting we address reinforcement learning, and learning from demonstration, where there is a cost associated with human time. This cost represents the human time required to teleoperate the robot, or recover the robot from failures. For e&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.09211v1-abstract-full').style.display = 'inline'; document.getElementById('2306.09211v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.09211v1-abstract-full" style="display: none;">
        We consider robot learning in the context of shared autonomy, where control of the system can switch between a human teleoperator and autonomous control. In this setting we address reinforcement learning, and learning from demonstration, where there is a cost associated with human time. This cost represents the human time required to teleoperate the robot, or recover the robot from failures. For each episode, the agent must choose between requesting human teleoperation, or using one of its autonomous controllers. In our approach, we learn to predict the success probability for each controller, given the initial state of an episode. This is used in a contextual multi-armed bandit algorithm to choose the controller for the episode. A controller is learnt online from demonstrations and reinforcement learning so that autonomous performance improves, and the system becomes less reliant on the teleoperator with more experience. We show that our approach to controller selection reduces the human cost to perform two simulated tasks and a single real-world task.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.09211v1-abstract-full').style.display = 'none'; document.getElementById('2306.09211v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Preprint version of IEEE Robotics and Automation Letters paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2302.03086">arXiv:2302.03086</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2302.03086">pdf</a>, <a href="https://arxiv.org/format/2302.03086">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DITTO: Offline Imitation Learning with World Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=DeMoss%2C+B">Branton DeMoss</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Foerster%2C+J">Jakob Foerster</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Posner%2C+I">Ingmar Posner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2302.03086v2-abstract-short" style="display: inline;">
        For imitation learning algorithms to scale to real-world challenges, they must handle high-dimensional observations, offline learning, and policy-induced covariate-shift. We propose DITTO, an offline imitation learning algorithm which addresses all three of these problems. DITTO optimizes a novel distance metric in the latent space of a learned world model: First, we train a world model on all ava&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.03086v2-abstract-full').style.display = 'inline'; document.getElementById('2302.03086v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2302.03086v2-abstract-full" style="display: none;">
        For imitation learning algorithms to scale to real-world challenges, they must handle high-dimensional observations, offline learning, and policy-induced covariate-shift. We propose DITTO, an offline imitation learning algorithm which addresses all three of these problems. DITTO optimizes a novel distance metric in the latent space of a learned world model: First, we train a world model on all available trajectory data, then, the imitation agent is unrolled from expert start states in the learned model, and penalized for its latent divergence from the expert dataset over multiple time steps. We optimize this multi-step latent divergence using standard reinforcement learning algorithms, which provably induces imitation learning, and empirically achieves state-of-the art performance and sample efficiency on a range of Atari environments from pixels, without any online environment access. We also adapt other standard imitation learning algorithms to the world model setting, and show that this considerably improves their performance. Our results show how creative use of world models can lead to a simple, robust, and highly-performant policy-learning framework.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.03086v2-abstract-full').style.display = 'none'; document.getElementById('2302.03086v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 February, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2212.00124">arXiv:2212.00124</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2212.00124">pdf</a>, <a href="https://arxiv.org/format/2212.00124">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        One Risk to Rule Them All: A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2212.00124v3-abstract-short" style="display: inline;">
        Offline reinforcement learning (RL) is suitable for safety-critical domains where online exploration is too costly or dangerous. In such safety-critical settings, decision-making should take into consideration the risk of catastrophic outcomes. In other words, decision-making should be risk-sensitive. Previous works on risk in offline RL combine together offline RL techniques, to avoid distributio&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.00124v3-abstract-full').style.display = 'inline'; document.getElementById('2212.00124v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2212.00124v3-abstract-full" style="display: none;">
        Offline reinforcement learning (RL) is suitable for safety-critical domains where online exploration is too costly or dangerous. In such safety-critical settings, decision-making should take into consideration the risk of catastrophic outcomes. In other words, decision-making should be risk-sensitive. Previous works on risk in offline RL combine together offline RL techniques, to avoid distributional shift, with risk-sensitive RL algorithms, to achieve risk-sensitivity. In this work, we propose risk-sensitivity as a mechanism to jointly address both of these issues. Our model-based approach is risk-averse to both epistemic and aleatoric uncertainty. Risk-aversion to epistemic uncertainty prevents distributional shift, as areas not covered by the dataset have high epistemic uncertainty. Risk-aversion to aleatoric uncertainty discourages actions that may result in poor outcomes due to environment stochasticity. Our experiments show that our algorithm achieves competitive performance on deterministic benchmarks, and outperforms existing approaches for risk-sensitive objectives in stochastic domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.00124v3-abstract-full').style.display = 'none'; document.getElementById('2212.00124v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 October, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 November, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2210.04067">arXiv:2210.04067</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2210.04067">pdf</a>, <a href="https://arxiv.org/format/2210.04067">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        VP-STO: Via-point-based Stochastic Trajectory Optimization for Reactive Robot Behavior
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jankowski%2C+J">Julius Jankowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bruderm%C3%BCller%2C+L">Lara Brudermüller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Calinon%2C+S">Sylvain Calinon</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2210.04067v2-abstract-short" style="display: inline;">
        Achieving reactive robot behavior in complex dynamic environments is still challenging as it relies on being able to solve trajectory optimization problems quickly enough, such that we can replan the future motion at frequencies which are sufficiently high for the task at hand. We argue that current limitations in Model Predictive Control (MPC) for robot manipulators arise from inefficient, high-d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.04067v2-abstract-full').style.display = 'inline'; document.getElementById('2210.04067v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2210.04067v2-abstract-full" style="display: none;">
        Achieving reactive robot behavior in complex dynamic environments is still challenging as it relies on being able to solve trajectory optimization problems quickly enough, such that we can replan the future motion at frequencies which are sufficiently high for the task at hand. We argue that current limitations in Model Predictive Control (MPC) for robot manipulators arise from inefficient, high-dimensional trajectory representations and the negligence of time-optimality in the trajectory optimization process. Therefore, we propose a motion optimization framework that optimizes jointly over space and time, generating smooth and timing-optimal robot trajectories in joint-space. While being task-agnostic, our formulation can incorporate additional task-specific requirements, such as collision avoidance, and yet maintain real-time control rates, demonstrated in simulation and real-world robot experiments on closed-loop manipulation. For additional material, please visit https://sites.google.com/oxfordrobotics.institute/vp-sto.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.04067v2-abstract-full').style.display = 'none'; document.getElementById('2210.04067v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 March, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 October, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">*Authors contributed equally</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2207.13409">arXiv:2207.13409</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2207.13409">pdf</a>, <a href="https://arxiv.org/format/2207.13409">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unbiased Active Inference for Classical Control
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pezzato%2C+C">Corrado Pezzato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrari%2C+R">Riccardo Ferrari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2207.13409v1-abstract-short" style="display: inline;">
        Active inference is a mathematical framework that originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behavior in robotics. Specifically, the active inference controller (AIC) has been successful on several continuous control and state-estimation tasks. Despite its relative success, some established design choices lead t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.13409v1-abstract-full').style.display = 'inline'; document.getElementById('2207.13409v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2207.13409v1-abstract-full" style="display: none;">
        Active inference is a mathematical framework that originated in computational neuroscience. Recently, it has been demonstrated as a promising approach for constructing goal-driven behavior in robotics. Specifically, the active inference controller (AIC) has been successful on several continuous control and state-estimation tasks. Despite its relative success, some established design choices lead to a number of practical limitations for robot control. These include having a biased estimate of the state, and only an implicit model of control actions. In this paper, we highlight these limitations and propose an extended version of the unbiased active inference controller (u-AIC). The u-AIC maintains all the compelling benefits of the AIC and removes its limitations. Simulation results on a 2-DOF arm and experiments on a real 7-DOF manipulator show the improved performance of the u-AIC with respect to the standard AIC. The code can be found at https://github.com/cpezzato/unbiased_aic.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2207.13409v1-abstract-full').style.display = 'none'; document.getElementById('2207.13409v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 July, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 8 figures. Accepted at IROS 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.12581">arXiv:2204.12581</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.12581">pdf</a>, <a href="https://arxiv.org/format/2204.12581">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RAMBO-RL: Robust Adversarial Model-Based Offline Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.12581v3-abstract-short" style="display: inline;">
        Offline reinforcement learning (RL) aims to find performant policies from logged data without further environment interaction. Model-based algorithms, which learn a model of the environment from the dataset and perform conservative policy optimisation within that model, have emerged as a promising approach to this problem. In this work, we present Robust Adversarial Model-Based Offline RL (RAMBO),&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.12581v3-abstract-full').style.display = 'inline'; document.getElementById('2204.12581v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.12581v3-abstract-full" style="display: none;">
        Offline reinforcement learning (RL) aims to find performant policies from logged data without further environment interaction. Model-based algorithms, which learn a model of the environment from the dataset and perform conservative policy optimisation within that model, have emerged as a promising approach to this problem. In this work, we present Robust Adversarial Model-Based Offline RL (RAMBO), a novel approach to model-based offline RL. We formulate the problem as a two-player zero sum game against an adversarial environment model. The model is trained to minimise the value function while still accurately predicting the transitions in the dataset, forcing the policy to act conservatively in areas not covered by the dataset. To approximately solve the two-player game, we alternate between optimising the policy and adversarially optimising the model. The problem formulation that we address is theoretically grounded, resulting in a probably approximately correct (PAC) performance guarantee and a pessimistic value function which lower bounds the value function in the true environment. We evaluate our approach on widely studied offline RL benchmarks, and demonstrate that it outperforms existing state-of-the-art baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.12581v3-abstract-full').style.display = 'none'; document.getElementById('2204.12581v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 October, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 April, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NeurIPS 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2204.08035">arXiv:2204.08035</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2204.08035">pdf</a>, <a href="https://arxiv.org/format/2204.08035">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Beta Residuals: Improving Fault-Tolerant Control for Sensory Faults via Bayesian Inference and Precision Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hartemink%2C+W">William Hartemink</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrari%2C+R+M+G">Riccardo M. G. Ferrari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2204.08035v1-abstract-short" style="display: inline;">
        Model-based fault-tolerant control (FTC) often consists of two distinct steps: fault detection &amp; isolation (FDI), and fault accommodation. In this work we investigate posing fault-tolerant control as a single Bayesian inference problem. Previous work showed that precision learning allows for stochastic FTC without an explicit fault detection step. While this leads to implicit fault recovery, infor&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.08035v1-abstract-full').style.display = 'inline'; document.getElementById('2204.08035v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2204.08035v1-abstract-full" style="display: none;">
        Model-based fault-tolerant control (FTC) often consists of two distinct steps: fault detection &amp; isolation (FDI), and fault accommodation. In this work we investigate posing fault-tolerant control as a single Bayesian inference problem. Previous work showed that precision learning allows for stochastic FTC without an explicit fault detection step. While this leads to implicit fault recovery, information on sensor faults is not provided, which may be essential for triggering other impact-mitigation actions. In this paper, we introduce a precision-learning based Bayesian FTC approach and a novel beta residual for fault detection. Simulation results are presented, supporting the use of beta residual against competing approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2204.08035v1-abstract-full').style.display = 'none'; document.getElementById('2204.08035v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 2 figures. Accepted at the 11th IFAC Symposium on Fault Detection, Supervision and Safety for Technical Processes - SAFEPROCESS 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.12746">arXiv:2110.12746</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.12746">pdf</a>, <a href="https://arxiv.org/format/2110.12746">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Planning for Risk-Aversion and Expected Value in MDPs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.12746v2-abstract-short" style="display: inline;">
        Planning in Markov decision processes (MDPs) typically optimises the expected cost. However, optimising the expectation does not consider the risk that for any given run of the MDP, the total cost received may be unacceptably high. An alternative approach is to find a policy which optimises a risk-averse objective such as conditional value at risk (CVaR). However, optimising the CVaR alone may res&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.12746v2-abstract-full').style.display = 'inline'; document.getElementById('2110.12746v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.12746v2-abstract-full" style="display: none;">
        Planning in Markov decision processes (MDPs) typically optimises the expected cost. However, optimising the expectation does not consider the risk that for any given run of the MDP, the total cost received may be unacceptably high. An alternative approach is to find a policy which optimises a risk-averse objective such as conditional value at risk (CVaR). However, optimising the CVaR alone may result in poor performance in expectation. In this work, we begin by showing that there can be multiple policies which obtain the optimal CVaR. This motivates us to propose a lexicographic approach which minimises the expected cost subject to the constraint that the CVaR of the total cost is optimal. We present an algorithm for this problem and evaluate our approach on four domains. Our results demonstrate that our lexicographic approach improves the expected cost compared to the state of the art algorithm, while achieving the optimal CVaR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.12746v2-abstract-full').style.display = 'none'; document.getElementById('2110.12746v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 March, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 October, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ICAPS 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.11287">arXiv:2109.11287</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.11287">pdf</a>, <a href="https://arxiv.org/format/2109.11287">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Risk-Aware Motion Planning in Partially Known Environments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Barbosa%2C+F+S">Fernando S. Barbosa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tumova%2C+J">Jana Tumova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.11287v1-abstract-short" style="display: inline;">
        Recent trends envisage robots being deployed in areas deemed dangerous to humans, such as buildings with gas and radiation leaks. In such situations, the model of the underlying hazardous process might be unknown to the agent a priori, giving rise to the problem of planning for safe behaviour in partially known environments. We employ Gaussian process regression to create a probabilistic model of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.11287v1-abstract-full').style.display = 'inline'; document.getElementById('2109.11287v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.11287v1-abstract-full" style="display: none;">
        Recent trends envisage robots being deployed in areas deemed dangerous to humans, such as buildings with gas and radiation leaks. In such situations, the model of the underlying hazardous process might be unknown to the agent a priori, giving rise to the problem of planning for safe behaviour in partially known environments. We employ Gaussian process regression to create a probabilistic model of the hazardous process from local noisy samples. The result of this regression is then used by a risk metric, such as the Conditional Value-at-Risk, to reason about the safety at a certain state. The outcome is a risk function that can be employed in optimal motion planning problems. We demonstrate the use of the proposed function in two approaches. First is a sampling-based motion planning algorithm with an event-based trigger for online replanning. Second is an adaptation to the incremental Gaussian Process motion planner (iGPMP2), allowing it to quickly react and adapt to the environment. Both algorithms are evaluated in representative simulation scenarios, where they demonstrate the ability of avoiding high-risk areas.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.11287v1-abstract-full').style.display = 'none'; document.getElementById('2109.11287v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 2 figures, to be published in CDC 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.05870">arXiv:2109.05870</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.05870">pdf</a>, <a href="https://arxiv.org/format/2109.05870">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1007/978-3-030-93736-2_48">10.1007/978-3-030-93736-2_48 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Stochastic Fault-tolerant Control using Precision Learning and Active Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pezzato%2C+C">Corrado Pezzato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corbato%2C+C+H">Carlos Hernandez Corbato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrari%2C+R">Riccardo Ferrari</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.05870v1-abstract-short" style="display: inline;">
        This work presents a fault-tolerant control scheme for sensory faults in robotic manipulators based on active inference. In the majority of existing schemes, a binary decision of whether a sensor is healthy (functional) or faulty is made based on measured data. The decision boundary is called a threshold and it is usually deterministic. Following a faulty decision, fault recovery is obtained by ex&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05870v1-abstract-full').style.display = 'inline'; document.getElementById('2109.05870v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.05870v1-abstract-full" style="display: none;">
        This work presents a fault-tolerant control scheme for sensory faults in robotic manipulators based on active inference. In the majority of existing schemes, a binary decision of whether a sensor is healthy (functional) or faulty is made based on measured data. The decision boundary is called a threshold and it is usually deterministic. Following a faulty decision, fault recovery is obtained by excluding the malfunctioning sensor. We propose a stochastic fault-tolerant scheme based on active inference and precision learning which does not require a priori threshold definitions to trigger fault recovery. Instead, the sensor precision, which represents its health status, is learned online in a model-free way allowing the system to gradually, and not abruptly exclude a failing unit. Experiments on a robotic manipulator show promising results and directions for future work are discussed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05870v1-abstract-full').style.display = 'none'; document.getElementById('2109.05870v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at the International Workshop on Active Inference (IWAI) 2021; 11 pages, 3 figures</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Machine Learning and Principles and Practice of Knowledge Discovery in Databases. ECML PKDD 2021. Communications in Computer and Information Science, vol 1524. Springer, Cham
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.05866">arXiv:2109.05866</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.05866">pdf</a>, <a href="https://arxiv.org/format/2109.05866">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Solving a Stochastic Shortest-Path Markov Decision Process as Probabilistic Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.05866v1-abstract-short" style="display: inline;">
        Previous work on planning as active inference addresses finite horizon problems and solutions valid for online planning. We propose solving the general Stochastic Shortest-Path Markov Decision Process (SSP MDP) as probabilistic inference. Furthermore, we discuss online and offline methods for planning under uncertainty. In an SSP MDP, the horizon is indefinite and unknown a priori. SSP MDPs genera&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05866v1-abstract-full').style.display = 'inline'; document.getElementById('2109.05866v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.05866v1-abstract-full" style="display: none;">
        Previous work on planning as active inference addresses finite horizon problems and solutions valid for online planning. We propose solving the general Stochastic Shortest-Path Markov Decision Process (SSP MDP) as probabilistic inference. Furthermore, we discuss online and offline methods for planning under uncertainty. In an SSP MDP, the horizon is indefinite and unknown a priori. SSP MDPs generalize finite and infinite horizon MDPs and are widely used in the artificial intelligence community. Additionally, we highlight some of the differences between solving an MDP using dynamic programming approaches widely used in the artificial intelligence community and approaches used in the active inference community.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.05866v1-abstract-full').style.display = 'none'; document.getElementById('2109.05866v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at the second International Workshop on Active Inference (IWAI 2021); 11 pages, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.01817">arXiv:2104.01817</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.01817">pdf</a>, <a href="https://arxiv.org/format/2104.01817">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Fault-tolerant Control of Robot Manipulators with Sensory Faults using Unbiased Active Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pezzato%2C+C">Corrado Pezzato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrari%2C+R">Riccardo Ferrari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corbato%2C+C+H">Carlos Hernandez Corbato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.01817v1-abstract-short" style="display: inline;">
        This work presents a novel fault-tolerant control scheme based on active inference. Specifically, a new formulation of active inference which, unlike previous solutions, provides unbiased state estimation and simplifies the definition of probabilistically robust thresholds for fault-tolerant control of robotic systems using the free-energy. The proposed solution makes use of the sensory prediction&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01817v1-abstract-full').style.display = 'inline'; document.getElementById('2104.01817v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.01817v1-abstract-full" style="display: none;">
        This work presents a novel fault-tolerant control scheme based on active inference. Specifically, a new formulation of active inference which, unlike previous solutions, provides unbiased state estimation and simplifies the definition of probabilistically robust thresholds for fault-tolerant control of robotic systems using the free-energy. The proposed solution makes use of the sensory prediction errors in the free-energy for the generation of residuals and thresholds for fault detection and isolation of sensory faults, and it does not require additional controllers for fault recovery. Results validating the benefits in a simulated 2-DOF manipulator are presented, and future directions to improve the current fault recovery approach are discussed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.01817v1-abstract-full').style.display = 'none'; document.getElementById('2104.01817v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 6 figures, Accepted at the European Control Conference (ECC) 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.05762">arXiv:2102.05762</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.05762">pdf</a>, <a href="https://arxiv.org/format/2102.05762">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Risk-Averse Bayes-Adaptive Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.05762v2-abstract-short" style="display: inline;">
        In this work, we address risk-averse Bayes-adaptive reinforcement learning. We pose the problem of optimising the conditional value at risk (CVaR) of the total return in Bayes-adaptive Markov decision processes (MDPs). We show that a policy optimising CVaR in this setting is risk-averse to both the parametric uncertainty due to the prior distribution over MDPs, and the internal uncertainty due to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.05762v2-abstract-full').style.display = 'inline'; document.getElementById('2102.05762v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.05762v2-abstract-full" style="display: none;">
        In this work, we address risk-averse Bayes-adaptive reinforcement learning. We pose the problem of optimising the conditional value at risk (CVaR) of the total return in Bayes-adaptive Markov decision processes (MDPs). We show that a policy optimising CVaR in this setting is risk-averse to both the parametric uncertainty due to the prior distribution over MDPs, and the internal uncertainty due to the inherent stochasticity of MDPs. We reformulate the problem as a two-player stochastic game and propose an approximate algorithm based on Monte Carlo tree search and Bayesian optimisation. Our experiments demonstrate that our approach significantly outperforms baseline approaches for this problem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.05762v2-abstract-full').style.display = 'none'; document.getElementById('2102.05762v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 October, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Full version of NeurIPS 2021 paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.04626">arXiv:2012.04626</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.04626">pdf</a>, <a href="https://arxiv.org/format/2012.04626">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Minimax Regret Optimisation for Robust Planning in Uncertain Markov Decision Processes
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rigter%2C+M">Marc Rigter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.04626v2-abstract-short" style="display: inline;">
        The parameters for a Markov Decision Process (MDP) often cannot be specified exactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets which the parameters belong to. Minimax regret has been proposed as an objective for planning in UMDPs to find robust policies which are not overly conservative. In this work, we focus on planning for Stochastic Shortest Path (SSP) UMDPs with un&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04626v2-abstract-full').style.display = 'inline'; document.getElementById('2012.04626v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.04626v2-abstract-full" style="display: none;">
        The parameters for a Markov Decision Process (MDP) often cannot be specified exactly. Uncertain MDPs (UMDPs) capture this model ambiguity by defining sets which the parameters belong to. Minimax regret has been proposed as an objective for planning in UMDPs to find robust policies which are not overly conservative. In this work, we focus on planning for Stochastic Shortest Path (SSP) UMDPs with uncertain cost and transition functions. We introduce a Bellman equation to compute the regret for a policy. We propose a dynamic programming algorithm that utilises the regret Bellman equation, and show that it optimises minimax regret exactly for UMDPs with independent uncertainties. For coupled uncertainties, we extend our approach to use options to enable a trade off between computation and solution quality. We evaluate our approach on both synthetic and real-world domains, showing that it significantly outperforms existing baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.04626v2-abstract-full').style.display = 'none'; document.getElementById('2012.04626v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 12 February, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Full version of AAAI 2021 paper, with corrigendum attached that describes error in original paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.05894">arXiv:2005.05894</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2005.05894">pdf</a>, <a href="https://arxiv.org/format/2005.05894">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Active Inference for Integrated State-Estimation, Control, and Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baioumy%2C+M">Mohamed Baioumy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.05894v2-abstract-short" style="display: inline;">
        This work presents an approach for control, state-estimation and learning model (hyper)parameters for robotic manipulators. It is based on the active inference framework, prominent in computational neuroscience as a theory of the brain, where behaviour arises from minimizing variational free-energy. The robotic manipulator shows adaptive and robust behaviour compared to state-of-the-art methods. A&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.05894v2-abstract-full').style.display = 'inline'; document.getElementById('2005.05894v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.05894v2-abstract-full" style="display: none;">
        This work presents an approach for control, state-estimation and learning model (hyper)parameters for robotic manipulators. It is based on the active inference framework, prominent in computational neuroscience as a theory of the brain, where behaviour arises from minimizing variational free-energy. The robotic manipulator shows adaptive and robust behaviour compared to state-of-the-art methods. Additionally, we show the exact relationship to classic methods such as PID control. Finally, we show that by learning a temporal parameter and model variances, our approach can deal with unmodelled dynamics, damps oscillations, and is robust against disturbances and poor initial parameters. The approach is validated on the `Franka Emika Panda&#39; 7 DoF manipulator.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.05894v2-abstract-full').style.display = 'none'; document.getElementById('2005.05894v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 March, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 May, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 6 figures, accepted for presentation at the International Conference on Robotics and Automation (ICRA) 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.04445">arXiv:2003.04445</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.04445">pdf</a>, <a href="https://arxiv.org/format/2003.04445">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Convex Hull Monte-Carlo Tree Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Painter%2C+M">Michael Painter</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.04445v2-abstract-short" style="display: inline;">
        This work investigates Monte-Carlo planning for agents in stochastic environments, with multiple objectives. We propose the Convex Hull Monte-Carlo Tree-Search (CHMCTS) framework, which builds upon Trial Based Heuristic Tree Search and Convex Hull Value Iteration (CHVI), as a solution to multi-objective planning in large environments. Moreover, we consider how to pose the problem of approximating&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.04445v2-abstract-full').style.display = 'inline'; document.getElementById('2003.04445v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.04445v2-abstract-full" style="display: none;">
        This work investigates Monte-Carlo planning for agents in stochastic environments, with multiple objectives. We propose the Convex Hull Monte-Carlo Tree-Search (CHMCTS) framework, which builds upon Trial Based Heuristic Tree Search and Convex Hull Value Iteration (CHVI), as a solution to multi-objective planning in large environments. Moreover, we consider how to pose the problem of approximating multiobjective planning solutions as a contextual multi-armed bandits problem, giving a principled motivation for how to select actions from the view of contextual regret. This leads us to the use of Contextual Zooming for action selection, yielding Zooming CHMCTS. We evaluate our algorithm using the Generalised Deep Sea Treasure environment, demonstrating that Zooming CHMCTS can achieve a sublinear contextual regret and scales better than CHVI on a given computational budget.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.04445v2-abstract-full').style.display = 'none'; document.getElementById('2003.04445v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 March, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 9 March, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Camera-ready version of paper accepted to ICAPS 2020, along with relevant appendices</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.04848">arXiv:1911.04848</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.04848">pdf</a>, <a href="https://arxiv.org/format/1911.04848">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3472206">10.1145/3472206 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mixed-Initiative variable autonomy for remotely operated mobile robots
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chiou%2C+M">Manolis Chiou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Stolkin%2C+R">Rustam Stolkin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.04848v2-abstract-short" style="display: inline;">
        This paper presents an Expert-guided Mixed-Initiative Control Switcher (EMICS) for remotely operated mobile robots. The EMICS enables switching between different levels of autonomy during task execution initiated by either the human operator and/or the EMICS. The EMICS is evaluated in two disaster response inspired experiments, one with a simulated robot and test arena, and one with a real robot i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.04848v2-abstract-full').style.display = 'inline'; document.getElementById('1911.04848v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.04848v2-abstract-full" style="display: none;">
        This paper presents an Expert-guided Mixed-Initiative Control Switcher (EMICS) for remotely operated mobile robots. The EMICS enables switching between different levels of autonomy during task execution initiated by either the human operator and/or the EMICS. The EMICS is evaluated in two disaster response inspired experiments, one with a simulated robot and test arena, and one with a real robot in a realistic environment.
  Analyses from the two experiments provide evidence that: a) Human-Initiative (HI) systems outperform systems with single modes of operation, such as pure teleoperation, in navigation tasks; b) in the context of the simulated robot experiment, Mixed-Initiative (MI) systems provide improved performance in navigation tasks, improved operator performance in cognitive demanding secondary tasks, and improved operator workload compared to HI. Results also reinforce previous human-robot interaction evidence regarding the importance of the operator&#39;s personality traits and their trust in the autonomous system. Lastly, our experiment on a physical robot provides empirical evidence that identify two major challenges for MI control: a) the design of context-aware MI control systems; and b) the conflict for control between the robot&#39;s MI control system and the operator. Insights regarding these challenges are discussed and ways to tackle them are proposed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.04848v2-abstract-full').style.display = 'none'; document.getElementById('1911.04848v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 October, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 12 November, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted for journal publication, under review</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ACM Transactions on Human-Robot Interaction, Volume 10, Issue 4, 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1807.05196">arXiv:1807.05196</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1807.05196">pdf</a>, <a href="https://arxiv.org/ps/1807.05196">ps</a>, <a href="https://arxiv.org/format/1807.05196">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Artificial Intelligence for Long-Term Robot Autonomy: A Survey
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckett%2C+T">Tom Duckett</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hanheide%2C+M">Marc Hanheide</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krajn%C3%ADk%2C+T">Tomáš Krajník</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1807.05196v1-abstract-short" style="display: inline;">
        Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e. weeks, months, or years) poses ma&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1807.05196v1-abstract-full').style.display = 'inline'; document.getElementById('1807.05196v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1807.05196v1-abstract-full" style="display: none;">
        Autonomous systems will play an essential role in many applications across diverse domains including space, marine, air, field, road, and service robotics. They will assist us in our daily routines and perform dangerous, dirty and dull tasks. However, enabling robotic systems to perform autonomously in complex, real-world scenarios over extended time periods (i.e. weeks, months, or years) poses many challenges. Some of these have been investigated by sub-disciplines of Artificial Intelligence (AI) including navigation &amp; mapping, perception, knowledge representation &amp; reasoning, planning, interaction, and learning. The different sub-disciplines have developed techniques that, when re-integrated within an autonomous system, can enable robots to operate effectively in complex, long-term scenarios. In this paper, we survey and discuss AI techniques as &#39;enablers&#39; for long-term robot autonomy, current progress in integrating these techniques within long-running robotic systems, and the future challenges and opportunities for AI in long-term autonomy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1807.05196v1-abstract-full').style.display = 'none'; document.getElementById('1807.05196v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 July, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication in the IEEE Robotics and Automation Letters (RA-L)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1803.02906">arXiv:1803.02906</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1803.02906">pdf</a>, <a href="https://arxiv.org/format/1803.02906">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Simultaneous Task Allocation and Planning Under Uncertainty
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Faruq%2C+F">Fatma Faruq</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Parker%2C+D">David Parker</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1803.02906v2-abstract-short" style="display: inline;">
        We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1803.02906v2-abstract-full').style.display = 'inline'; document.getElementById('1803.02906v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1803.02906v2-abstract-full" style="display: none;">
        We propose novel techniques for task allocation and planning in multi-robot systems operating in uncertain environments. Task allocation is performed simultaneously with planning, which provides more detailed information about individual robot behaviour, but also exploits independence between tasks to do so efficiently. We use Markov decision processes to model robot behaviour and linear temporal logic to specify tasks and safety constraints. Building upon techniques and tools from formal verification, we show how to generate a sequence of multi-robot policies, iteratively refining them to reallocate tasks if individual robots fail, and providing probabilistic guarantees on the performance (and safe operation) of the team of robots under the resulting policy. We implement our approach and evaluate it on a benchmark multi-robot example.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1803.02906v2-abstract-full').style.display = 'none'; document.getElementById('1803.02906v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 August, 2018; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 March, 2018;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2018.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1702.08513">arXiv:1702.08513</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1702.08513">pdf</a>, <a href="https://arxiv.org/format/1702.08513">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Databases">cs.DB</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/IROS.2017.8206444">10.1109/IROS.2017.8206444 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Deep Visual Object Models From Noisy Web Data: How to Make it Work
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Massouh%2C+N">Nizar Massouh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Babiloni%2C+F">Francesca Babiloni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tommasi%2C+T">Tatiana Tommasi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Young%2C+J">Jay Young</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Caputo%2C+B">Barbara Caputo</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1702.08513v1-abstract-short" style="display: inline;">
        Deep networks thrive when trained on large scale data collections. This has given ImageNet a central role in the development of deep architectures for visual object classification. However, ImageNet was created during a specific period in time, and as such it is prone to aging, as well as dataset bias issues. Moving beyond fixed training datasets will lead to more robust visual systems, especially&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1702.08513v1-abstract-full').style.display = 'inline'; document.getElementById('1702.08513v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1702.08513v1-abstract-full" style="display: none;">
        Deep networks thrive when trained on large scale data collections. This has given ImageNet a central role in the development of deep architectures for visual object classification. However, ImageNet was created during a specific period in time, and as such it is prone to aging, as well as dataset bias issues. Moving beyond fixed training datasets will lead to more robust visual systems, especially when deployed on robots in new environments which must train on the objects they encounter there. To make this possible, it is important to break free from the need for manual annotators. Recent work has begun to investigate how to use the massive amount of images available on the Web in place of manual image annotations. We contribute to this research thread with two findings: (1) a study correlating a given level of noisily labels to the expected drop in accuracy, for two deep architectures, on two different types of noise, that clearly identifies GoogLeNet as a suitable architecture for learning from Web data; (2) a recipe for the creation of Web datasets with minimal noise and maximum visual variability, based on a visual and natural language processing concept expansion strategy. By combining these two results, we obtain a method for learning powerful deep object models automatically from the Web. We confirm the effectiveness of our approach through object categorization experiments using our Web-derived version of ImageNet on a popular robot vision benchmark database, and on a lifelong object discovery task on a mobile robot.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1702.08513v1-abstract-full').style.display = 'none'; document.getElementById('1702.08513v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 February, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 7 figures, 3 tables</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1604.04384">arXiv:1604.04384</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1604.04384">pdf</a>, <a href="https://arxiv.org/format/1604.04384">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/MRA.2016.2636359">10.1109/MRA.2016.2636359 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The STRANDS Project: Long-Term Autonomy in Everyday Environments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hawes%2C+N">Nick Hawes</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burbridge%2C+C">Chris Burbridge</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jovan%2C+F">Ferdian Jovan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kunze%2C+L">Lars Kunze</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lacerda%2C+B">Bruno Lacerda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mudrov%C3%A1%2C+L">Lenka Mudrová</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Young%2C+J">Jay Young</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wyatt%2C+J">Jeremy Wyatt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hebesberger%2C+D">Denise Hebesberger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=K%C3%B6rtner%2C+T">Tobias Körtner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ambrus%2C+R">Rares Ambrus</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bore%2C+N">Nils Bore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Folkesson%2C+J">John Folkesson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jensfelt%2C+P">Patric Jensfelt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Beyer%2C+L">Lucas Beyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hermans%2C+A">Alexander Hermans</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Leibe%2C+B">Bastian Leibe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aldoma%2C+A">Aitor Aldoma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=F%C3%A4ulhammer%2C+T">Thomas Fäulhammer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zillich%2C+M">Michael Zillich</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vincze%2C+M">Markus Vincze</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chinellato%2C+E">Eris Chinellato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Al-Omari%2C+M">Muhannad Al-Omari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duckworth%2C+P">Paul Duckworth</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gatsoulis%2C+Y">Yiannis Gatsoulis</a>
      , et al. (8 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1604.04384v2-abstract-short" style="display: inline;">
        Thanks to the efforts of the robotics and autonomous systems community, robots are becoming ever more capable. There is also an increasing demand from end-users for autonomous service robots that can operate in real environments for extended periods. In the STRANDS project we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.04384v2-abstract-full').style.display = 'inline'; document.getElementById('1604.04384v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1604.04384v2-abstract-full" style="display: none;">
        Thanks to the efforts of the robotics and autonomous systems community, robots are becoming ever more capable. There is also an increasing demand from end-users for autonomous service robots that can operate in real environments for extended periods. In the STRANDS project we are tackling this demand head-on by integrating state-of-the-art artificial intelligence and robotics research into mobile service robots, and deploying these systems for long-term installations in security and care environments. Over four deployments, our robots have been operational for a combined duration of 104 days autonomously performing end-user defined tasks, covering 116km in the process. In this article we describe the approach we have used to enable long-term autonomous operation in everyday environments, and how our robots are able to use their long run times to improve their own performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.04384v2-abstract-full').style.display = 'none'; document.getElementById('1604.04384v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 October, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 April, 2016;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2016.
      
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>