<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 1,314 results for author: <span class="mathjax">Chao Ma</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Chao Ma">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Chao+Ma&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Chao Ma">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2509.01322">arXiv:2509.01322</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2509.01322">pdf</a>, <a href="https://arxiv.org/ps/2509.01322">ps</a>, <a href="https://arxiv.org/format/2509.01322">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LongCat-Flash Technical Report
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Meituan+LongCat+Team"> Meituan LongCat Team</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bayan"> Bayan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+B">Bei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+B">Bingye Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+B">Bo Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rong%2C+B">Bolin Rong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+C">Chen Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+C">Cheng Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+C">Chengcheng Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xi%2C+C">Chenguang Xi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+C">Chong Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qin%2C+C">Chuan Qin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chuyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+C">Cong Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Congkui Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+D">Dan Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+D">Daoru Pan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bu%2C+D">Defei Bu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+D">Dengchang Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kong%2C+D">Deyang Kong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+D">Dishan Liu</a>
      , et al. (157 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2509.01322v1-abstract-short" style="display: inline;">
        We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE) language model designed for both computational efficiency and advanced agentic capabilities. Stemming from the need for scalable efficiency, LongCat-Flash adopts two novel designs: (a) Zero-computation Experts, which enables dynamic computational budget allocation and activates 18.6B-31.3B (27B on average) per token depen&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.01322v1-abstract-full').style.display = 'inline'; document.getElementById('2509.01322v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2509.01322v1-abstract-full" style="display: none;">
        We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE) language model designed for both computational efficiency and advanced agentic capabilities. Stemming from the need for scalable efficiency, LongCat-Flash adopts two novel designs: (a) Zero-computation Experts, which enables dynamic computational budget allocation and activates 18.6B-31.3B (27B on average) per token depending on contextual demands, optimizing resource usage. (b) Shortcut-connected MoE, which enlarges the computation-communication overlap window, demonstrating notable gains in inference efficiency and throughput compared to models of a comparable scale. We develop a comprehensive scaling framework for large models that combines hyperparameter transfer, model-growth initialization, a multi-pronged stability suite, and deterministic computation to achieve stable and reproducible training. Notably, leveraging the synergy among scalable architectural design and infrastructure efforts, we complete model training on more than 20 trillion tokens within 30 days, while achieving over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million output tokens. To cultivate LongCat-Flash towards agentic intelligence, we conduct a large-scale pre-training on optimized mixtures, followed by targeted mid- and post-training on reasoning, code, and instructions, with further augmentation from synthetic data and tool use tasks. Comprehensive evaluations demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers highly competitive performance among other leading models, with exceptional strengths in agentic tasks. The model checkpoint of LongCat-Flash is open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.01322v1-abstract-full').style.display = 'none'; document.getElementById('2509.01322v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 September, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2509.01074">arXiv:2509.01074</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2509.01074">pdf</a>, <a href="https://arxiv.org/ps/2509.01074">ps</a>, <a href="https://arxiv.org/format/2509.01074">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        High-efficiency Weak-trace-free Counterfactual Communication via Quantum Zeno Effect
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xing%2C+T">Tianyi Xing</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+A">Anqi Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yizhi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+C">Chao Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yaxuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+P">Pingyu Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+J">Jiangfang Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+D">Dongyang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yingwen Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qiang%2C+X">Xiaogang Qiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Sheng Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+P">Ping Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+J">Junjie Wu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2509.01074v1-abstract-short" style="display: inline;">
        The quantum Zeno effect, which inhibits quantum state evolution via repeated weak measurements, significantly enhances the efficiency of interaction-free measurement (IFM). This fundamental mechanism facilitates high-efficiency counterfactual quantum communication, enabling information delivery without particle transmission through the channel. However, the transmission time of the counterfactual&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.01074v1-abstract-full').style.display = 'inline'; document.getElementById('2509.01074v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2509.01074v1-abstract-full" style="display: none;">
        The quantum Zeno effect, which inhibits quantum state evolution via repeated weak measurements, significantly enhances the efficiency of interaction-free measurement (IFM). This fundamental mechanism facilitates high-efficiency counterfactual quantum communication, enabling information delivery without particle transmission through the channel. However, the transmission time of the counterfactual communication requires minutes for bit and suffers the bit error when transmitting an image. Applying the quantum Zeno effect, we experimentally demonstrate high-efficiency weak-trace-free counterfactual communication on a quantum photonic chip, achieving a transmission probability of $74.2 \pm 1.6\%$ for bit 0 and $85.1 \pm 1.3\%$ for bit 1. Furthermore, we successfully transmit our group&#39;s logo --Quanta-- through counterfactual communication, and reduce the time cost from minutes to seconds for bit, with zero bit errors after information processing. Our study provides a promising approach for secure and efficient communication using integrated silicon quantum photonics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.01074v1-abstract-full').style.display = 'none'; document.getElementById('2509.01074v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2509.00289">arXiv:2509.00289</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2509.00289">pdf</a>, <a href="https://arxiv.org/ps/2509.00289">ps</a>, <a href="https://arxiv.org/format/2509.00289">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Helicity amplitude and branching fraction measurement of $χ_{cJ} \rightarrow Λ\barΛ $
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (697 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2509.00289v1-abstract-short" style="display: inline;">
        Utilizing $2712.4 \pm 14.3$ million $ψ(3686)$ events accumulated by the BESIII experiment, we perform a partial wave analysis of $ψ(3686)\rightarrowγχ_{cJ}\rightarrowγΛ\barΛ$ decay ($J=0,1,2$). The ratio of the helicity amplitudes with same (++) and opposite (+-) helicity for $χ_{c2}\rightarrowΛ\barΛ$ decay is determined for the first time to be $R_{χ_{c2}}=0.575 \pm 0.048 \pm 0.018 $, with a rela&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.00289v1-abstract-full').style.display = 'inline'; document.getElementById('2509.00289v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2509.00289v1-abstract-full" style="display: none;">
        Utilizing $2712.4 \pm 14.3$ million $ψ(3686)$ events accumulated by the BESIII experiment, we perform a partial wave analysis of $ψ(3686)\rightarrowγχ_{cJ}\rightarrowγΛ\barΛ$ decay ($J=0,1,2$). The ratio of the helicity amplitudes with same (++) and opposite (+-) helicity for $χ_{c2}\rightarrowΛ\barΛ$ decay is determined for the first time to be $R_{χ_{c2}}=0.575 \pm 0.048 \pm 0.018 $, with a relative phase angle $ΔΦ_{χ_{c2}} = 0.37 \pm 0.15 \pm 0.05 $~rad. The parameters of the angular distribution of $χ_{c2}$ are determined to be $α_{χ_{c2}} = -0.211 \pm 0.100 \pm 0.050 $ and $β_{χ_{c2}} = -0.039 \pm 0.089 \pm 0.033 $, based on the distribution $dN / d\cosθ= 1 + α_{χ_{c2}} \cos^2θ+ β_{χ_{c2}} \cos^4θ$. The width of $χ_{c0}$ is determined to be $12.31 \pm 0.26 \pm 0.12 $~MeV. Additionally, the branching fractions for $χ_{cJ} \rightarrow Λ\barΛ$ are measured to be $(3.662 \pm 0.048 \pm 0.111) \times 10^{-4}$, $(1.182 \pm 0.026 \pm 0.042) \times 10^{-4}$, and $(1.704 \pm 0.035 \pm 0.057) \times 10^{-4}$ for $χ_{c0}$, $χ_{c1}$ and $χ_{c2}$, respectively, where the first uncertainty is statistical and the second systematic.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2509.00289v1-abstract-full').style.display = 'none'; document.getElementById('2509.00289v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This is the first submission of the manuscript. 13 pages, 15 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.19763">arXiv:2508.19763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.19763">pdf</a>, <a href="https://arxiv.org/ps/2508.19763">ps</a>, <a href="https://arxiv.org/format/2508.19763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Representation Theory">math.RT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Rings and Algebras">math.RA</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Homological Bounds of Gentle algebras
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yu-Zhe Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+X">Xin Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+J">Jiacheng Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.19763v1-abstract-short" style="display: inline;">
        This paper studies the homological bounds of gentle algebras, i.e., the upper bounds for the sum of the projective and injective dimensions of indecomposable modules over gentle algebras. We provide conditions under which this sum is strictly less than twice the global dimension, and as an application, we give a characterization of quasi-tilted gentle algebras.
        
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.19763v1-abstract-full" style="display: none;">
        This paper studies the homological bounds of gentle algebras, i.e., the upper bounds for the sum of the projective and injective dimensions of indecomposable modules over gentle algebras. We provide conditions under which this sum is strictly less than twice the global dimension, and as an application, we give a characterization of quasi-tilted gentle algebras.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19763v1-abstract-full').style.display = 'none'; document.getElementById('2508.19763v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">26 pages, 2 figures</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          16G10; 16G20; 16E05; 16E10
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.19182">arXiv:2508.19182</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.19182">pdf</a>, <a href="https://arxiv.org/ps/2508.19182">ps</a>, <a href="https://arxiv.org/format/2508.19182">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SoccerNet 2025 Challenges Results
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Giancola%2C+S">Silvio Giancola</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cioppa%2C+A">Anthony Cioppa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guti%C3%A9rrez-P%C3%A9rez%2C+M">Marc Gutiérrez-Pérez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Held%2C+J">Jan Held</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hinojosa%2C+C">Carlos Hinojosa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joos%2C+V">Victor Joos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Leduc%2C+A">Arnaud Leduc</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Magera%2C+F">Floriane Magera</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sanchez%2C+K">Karen Sanchez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Somers%2C+V">Vladimir Somers</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xarles%2C+A">Artur Xarles</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agudo%2C+A">Antonio Agudo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alahi%2C+A">Alexandre Alahi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barnich%2C+O">Olivier Barnich</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Clap%C3%A9s%2C+A">Albert Clapés</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Vleeschouwer%2C+C">Christophe De Vleeschouwer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Escalera%2C+S">Sergio Escalera</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ghanem%2C+B">Bernard Ghanem</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moeslund%2C+T+B">Thomas B. Moeslund</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Van+Droogenbroeck%2C+M">Marc Van Droogenbroeck</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abe%2C+T">Tomoki Abe</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alotaibi%2C+S">Saad Alotaibi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Altawijri%2C+F">Faisal Altawijri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Araujo%2C+S">Steven Araujo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+X">Xiang Bai</a>
      , et al. (93 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.19182v1-abstract-short" style="display: inline;">
        The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This year&#39;s challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, tar&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19182v1-abstract-full').style.display = 'inline'; document.getElementById('2508.19182v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.19182v1-abstract-full" style="display: none;">
        The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This year&#39;s challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19182v1-abstract-full').style.display = 'none'; document.getElementById('2508.19182v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.19092">arXiv:2508.19092</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.19092">pdf</a>, <a href="https://arxiv.org/ps/2508.19092">ps</a>, <a href="https://arxiv.org/format/2508.19092">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measurement of the branching fraction of $\psip \to ωηη$
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (706 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.19092v1-abstract-short" style="display: inline;">
        Using a sample of (2.712 $\pm$ 0.014)$\times 10^{9}$ $\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\psip \to ωηη$ is observed for the first time. The branching fraction of the $ψ(3686)\toωηη$ decay is measured to be (1.65 $\pm$ 0.02 $\pm$ 0.21)$\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19092v1-abstract-full').style.display = 'inline'; document.getElementById('2508.19092v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.19092v1-abstract-full" style="display: none;">
        Using a sample of (2.712 $\pm$ 0.014)$\times 10^{9}$ $\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\psip \to ωηη$ is observed for the first time. The branching fraction of the $ψ(3686)\toωηη$ decay is measured to be (1.65 $\pm$ 0.02 $\pm$ 0.21)$\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear structures associated with the well-established $ω(1420)$ and $f_{0}(1710)$ resonances are observed in the $ωη$ and $ηη$ invariant-mass spectra, respectively.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19092v1-abstract-full').style.display = 'none'; document.getElementById('2508.19092v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.19087">arXiv:2508.19087</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.19087">pdf</a>, <a href="https://arxiv.org/ps/2508.19087">ps</a>, <a href="https://arxiv.org/format/2508.19087">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Hardware Architecture">cs.AR</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TCAD.2025.3604321">10.1109/TCAD.2025.3604321 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Shaobo Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+C">Chao Fang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shao%2C+H">Haikuo Shao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhongfeng Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.19087v1-abstract-short" style="display: inline;">
        Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited suppor&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19087v1-abstract-full').style.display = 'inline'; document.getElementById('2508.19087v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.19087v1-abstract-full" style="display: none;">
        Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\times$ speedup compared to FP16 baselines and a 2.16$\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\times$ speedup over FP16 and 1.65$\times$ speedup over CUTLASS integer baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.19087v1-abstract-full').style.display = 'none'; document.getElementById('2508.19087v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in the IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18761">arXiv:2508.18761</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18761">pdf</a>, <a href="https://arxiv.org/ps/2508.18761">ps</a>, <a href="https://arxiv.org/format/2508.18761">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Study of the $χ_{cJ}\rightarrowΛ\barΛη^\prime$ decays
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M+B">M. B. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (683 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18761v1-abstract-short" style="display: inline;">
        Using a data sample of $(2.712\pm0.014)\times10^{9}$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we investigate the decays $χ_{cJ} \rightarrow Λ\barΛ η^\prime$ for $J=0,~1,~2$ via the radiative transition $ψ(3686) \rightarrow γχ_{cJ}$. The decays $χ_{c0,2}\rightarrowΛ\barΛη^\prime$ are observed for the first time, with statistical significances of 6.7$\,σ$ and 6.4&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18761v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18761v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18761v1-abstract-full" style="display: none;">
        Using a data sample of $(2.712\pm0.014)\times10^{9}$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we investigate the decays $χ_{cJ} \rightarrow Λ\barΛ η^\prime$ for $J=0,~1,~2$ via the radiative transition $ψ(3686) \rightarrow γχ_{cJ}$. The decays $χ_{c0,2}\rightarrowΛ\barΛη^\prime$ are observed for the first time, with statistical significances of 6.7$\,σ$ and 6.4$\,σ$, respectively. Evidence for the decay $χ_{c1}\rightarrowΛ\barΛη^\prime$ is found with a statistical significance of 3.3$\,σ$. The corresponding branching fractions are measured to be $\mathscr{B}(χ_{c0}\rightarrowΛ\barΛη^\prime)=(7.56\pm1.42\pm0.90)\times10^{-5}$, $\mathscr{B}(χ_{c1}\rightarrowΛ\barΛη^\prime)=(1.54\pm0.51\pm0.16)\times10^{-5}$, and $\mathscr{B}(χ_{c2}\rightarrowΛ\barΛη^\prime)=(3.03\pm0.61\pm0.29)\times10^{-5}$, where the first uncertainties are statistical and the second systematic. No significant excited $Λ$ baryon states or $Λ\barΛ$ near-threshold enhancements are observed.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18761v1-abstract-full').style.display = 'none'; document.getElementById('2508.18761v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18601">arXiv:2508.18601</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18601">pdf</a>, <a href="https://arxiv.org/ps/2508.18601">ps</a>, <a href="https://arxiv.org/format/2508.18601">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Search for $χ_{c1}\to π^{+}π^{-}η_c$ via $ψ(3686)\toγχ_{c1}$
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (697 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18601v1-abstract-short" style="display: inline;">
        Utilizing $(2712.4 \pm 14.3) \times 10^6$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we search for the hadronic transition process $χ_{c1} \to π^+π^-η_c$ following the decay $ψ(3686)\to γχ_{c1}$. No significant signal is observed, and an upper limit of $\mathcal{B}(χ_{c1}\toπ^+π^-η_c)$ is determined to be $3.1 times 10^{-4}$~at 90\% confidence level, which is one o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18601v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18601v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18601v1-abstract-full" style="display: none;">
        Utilizing $(2712.4 \pm 14.3) \times 10^6$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we search for the hadronic transition process $χ_{c1} \to π^+π^-η_c$ following the decay $ψ(3686)\to γχ_{c1}$. No significant signal is observed, and an upper limit of $\mathcal{B}(χ_{c1}\toπ^+π^-η_c)$ is determined to be $3.1 times 10^{-4}$~at 90\% confidence level, which is one order of magnitude more stringent than the previous measurement.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18601v1-abstract-full').style.display = 'none'; document.getElementById('2508.18601v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18594">arXiv:2508.18594</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18594">pdf</a>, <a href="https://arxiv.org/ps/2508.18594">ps</a>, <a href="https://arxiv.org/format/2508.18594">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Search for a bound state of $Λ_{c}\barΣ_{c}$ near threshold
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (706 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18594v1-abstract-short" style="display: inline;">
        We search for a possible $Λ_{c} \bar{Σ}_{c}$ bound state, denoted as $H_{c}^{\pm}$, via the $ e^{+}e^{-} \to π^{+} π^{-} Λ_{c}^{+}\barΛ_{c}^{-}$ process for the first time. This analysis utilizes 207.8 and 159.3 pb$^{-1}$ of $e^{+}e^{-}$ annihilation data at the center-of-mass energies of 4918.02 and 4950.93 MeV, respectively, collected with the BESIII detector at the BEPCII collider. No statistic&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18594v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18594v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18594v1-abstract-full" style="display: none;">
        We search for a possible $Λ_{c} \bar{Σ}_{c}$ bound state, denoted as $H_{c}^{\pm}$, via the $ e^{+}e^{-} \to π^{+} π^{-} Λ_{c}^{+}\barΛ_{c}^{-}$ process for the first time. This analysis utilizes 207.8 and 159.3 pb$^{-1}$ of $e^{+}e^{-}$ annihilation data at the center-of-mass energies of 4918.02 and 4950.93 MeV, respectively, collected with the BESIII detector at the BEPCII collider. No statistically significant signal is observed. The upper limits of the product of Born cross section and branching fraction $σ(e^{+}e^{-} \to π^{+} H_c^{-} + c.c.) \times \mathcal{B}(H_c^{-} \rightarrow π^{-}Λ_{c}^{+}\barΛ_{c}^{-})$ at a 90\% confidence level are reported at each energy point and for various $H_{c}$ mass hypotheses (4715, 4720, 4725, 4730, and 4735 MeV/$c^{2}$) and widths (5, 10, or 20 MeV), with the upper limits ranging from 1.1 pb to 6.4 pb.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18594v1-abstract-full').style.display = 'none'; document.getElementById('2508.18594v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18138">arXiv:2508.18138</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18138">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Superconductivity">cond-mat.supr-con</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1002/adma.202513265">10.1002/adma.202513265 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Asymmetric stress engineering of dense dislocations in brittle superconductors for strong vortex pinning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+M">Meng Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+C">Chiheng Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yao%2C+C">Chao Yao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zhihao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">Qinghua Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gong%2C+Y">Yue Gong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+H">He Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gong%2C+D">Dongliang Gong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+D">Dongliang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">Xianping Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+F">Fang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Y">Yuping Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Z">Zengwei Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jianqi Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+J">Junyi Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Awaji%2C+S">Satoshi Awaji</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiaolin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+J">Jianxin Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hosono%2C+H">Hideo Hosono</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yanwei Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18138v1-abstract-short" style="display: inline;">
        Large lossless currents in high-temperature superconductors (HTS) critically rely on dense defects with suitable size and dimensionality to pin vortices, with dislocations being particularly effective due to their one-dimensional geometry to interact extensively with vortex lines. However, in non-metallic compounds such as HTS with rigid lattices, conventional deformation methods typically lead to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18138v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18138v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18138v1-abstract-full" style="display: none;">
        Large lossless currents in high-temperature superconductors (HTS) critically rely on dense defects with suitable size and dimensionality to pin vortices, with dislocations being particularly effective due to their one-dimensional geometry to interact extensively with vortex lines. However, in non-metallic compounds such as HTS with rigid lattices, conventional deformation methods typically lead to catastrophic fracture rather than dislocation-mediated plasticity, making it a persistent challenge to introduce dislocations at high density. Here, we propose an asymmetric stress field strategy using extrusion to directly nucleate a high-density of dislocations in HTS by activating shear-driven lattice slip and twisting under superimposed hydrostatic compression. As demonstrated in iron-based superconductors (IBS), atomic displacements of nearly one angstrom trigger the formation of tilted dislocation lines with a density approaching that of metals. With further structural refinement, these dislocations serve as strong pinning centers that lead to a fivefold enhancement in the current-carrying capacity of IBS at 33 T, along with low anisotropy and a large irreversibility field. This work not only establishes a scalable route to engineer pinning landscapes in HTS, but also offers a generalizable framework for manipulating dislocation structures in rigid crystalline systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18138v1-abstract-full').style.display = 'none'; document.getElementById('2508.18138v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">27 pages, 5 figures</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Adv. Mater. (2025): e13265
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18081">arXiv:2508.18081</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18081">pdf</a>, <a href="https://arxiv.org/ps/2508.18081">ps</a>, <a href="https://arxiv.org/format/2508.18081">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="General Relativity and Quantum Cosmology">gr-qc</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GWTC-4.0: Methods for Identifying and Characterizing Gravitational-wave Transients
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=The+LIGO+Scientific+Collaboration"> The LIGO Scientific Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=the+Virgo+Collaboration"> the Virgo Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=the+KAGRA+Collaboration"> the KAGRA Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abac%2C+A+G">A. G. Abac</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abouelfettouh%2C+I">I. Abouelfettouh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Acernese%2C+F">F. Acernese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ackley%2C+K">K. Ackley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhicary%2C+S">S. Adhicary</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+D">D. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+N">N. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+R+X">R. X. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adkins%2C+V+K">V. K. Adkins</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Afroz%2C+S">S. Afroz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+D">D. Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agathos%2C+M">M. Agathos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abchouyeh%2C+M+A">M. Aghaei Abchouyeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aguiar%2C+O+D">O. D. Aguiar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmadzadeh%2C+S">S. Ahmadzadeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aiello%2C+L">L. Aiello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ain%2C+A">A. Ain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ajith%2C+P">P. Ajith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Akcay%2C+S">S. Akcay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Akutsu%2C+T">T. Akutsu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Albanesi%2C+S">S. Albanesi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alfaidi%2C+R+A">R. A. Alfaidi</a>
      , et al. (1787 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18081v1-abstract-short" style="display: inline;">
        The Gravitational-Wave Transient Catalog (GWTC) is a collection of candidate gravitational-wave transient signals identified and characterized by the LIGO-Virgo-KAGRA Collaboration. Producing the contents of the GWTC from detector data requires complex analysis methods. These comprise techniques to model the signal; identify the transients in the data; evaluate the quality of the data and mitigate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18081v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18081v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18081v1-abstract-full" style="display: none;">
        The Gravitational-Wave Transient Catalog (GWTC) is a collection of candidate gravitational-wave transient signals identified and characterized by the LIGO-Virgo-KAGRA Collaboration. Producing the contents of the GWTC from detector data requires complex analysis methods. These comprise techniques to model the signal; identify the transients in the data; evaluate the quality of the data and mitigate possible instrumental issues; infer the parameters of each transient; compare the data with the waveform models for compact binary coalescences; and handle the large amount of results associated with all these different analyses. In this paper, we describe the methods employed to produce the catalog&#39;s fourth release, GWTC-4.0, focusing on the analysis of the first part of the fourth observing run of Advanced LIGO, Advanced Virgo and KAGRA.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18081v1-abstract-full').style.display = 'none'; document.getElementById('2508.18081v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">As part of the Astrophysical Journal Letters Focus Issue on the Gravitational Wave Transient Catalog</span>
    </p>
    

    
      <p class="comments is-size-7">
        
          <span class="has-text-black-bis has-text-weight-semibold">Report number:</span>
          LIGO-P2400300
        

        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.18080">arXiv:2508.18080</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.18080">pdf</a>, <a href="https://arxiv.org/ps/2508.18080">ps</a>, <a href="https://arxiv.org/format/2508.18080">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="General Relativity and Quantum Cosmology">gr-qc</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        GWTC-4.0: An Introduction to Version 4.0 of the Gravitational-Wave Transient Catalog
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=The+LIGO+Scientific+Collaboration"> The LIGO Scientific Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=the+Virgo+Collaboration"> the Virgo Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=the+KAGRA+Collaboration"> the KAGRA Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abac%2C+A+G">A. G. Abac</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abouelfettouh%2C+I">I. Abouelfettouh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Acernese%2C+F">F. Acernese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ackley%2C+K">K. Ackley</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhicary%2C+S">S. Adhicary</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+D">D. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+N">N. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adhikari%2C+R+X">R. X. Adhikari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adkins%2C+V+K">V. K. Adkins</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Afroz%2C+S">S. Afroz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agarwal%2C+D">D. Agarwal</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agathos%2C+M">M. Agathos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Abchouyeh%2C+M+A">M. Aghaei Abchouyeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aguiar%2C+O+D">O. D. Aguiar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ahmadzadeh%2C+S">S. Ahmadzadeh</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aiello%2C+L">L. Aiello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ain%2C+A">A. Ain</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ajith%2C+P">P. Ajith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Akcay%2C+S">S. Akcay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Akutsu%2C+T">T. Akutsu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Albanesi%2C+S">S. Albanesi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Alfaidi%2C+R+A">R. A. Alfaidi</a>
      , et al. (1785 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.18080v1-abstract-short" style="display: inline;">
        The Gravitational-Wave Transient Catalog (GWTC) is a collection of short-duration (transient) gravitational wave signals identified by the LIGO-Virgo-KAGRA Collaboration in gravitational-wave data produced by the eponymous detectors. The catalog provides information about the identified candidates, such as the arrival time and amplitude of the signal and properties of the signal&#39;s source as inferr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18080v1-abstract-full').style.display = 'inline'; document.getElementById('2508.18080v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.18080v1-abstract-full" style="display: none;">
        The Gravitational-Wave Transient Catalog (GWTC) is a collection of short-duration (transient) gravitational wave signals identified by the LIGO-Virgo-KAGRA Collaboration in gravitational-wave data produced by the eponymous detectors. The catalog provides information about the identified candidates, such as the arrival time and amplitude of the signal and properties of the signal&#39;s source as inferred from the observational data. GWTC is the data release of this dataset and version 4.0 extends the catalog to include observations made during the first part of the fourth LIGO-Virgo-KAGRA observing run up until 2024 January 31. This paper marks an introduction to a collection of articles related to this version of the catalog, GWTC-4.0. The collection of articles accompanying the catalog provides documentation of the methods used to analyze the data, summaries of the catalog of events, observational measurements drawn from the population, and detailed discussions of selected candidates
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.18080v1-abstract-full').style.display = 'none'; document.getElementById('2508.18080v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">As part of the Astrophysical Journal Letters Focus Issue on the Gravitational Wave Transient Catalog</span>
    </p>
    

    
      <p class="comments is-size-7">
        
          <span class="has-text-black-bis has-text-weight-semibold">Report number:</span>
          LIGO-P2400293
        

        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.17819">arXiv:2508.17819</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.17819">pdf</a>, <a href="https://arxiv.org/ps/2508.17819">ps</a>, <a href="https://arxiv.org/format/2508.17819">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Search for CP violation in e+e- -&gt; psi(3770) -&gt; DDbar via D -&gt; KsPi0
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M+B">M. B. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (707 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.17819v2-abstract-short" style="display: inline;">
        Utilizing data sample of electron-positron collisions recorded with the BESIII detector at the center-of-mass energies of 3.773~GeV, corresponding to an integrated luminosity of 20.28~fb$^{-1}$, we report the first search for the CP forbidden process $e^+e^- \to ψ(3773) \to D^0\bar{D}^0 \to (K^0_Sπ^0)(K^0_Sπ^0)$. No significant signal is observed. We set the upper limit on the observed cross secti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.17819v2-abstract-full').style.display = 'inline'; document.getElementById('2508.17819v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.17819v2-abstract-full" style="display: none;">
        Utilizing data sample of electron-positron collisions recorded with the BESIII detector at the center-of-mass energies of 3.773~GeV, corresponding to an integrated luminosity of 20.28~fb$^{-1}$, we report the first search for the CP forbidden process $e^+e^- \to ψ(3773) \to D^0\bar{D}^0 \to (K^0_Sπ^0)(K^0_Sπ^0)$. No significant signal is observed. We set the upper limit on the observed cross section to be 7.37~fb, and the upper limit on the joint branching fraction of the C-odd correlated neutral $D$ pair $\mathcal{B}[(D^0\bar{D}^0)_{\text{C-odd}} \to (K^0_Sπ^0)(K^0_Sπ^0)]$ to be $2.04 \times 10^{-6}$ at the 90\% confidence level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.17819v2-abstract-full').style.display = 'none'; document.getElementById('2508.17819v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 August, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 4 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.16483">arXiv:2508.16483</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.16483">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optics">physics.optics</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Skyrmions based on optical anisotropy for topological encoding
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yunqi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+A+A">An Aloysius Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+Z">Zimo Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yifei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+R">Ruofu Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+R">Runchen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pong%2C+Z">Zhi-Kai Pong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+Y">Yuxi Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+C">Chao He</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.16483v1-abstract-short" style="display: inline;">
        The observation of skyrmions across diverse physical domains suggests that they are universal features of S$^{2}$-valued fields, reflecting the ubiquity of topology in the study of the natural world. In this paper, we develop an abstract technique of parameter space dimensionality reduction that extends the skyrmion framework to fields taking values in manifolds of dimension greater than 2, thereb&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.16483v1-abstract-full').style.display = 'inline'; document.getElementById('2508.16483v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.16483v1-abstract-full" style="display: none;">
        The observation of skyrmions across diverse physical domains suggests that they are universal features of S$^{2}$-valued fields, reflecting the ubiquity of topology in the study of the natural world. In this paper, we develop an abstract technique of parameter space dimensionality reduction that extends the skyrmion framework to fields taking values in manifolds of dimension greater than 2, thereby broadening the range of systems that can support skyrmions. To prove that this is more than just a mathematical abstraction, we apply our technique to light-matter interactions, directly encoding skyrmionic structures into the optical anisotropy of spatially varying structured matter by selecting a distinguished axis, which is fundamentally different from the more commonly known skyrmions formed by director fields in liquid crystals. We experimentally realize such skyrmions using a liquid-crystal-based tunable elliptical retarder array as a proof-of-concept platform and demonstrate complex, reconfigurable skyrmionic states exhibiting topological robustness under artificially introduced stochastic perturbations. Exploiting this robustness, we demonstrate a promising application of skyrmions in topologically protected information storage and show, both theoretically and experimentally, that the physically realized S$^{2}$-valued field can differ from the designed field everywhere by a large margin of error (up to 60°) without affecting the underlying topological charge.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.16483v1-abstract-full').style.display = 'none'; document.getElementById('2508.16483v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.15763">arXiv:2508.15763</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.15763">pdf</a>, <a href="https://arxiv.org/ps/2508.15763">ps</a>, <a href="https://arxiv.org/format/2508.15763">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Intern-S1: A Scientific Multimodal Foundation Model
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+L">Lei Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+Z">Zhongrui Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+Y">Yuhang Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+M">Maosong Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+W">Weihan Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+C">Chiyu Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+H">Haojiong Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+K">Kai Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+P">Pengcheng Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Ying Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yongkang Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yu Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chu%2C+P">Pei Chu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chu%2C+T">Tao Chu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+E">Erfei Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+G">Ganqu Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+L">Long Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+Z">Ziyun Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+N">Nianchen Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+N">Ning Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+N">Nanqing Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+P">Peijie Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dou%2C+S">Shihan Dou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+S">Sinan Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Duan%2C+H">Haodong Duan</a>
      , et al. (152 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.15763v2-abstract-short" style="display: inline;">
        In recent years, a plethora of open-source foundation models have emerged, achieving remarkable progress in some widely attended fields, with performance being quite close to that of closed-source models. However, in high-value but more challenging scientific professional fields, either the fields still rely on expert models, or the progress of general foundation models lags significantly compared&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.15763v2-abstract-full').style.display = 'inline'; document.getElementById('2508.15763v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.15763v2-abstract-full" style="display: none;">
        In recent years, a plethora of open-source foundation models have emerged, achieving remarkable progress in some widely attended fields, with performance being quite close to that of closed-source models. However, in high-value but more challenging scientific professional fields, either the fields still rely on expert models, or the progress of general foundation models lags significantly compared to those in popular areas, far from sufficient for transforming scientific research and leaving substantial gap between open-source models and closed-source models in these scientific domains. To mitigate this gap and explore a step further toward Artificial General Intelligence (AGI), we introduce Intern-S1, a specialized generalist equipped with general understanding and reasoning capabilities with expertise to analyze multiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE) model with 28 billion activated parameters and 241 billion total parameters, continually pre-trained on 5T tokens, including over 2.5T tokens from scientific domains. In the post-training stage, Intern-S1 undergoes offline and then online reinforcement learning (RL) in InternBootCamp, where we propose Mixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks simultaneously. Through integrated innovations in algorithms, data, and training systems, Intern-S1 achieved top-tier performance in online RL training. On comprehensive evaluation benchmarks, Intern-S1 demonstrates competitive performance on general reasoning tasks among open-source models and significantly outperforms open-source models in scientific domains, surpassing closed-source state-of-the-art models in professional tasks, such as molecular synthesis planning, reaction condition prediction, predicting thermodynamic stabilities for crystals. Our models are available at https://huggingface.co/internlm/Intern-S1.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.15763v2-abstract-full').style.display = 'none'; document.getElementById('2508.15763v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 21 August, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.14609">arXiv:2508.14609</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.14609">pdf</a>, <a href="https://arxiv.org/ps/2508.14609">ps</a>, <a href="https://arxiv.org/format/2508.14609">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AnchorSync: Global Consistency Optimization for Long Video Editing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Zichi Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yinggui Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wei%2C+T">Tao Wei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chao Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.14609v1-abstract-short" style="display: inline;">
        Editing long videos remains a challenging task due to the need for maintaining both global consistency and temporal coherence across thousands of frames. Existing methods often suffer from structural drift or temporal artifacts, particularly in minute-long sequences. We introduce AnchorSync, a novel diffusion-based framework that enables high-quality, long-term video editing by decoupling the task&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.14609v1-abstract-full').style.display = 'inline'; document.getElementById('2508.14609v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.14609v1-abstract-full" style="display: none;">
        Editing long videos remains a challenging task due to the need for maintaining both global consistency and temporal coherence across thousands of frames. Existing methods often suffer from structural drift or temporal artifacts, particularly in minute-long sequences. We introduce AnchorSync, a novel diffusion-based framework that enables high-quality, long-term video editing by decoupling the task into sparse anchor frame editing and smooth intermediate frame interpolation. Our approach enforces structural consistency through a progressive denoising process and preserves temporal dynamics via multimodal guidance. Extensive experiments show that AnchorSync produces coherent, high-fidelity edits, surpassing prior methods in visual quality and temporal stability.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.14609v1-abstract-full').style.display = 'none'; document.getElementById('2508.14609v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ACM MM 2025; Code is released at https://github.com/VISION-SJTU/AnchorSync</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.12667">arXiv:2508.12667</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.12667">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Strongly Correlated Electrons">cond-mat.str-el</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Anomalous Nernst Effect and Its Implications for Time-Reversal Symmetry Breaking in Kagome Metal ScV6Sn6
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yazhou Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+S">Saizheng Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+J">Jiaxing Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+J">Jiajun Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yuwei Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+T">Tao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jialu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+C">Chenchao Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dai%2C+J">Jianhui Dai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cao%2C+C">Chao Cao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Y">Yu Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+P">Peijie Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yuke Li</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.12667v1-abstract-short" style="display: inline;">
        The nonmagnetic kagome metal ScV6Sn6 displays an unconventional charge order (CO) accompanied by signatures of an anomalous Hall effect, hidden magnetism, and multiple lattice instabilities. In this study, we report the observation of unconventional anomalous thermoelectric properties. Notably, unexpected anomalous transverse Nernst signals reach a peak value of ~4 μV/K near the TCDW ~92 K in ScV6&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.12667v1-abstract-full').style.display = 'inline'; document.getElementById('2508.12667v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.12667v1-abstract-full" style="display: none;">
        The nonmagnetic kagome metal ScV6Sn6 displays an unconventional charge order (CO) accompanied by signatures of an anomalous Hall effect, hidden magnetism, and multiple lattice instabilities. In this study, we report the observation of unconventional anomalous thermoelectric properties. Notably, unexpected anomalous transverse Nernst signals reach a peak value of ~4 μV/K near the TCDW ~92 K in ScV6Sn6, and these signals persist in the charge-ordered state as the temperature decreases to 10 K. Furthermore, both thermopower and thermal conductivity exhibit significant changes under magnetic fields, even in the nonmagnetic ground state. These observations strongly suggest the emergence of time-reversal symmetry breaking in ScV6Sn6, as supported by muon spin relaxation (μSR) measurements. While hidden magnetism represents the most plausible origin, alternative mechanisms involving orbital currents and chiral charge order remain possible.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.12667v1-abstract-full').style.display = 'none'; document.getElementById('2508.12667v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">14 pages, 4 figures, to appear in SCIENCE CHINA Physics, Mechanics and Astronomy</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.11951">arXiv:2508.11951</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.11951">pdf</a>, <a href="https://arxiv.org/ps/2508.11951">ps</a>, <a href="https://arxiv.org/format/2508.11951">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+H">Hao Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sang%2C+H">Hong Sang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yajing Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qiu%2C+P">Ping Qiu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ji%2C+C">Chao Ji</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.11951v1-abstract-short" style="display: inline;">
        This paper investigates multi-scale feature approximation and transferable features for object detection from point clouds. Multi-scale features are critical for object detection from point clouds. However, multi-scale feature learning usually involves multiple neighborhood searches and scale-aware layers, which can hinder efforts to achieve lightweight models and may not be conducive to research&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11951v1-abstract-full').style.display = 'inline'; document.getElementById('2508.11951v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.11951v1-abstract-full" style="display: none;">
        This paper investigates multi-scale feature approximation and transferable features for object detection from point clouds. Multi-scale features are critical for object detection from point clouds. However, multi-scale feature learning usually involves multiple neighborhood searches and scale-aware layers, which can hinder efforts to achieve lightweight models and may not be conducive to research constrained by limited computational resources. This paper approximates point-based multi-scale features from a single neighborhood based on knowledge distillation. To compensate for the loss of constructive diversity in a single neighborhood, this paper designs a transferable feature embedding mechanism. Specifically, class-aware statistics are employed as transferable features given the small computational cost. In addition, this paper introduces the central weighted intersection over union for localization to alleviate the misalignment brought by the center offset in optimization. Note that the method presented in this paper saves computational costs. Extensive experiments on public datasets demonstrate the effectiveness of the proposed method.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11951v1-abstract-full').style.display = 'none'; document.getElementById('2508.11951v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.11565">arXiv:2508.11565</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.11565">pdf</a>, <a href="https://arxiv.org/ps/2508.11565">ps</a>, <a href="https://arxiv.org/format/2508.11565">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        INFNet: A Task-aware Information Flow Network for Large-Scale Recommendation Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+K">Kaiyuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mao%2C+D">Dongdong Mao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yongxiang Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yanhua Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+Y">Yanxiang Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xialong Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+P">Peng Jiang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.11565v1-abstract-short" style="display: inline;">
        Feature interaction has long been a cornerstone of ranking models in large-scale recommender systems due to its proven effectiveness in capturing complex dependencies among features. However, existing feature interaction strategies face two critical challenges in industrial applications: (1) The vast number of categorical and sequential features makes exhaustive interaction computationally prohibi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11565v1-abstract-full').style.display = 'inline'; document.getElementById('2508.11565v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.11565v1-abstract-full" style="display: none;">
        Feature interaction has long been a cornerstone of ranking models in large-scale recommender systems due to its proven effectiveness in capturing complex dependencies among features. However, existing feature interaction strategies face two critical challenges in industrial applications: (1) The vast number of categorical and sequential features makes exhaustive interaction computationally prohibitive, often resulting in optimization difficulties. (2) Real-world recommender systems typically involve multiple prediction objectives, yet most current approaches apply feature interaction modules prior to the multi-task learning layers. This late-fusion design overlooks task-specific feature dependencies and inherently limits the capacity of multi-task modeling. To address these limitations, we propose the Information Flow Network (INFNet), a task-aware architecture designed for large-scale recommendation scenarios. INFNet distinguishes features into three token types, categorical tokens, sequence tokens, and task tokens, and introduces a novel dual-flow design comprising heterogeneous and homogeneous alternating information blocks. For heterogeneous information flow, we employ a cross-attention mechanism with proxy that facilitates efficient cross-modal token interaction with balanced computational cost. For homogeneous flow, we design type-specific Proxy Gated Units (PGUs) to enable fine-grained intra-type feature processing. Extensive experiments on multiple offline benchmarks confirm that INFNet achieves state-of-the-art performance. Moreover, INFNet has been successfully deployed in a commercial online advertising system, yielding significant gains of +1.587% in Revenue (REV) and +1.155% in Click-Through Rate (CTR).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11565v1-abstract-full').style.display = 'none'; document.getElementById('2508.11565v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.11400">arXiv:2508.11400</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.11400">pdf</a>, <a href="https://arxiv.org/ps/2508.11400">ps</a>, <a href="https://arxiv.org/format/2508.11400">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Production and Decay Dynamics of the Charmed Baryon $Λ_c^+$ in $e^+e^-$ Annihilations near Threshold
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M+B">M. B. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (706 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.11400v2-abstract-short" style="display: inline;">
        The study of the charmed baryons is crucial for investigating the strong and weak interactions in the Standard Model and for gaining insights into the internal structure of baryons. In an $e^+e^-$ experiment the lightest charmed baryon, $Λ_c^+$, can be produced in pairs through the single photon annihilation process. This process can be described by two complex electromagnetic form factors. The pr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11400v2-abstract-full').style.display = 'inline'; document.getElementById('2508.11400v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.11400v2-abstract-full" style="display: none;">
        The study of the charmed baryons is crucial for investigating the strong and weak interactions in the Standard Model and for gaining insights into the internal structure of baryons. In an $e^+e^-$ experiment the lightest charmed baryon, $Λ_c^+$, can be produced in pairs through the single photon annihilation process. This process can be described by two complex electromagnetic form factors. The presence of a non-zero relative phase between these form factors gives rise to a transverse polarization of the charmed baryon and provides additional constraints on the dynamic parameters in the decays. In this article, we present the first observation of the transverse polarization of $Λ_{c}^{+}$ in the reaction $e^+e^- \to Λ_c^{+}\barΛ_c^-$, based on $6.4~\text{fb}^{-1}$ of $e^{+}e^{-}$ annihilation data collected at center-of-mass energies between 4600 MeV and 4951 MeV with the BESIII detector. The decay asymmetry parameters and strong phase shift in the decays $Λ_c^+ \to pK_S^0$, $Λπ^+$, $Σ^0π^+$, $Σ^+π^0$ are also simultaneously extracted from the joint angular distributions. These results are vital for understanding CP violation and its role in the matter-antimatter asymmetry of the Universe.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11400v2-abstract-full').style.display = 'none'; document.getElementById('2508.11400v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 August, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">21 pages, 8 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.11276">arXiv:2508.11276</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.11276">pdf</a>, <a href="https://arxiv.org/ps/2508.11276">ps</a>, <a href="https://arxiv.org/format/2508.11276">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measurement of the Born cross section for $e^+e^- \to p K^- K^- \barΞ^+$ at $\sqrt{s} =$ 3.5-4.9 GeV
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (701 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.11276v1-abstract-short" style="display: inline;">
        Using $e^+ e^-$ collision data corresponding to a total integrated luminosity of 20 ${\rm fb}^{-1}$ collected with the BESIII detector at the BEPCII collider, we present a measurement of the Born cross section for the process $e^+e^- \to p K^-K^-\barΞ^{+}$ at 39 center-of-mass energies between 3.5 and 4.9 GeV with a partial reconstruction technique. By performing a fit to the dressed cross section&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11276v1-abstract-full').style.display = 'inline'; document.getElementById('2508.11276v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.11276v1-abstract-full" style="display: none;">
        Using $e^+ e^-$ collision data corresponding to a total integrated luminosity of 20 ${\rm fb}^{-1}$ collected with the BESIII detector at the BEPCII collider, we present a measurement of the Born cross section for the process $e^+e^- \to p K^-K^-\barΞ^{+}$ at 39 center-of-mass energies between 3.5 and 4.9 GeV with a partial reconstruction technique. By performing a fit to the dressed cross section of $e^{+}e^{-}\to p K^- K^-\barΞ^{+}$ with a power law function for continuum production and one resonance at a time for the $ψ(3770)$, $ψ(4040)$, $ψ(4160)$, $ψ(4230)$, $ψ(4360)$, $ψ(4415)$ or $ψ(4660)$, respectively, the upper limits for the product of partial electronic width and branching fraction into the final state $p K^- K^- \barΞ^+$ for these resonances are determined at the $90\%$ confidence level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.11276v1-abstract-full').style.display = 'none'; document.getElementById('2508.11276v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, 2 figures, 3 tables, etc</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.05421">arXiv:2508.05421</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.05421">pdf</a>, <a href="https://arxiv.org/ps/2508.05421">ps</a>, <a href="https://arxiv.org/format/2508.05421">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Atomic Physics">physics.atom-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        LLM-based Multi-Agent Copilot for Quantum Sensor
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sha%2C+R">Rong Sha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+B">Binglin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+J">Jun Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+X">Xiaoxiao Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+C">Chengkun Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+L">Liang Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+C">Chao Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+J">Jixun Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+G">Guochao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+S">Shuhua Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+L">Lingxiao Zhu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.05421v1-abstract-short" style="display: inline;">
        Large language models (LLM) exhibit broad utility but face limitations in quantum sensor development, stemming from interdisciplinary knowledge barriers and involving complex optimization processes. Here we present QCopilot, an LLM-based multi-agent framework integrating external knowledge access, active learning, and uncertainty quantification for quantum sensor design and diagnosis. Comprising c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05421v1-abstract-full').style.display = 'inline'; document.getElementById('2508.05421v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.05421v1-abstract-full" style="display: none;">
        Large language models (LLM) exhibit broad utility but face limitations in quantum sensor development, stemming from interdisciplinary knowledge barriers and involving complex optimization processes. Here we present QCopilot, an LLM-based multi-agent framework integrating external knowledge access, active learning, and uncertainty quantification for quantum sensor design and diagnosis. Comprising commercial LLMs with few-shot prompt engineering and vector knowledge base, QCopilot employs specialized agents to adaptively select optimization methods, automate modeling analysis, and independently perform problem diagnosis. Applying QCopilot to atom cooling experiments, we generated 10${}^{\rm{8}}$ sub-$\rmμ$K atoms without any human intervention within a few hours, representing $\sim$100$\times$ speedup over manual experimentation. Notably, by continuously accumulating prior knowledge and enabling dynamic modeling, QCopilot can autonomously identify anomalous parameters in multi-parameter experimental settings. Our work reduces barriers to large-scale quantum sensor deployment and readily extends to other quantum information systems.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05421v1-abstract-full').style.display = 'none'; document.getElementById('2508.05421v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages,4 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.05365">arXiv:2508.05365</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.05365">pdf</a>, <a href="https://arxiv.org/ps/2508.05365">ps</a>, <a href="https://arxiv.org/format/2508.05365">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Mesoscale and Nanoscale Physics">cond-mat.mes-hall</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Materials Science">cond-mat.mtrl-sci</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Stacking-induced type-II quantum spin Hall insulators with high spin Chern number in unconventional magnetism
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Tan%2C+C">Chao-Yang Tan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+P">Panjun Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Z">Ze-Feng Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+F">Fengjie Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+P">Peng-Jie Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Z">Zhong-Yi Lu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.05365v1-abstract-short" style="display: inline;">
        Generally, stacking two monolayer type-I quantum spin Hall insulators gives rise to a trivial insulator. However, whether or not stacking two type-II quantum spin Hall insulators results in a trivial insulator has not yet been explored. In this letter, based on the calculations of lattice model, we demonstrate that stacking two type-II quantum spin Hall insulators does not yield a trivial insulato&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05365v1-abstract-full').style.display = 'inline'; document.getElementById('2508.05365v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.05365v1-abstract-full" style="display: none;">
        Generally, stacking two monolayer type-I quantum spin Hall insulators gives rise to a trivial insulator. However, whether or not stacking two type-II quantum spin Hall insulators results in a trivial insulator has not yet been explored. In this letter, based on the calculations of lattice model, we demonstrate that stacking two type-II quantum spin Hall insulators does not yield a trivial insulator, but instead forms a quantum spin Hall insulator with high spin Chern number. In this phase, there are two pairs of topological edge states with opposite chirality and polarization coexisting in the boundary. Our calculations further reveal that the quantized spin Hall conductance of the bilayer is twice that of the monolayer. When U(1) symmetry is present, the high spin Chern number phase remains stable; when U(1) symmetry is broken, it persists over a broad parameter range. Furthermore, based on the first-principles electronic structure calculations, we propose that bilayer Nb$_2$SeTeO is a type-II quantum spin Hall insulator with high spin Chern number. Finally, extending this strategy to multilayer stacks naturally leads to quantum spin Hall insulator with larger spin Chern number. Our work not only deepens the distinction between type-I and type-II quantum spin Hall insulators, but also offers a route toward realizing highly quantized spin Hall conductance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.05365v1-abstract-full').style.display = 'none'; document.getElementById('2508.05365v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">5pages,4figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.03456">arXiv:2508.03456</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.03456">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Biomolecules">q-bio.BM</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Decoding Polyphenol-Protein Interactions with Deep Learning: From Molecular Mechanisms to Food Applications
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Q">Qiang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+T">Tiantian Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nian%2C+B">Binbin Nian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+F">Feiyang Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+S">Siqi Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=V%C3%A1squez%2C+A+F">Andrés F. Vásquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+L">Liping Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+C">Chao Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Davari%2C+M+D">Mehdi D. Davari</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.03456v1-abstract-short" style="display: inline;">
        Polyphenols and proteins are essential biomolecules that influence food functionality and, by extension, human health. Their interactions -- hereafter referred to as PhPIs (polyphenol-protein interactions) -- affect key processes such as nutrient bioavailability, antioxidant activity, and therapeutic efficacy. However, these interactions remain challenging due to the structural diversity of polyph&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03456v1-abstract-full').style.display = 'inline'; document.getElementById('2508.03456v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.03456v1-abstract-full" style="display: none;">
        Polyphenols and proteins are essential biomolecules that influence food functionality and, by extension, human health. Their interactions -- hereafter referred to as PhPIs (polyphenol-protein interactions) -- affect key processes such as nutrient bioavailability, antioxidant activity, and therapeutic efficacy. However, these interactions remain challenging due to the structural diversity of polyphenols and the dynamic nature of protein binding. Traditional experimental techniques like nuclear magnetic resonance (NMR) and mass spectrometry (MS), along with computational tools such as molecular docking and molecular dynamics (MD), have offered important insights but face constraints in scalability, throughput, and reproducibility. This review explores how deep learning (DL) is reshaping the study of PhPIs by enabling efficient prediction of binding sites, interaction affinities, and MD using high-dimensional bio- and chem-informatics data. While DL enhances prediction accuracy and reduces experimental redundancy, its effectiveness remains limited by data availability, quality, and representativeness, particularly in the context of natural products. We critically assess current DL frameworks for PhPIs analysis and outline future directions, including multimodal data integration, improved model generalizability, and development of domain-specific benchmark datasets. This synthesis offers guidance for researchers aiming to apply DL in unraveling structure-function relationships of polyphenols, accelerating discovery in nutritional science and therapeutic development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03456v1-abstract-full').style.display = 'none'; document.getElementById('2508.03456v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.03049">arXiv:2508.03049</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.03049">pdf</a>, <a href="https://arxiv.org/ps/2508.03049">ps</a>, <a href="https://arxiv.org/format/2508.03049">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Numerical Analysis">math.NA</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Low-rankness and Smoothness Meet Subspace: A Unified Tensor Regularization for Hyperspectral Image Super-resolution
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+C">Chao Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+M">Mingxi Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Chao Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.03049v1-abstract-short" style="display: inline;">
        Hyperspectral image super-resolution (HSI-SR) has emerged as a challenging yet critical problem in remote sensing. Existing approaches primarily focus on regularization techniques that leverage low-rankness and local smoothness priors. Recently, correlated total variation has been introduced for tensor recovery, integrating these priors into a single regularization framework. Direct application to&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03049v1-abstract-full').style.display = 'inline'; document.getElementById('2508.03049v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.03049v1-abstract-full" style="display: none;">
        Hyperspectral image super-resolution (HSI-SR) has emerged as a challenging yet critical problem in remote sensing. Existing approaches primarily focus on regularization techniques that leverage low-rankness and local smoothness priors. Recently, correlated total variation has been introduced for tensor recovery, integrating these priors into a single regularization framework. Direct application to HSI-SR, however, is hindered by the high spectral dimensionality of hyperspectral data. In this paper, we propose a unified tensor regularizer, called JLRST, which jointly encodes low-rankness and local smoothness priors under a subspace framework. Specifically, we compute the gradients of the clustered coefficient tensors along all three tensor modes to fully exploit spectral correlations and nonlocal similarities in HSI. By enforcing priors on subspace coefficients rather than the entire HR-HSI data, the proposed method achieves improved computational efficiency and accuracy. Furthermore, to mitigate the bias introduced by the tensor nuclear norm (TNN), we introduce the mode-3 logarithmic TNN to process gradient tensors. An alternating direction method of multipliers with proven convergence is developed to solve the proposed model. Experimental results demonstrate that our approach significantly outperforms state-of-the-art methods in HSI-SR.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03049v1-abstract-full').style.display = 'none'; document.getElementById('2508.03049v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">13 pages, 71 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.03012">arXiv:2508.03012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.03012">pdf</a>, <a href="https://arxiv.org/ps/2508.03012">ps</a>, <a href="https://arxiv.org/format/2508.03012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Software Engineering">cs.SE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tool-integrated Reinforcement Learning for Repo Deep Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Z">Zexiong Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+C">Chao Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zeng%2C+Q">Qunhong Zeng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+P">Pengfei Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+Y">Yanzhen Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+B">Bing Xie</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.03012v2-abstract-short" style="display: inline;">
        Issue localization, the process of identifying code locations that need modification to resolve software issues, is a critical yet challenging task in software development. The semantic gap between natural language issue descriptions and faulty code requires complex multi-hop reasoning through code dependencies. Existing LLM-based agents attempt to address this by integrating repository retrieval&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03012v2-abstract-full').style.display = 'inline'; document.getElementById('2508.03012v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.03012v2-abstract-full" style="display: none;">
        Issue localization, the process of identifying code locations that need modification to resolve software issues, is a critical yet challenging task in software development. The semantic gap between natural language issue descriptions and faulty code requires complex multi-hop reasoning through code dependencies. Existing LLM-based agents attempt to address this by integrating repository retrieval tools. However, this transforms issue localization into a demanding task we call Repo Deep Search, which requires the LLM to effectively utilize various repository retrieval tools throughout a multi-step reasoning and navigation process. To tackle this challenge, we present ToolTrain, a two-stage tool-integrated training framework combining rejection-sampled supervised fine-tuning and tool-integrated reinforcement learning to enhance LLMs&#39; ability to use retrieval tools for issue localization. Experimental results show that ToolTrain-trained models achieve state-of-the-art performance, with our 32B model even surpassing Claude-3.7 on function-level localization. The results also show that improved localization performance translates to better end-to-end issue resolution performance. This further demonstrates that training for issue localization is a viable and effective strategy for improving automated software development.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.03012v2-abstract-full').style.display = 'none'; document.getElementById('2508.03012v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 4 August, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.01359">arXiv:2508.01359</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.01359">pdf</a>, <a href="https://arxiv.org/ps/2508.01359">ps</a>, <a href="https://arxiv.org/format/2508.01359">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measurement of Born Cross Sections and Effective Form Factors of $e^+e^-\to Ω^{-}\barΩ^{+}$ from$\sqrt{s}$ = 3.7 to 4.7 GeV
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Afedulidis%2C+O">O. Afedulidis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balossino%2C+I">I. Balossino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>
      , et al. (625 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.01359v1-abstract-short" style="display: inline;">
        Using $e^+e^-$ collision data corresponding to an integrated luminosity of 22.7 fb$^{-1}$, collected at center-of-mass energies between 3.7 and 4.7 GeV with the BESIII detector at the BEPCII storage ring, we measure the energy-dependent Born cross sections of $e^+e^-\to Ω^{-}\barΩ^+$ and the effective form factors of the $Ω^-$ baryon. The analysis employs a single baryon tagging method, and the re&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.01359v1-abstract-full').style.display = 'inline'; document.getElementById('2508.01359v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.01359v1-abstract-full" style="display: none;">
        Using $e^+e^-$ collision data corresponding to an integrated luminosity of 22.7 fb$^{-1}$, collected at center-of-mass energies between 3.7 and 4.7 GeV with the BESIII detector at the BEPCII storage ring, we measure the energy-dependent Born cross sections of $e^+e^-\to Ω^{-}\barΩ^+$ and the effective form factors of the $Ω^-$ baryon. The analysis employs a single baryon tagging method, and the results are consistent with theoretical predictions, providing critical constraints on the electromagnetic structure of the $Ω^-$ hyperon. No significant signal of charmonium or charmonium-like states decaying to $Ω^{-}\barΩ^+$ is observed in the investigated energy range.This paper supersedes the withdrawn work arXiv:2505.03180v1.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.01359v1-abstract-full').style.display = 'none'; document.getElementById('2508.01359v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.00649">arXiv:2508.00649</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.00649">pdf</a>, <a href="https://arxiv.org/ps/2508.00649">ps</a>, <a href="https://arxiv.org/format/2508.00649">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Cryptography and Security">cs.CR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+J">Junhao Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+J">Jiahao Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lin%2C+C">Chenhao Lin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+Z">Zhengyu Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chen Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chong Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Cong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Q">Qian Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+C">Chao Shen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.00649v2-abstract-short" style="display: inline;">
        Developing reliable defenses against patch attacks on object detectors has attracted increasing interest. However, we identify that existing defense evaluations lack a unified and comprehensive framework, resulting in inconsistent and incomplete assessments of current methods. To address this issue, we revisit 11 representative defenses and present the first patch defense benchmark, involving 2 at&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.00649v2-abstract-full').style.display = 'inline'; document.getElementById('2508.00649v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.00649v2-abstract-full" style="display: none;">
        Developing reliable defenses against patch attacks on object detectors has attracted increasing interest. However, we identify that existing defense evaluations lack a unified and comprehensive framework, resulting in inconsistent and incomplete assessments of current methods. To address this issue, we revisit 11 representative defenses and present the first patch defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object detectors, and 4 diverse metrics. This leads to the large-scale adversarial patch dataset with 94 types of patches and 94,000 images. Our comprehensive analyses reveal new insights: (1) The difficulty in defending against naturalistic patches lies in the data distribution, rather than the commonly believed high frequencies. Our new dataset with diverse patch distributions can be used to improve existing defenses by 15.09% AP@0.5. (2) The average precision of the attacked object, rather than the commonly pursued patch detection accuracy, shows high consistency with defense performance. (3) Adaptive attacks can substantially bypass existing defenses, and defenses with complex/stochastic models or universal patch properties are relatively robust. We hope that our analyses will serve as guidance on properly evaluating patch attacks/defenses and advancing their design. Code and dataset are available at https://github.com/Gandolfczjh/APDE, where we will keep integrating new attacks/defenses.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.00649v2-abstract-full').style.display = 'none'; document.getElementById('2508.00649v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 1 August, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ICCV 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.22879">arXiv:2507.22879</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.22879">pdf</a>, <a href="https://arxiv.org/ps/2507.22879">ps</a>, <a href="https://arxiv.org/format/2507.22879">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        RecGPT Technical Report
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+C">Chao Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+D">Dian Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+G">Gaoyang Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+J">Jiakai Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+J">Jian Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jing Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+M">Mao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dai%2C+S">Sunhao Dai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+W">Wen Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+W">Wenjun Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+Y">Yuning Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Z">Zhujin Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+B">Bo Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+C">Chi Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+D">Dimin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+D">Dixuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+F">Fan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+F">Fan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+H">Haibin Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Haozhuang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+J">Jialin Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Jiamang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+J">Jiawei Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+J">Jin Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+J">Ju Huang</a>
      , et al. (29 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.22879v2-abstract-short" style="display: inline;">
        Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.22879v2-abstract-full').style.display = 'inline'; document.getElementById('2507.22879v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.22879v2-abstract-full" style="display: none;">
        Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting approach often leads to overfitting to narrow historical preferences, failing to capture users&#39; evolving and latent interests. As a result, it reinforces filter bubbles and long-tail phenomena, ultimately harming user experience and threatening the sustainability of the whole recommendation ecosystem.
  To address these challenges, we rethink the overall design paradigm of recommender systems and propose RecGPT, a next-generation framework that places user intent at the center of the recommendation pipeline. By integrating large language models (LLMs) into key stages of user interest mining, item retrieval, and explanation generation, RecGPT transforms log-fitting recommendation into an intent-centric process. To effectively align general-purpose LLMs to the above domain-specific recommendation tasks at scale, RecGPT incorporates a multi-stage training paradigm, which integrates reasoning-enhanced pre-alignment and self-training evolution, guided by a Human-LLM cooperative judge system. Currently, RecGPT has been fully deployed on the Taobao App. Online experiments demonstrate that RecGPT achieves consistent performance gains across stakeholders: users benefit from increased content diversity and satisfaction, merchants and the platform gain greater exposure and conversions. These comprehensive improvement results across all stakeholders validates that LLM-driven, intent-centric design can foster a more sustainable and mutually beneficial recommendation ecosystem.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.22879v2-abstract-full').style.display = 'none'; document.getElementById('2507.22879v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 July, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.21844">arXiv:2507.21844</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.21844">pdf</a>, <a href="https://arxiv.org/ps/2507.21844">ps</a>, <a href="https://arxiv.org/format/2507.21844">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Architecture Distillation Made Simple with Redundancy Suppression
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Weijia Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yuehao Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ran%2C+W">Wu Ran</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+C">Chao Ma</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.21844v1-abstract-short" style="display: inline;">
        We describe a simple method for cross-architecture knowledge distillation, where the knowledge transfer is cast into a redundant information suppression formulation. Existing methods introduce sophisticated modules, architecture-tailored designs, and excessive parameters, which impair their efficiency and applicability. We propose to extract the architecture-agnostic knowledge in heterogeneous rep&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21844v1-abstract-full').style.display = 'inline'; document.getElementById('2507.21844v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.21844v1-abstract-full" style="display: none;">
        We describe a simple method for cross-architecture knowledge distillation, where the knowledge transfer is cast into a redundant information suppression formulation. Existing methods introduce sophisticated modules, architecture-tailored designs, and excessive parameters, which impair their efficiency and applicability. We propose to extract the architecture-agnostic knowledge in heterogeneous representations by reducing the redundant architecture-exclusive information. To this end, we present a simple redundancy suppression distillation (RSD) loss, which comprises cross-architecture invariance maximisation and feature decorrelation objectives. To prevent the student from entirely losing its architecture-specific capabilities, we further design a lightweight module that decouples the RSD objective from the student&#39;s internal representations. Our method is devoid of the architecture-specific designs and complex operations in the pioneering method of OFA. It outperforms OFA on CIFAR-100 and ImageNet-1k benchmarks with only a fraction of their parameter overhead, which highlights its potential as a simple and strong baseline to the cross-architecture distillation community.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21844v1-abstract-full').style.display = 'none'; document.getElementById('2507.21844v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ICCV 2025 (Highlight)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.21826">arXiv:2507.21826</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.21826">pdf</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optics">physics.optics</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Inkjet Printed Liquid Crystal Droplet for Complex Beam Manipulation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+M">Mengmeng Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=He%2C+C">Chao He</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Elston%2C+S+J">Steve J. Elston</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yifei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+B">Bohan Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhao%2C+Z">Zimo Zhao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qiu%2C+X">Xuke Qiu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castrej%C3%B3n-Pita%2C+A+A">Alfonso A. Castrejón-Pita</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Morris%2C+S+M">Stephen M. Morris</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.21826v1-abstract-short" style="display: inline;">
        The inkjet-fabricated liquid crystal (LC) droplet device not only capitalizes on the intrinsic birefringence properties of liquid crystals but also leverages the hemispherical shape of droplet devices on substrates. This configuration facilitates self-alignment of the LC director under the influence of surface tension. The LC droplet devices we fabricated are capable of intricate beam manipulation&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21826v1-abstract-full').style.display = 'inline'; document.getElementById('2507.21826v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.21826v1-abstract-full" style="display: none;">
        The inkjet-fabricated liquid crystal (LC) droplet device not only capitalizes on the intrinsic birefringence properties of liquid crystals but also leverages the hemispherical shape of droplet devices on substrates. This configuration facilitates self-alignment of the LC director under the influence of surface tension. The LC droplet devices we fabricated are capable of intricate beam manipulation, encompassing both generation and analysis of light beams. Such devices possess substantial prospective applications in the fields of optical communications and light beam characterization, highlighting their significant potential for advancement in optical technologies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21826v1-abstract-full').style.display = 'none'; document.getElementById('2507.21826v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.21809">arXiv:2507.21809</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.21809">pdf</a>, <a href="https://arxiv.org/ps/2507.21809">ps</a>, <a href="https://arxiv.org/format/2507.21809">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=HunyuanWorld+Team"> HunyuanWorld Team</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Z">Zhenwei Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yuhao Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+J">Junta Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+Z">Zixiao Gu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+H">Haoyuan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zuo%2C+X">Xuhui Zuo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+T">Tianyu Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+W">Wenhuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Sheng Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lian%2C+Y">Yihang Lian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tsai%2C+Y">Yulin Tsai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+L">Lifu Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+S">Sicong Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+P">Puhua Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+X">Xianghui Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+D">Dongyuan Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yixuan Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mao%2C+X">Xinyue Mao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jiaao Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Junlin Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Jihong Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+M">Meng Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+L">Liang Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jia%2C+Y">Yiwen Jia</a>
      , et al. (30 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.21809v2-abstract-short" style="display: inline;">
        Creating immersive and playable 3D worlds from texts or images remains a fundamental challenge in computer vision and graphics. Existing world generation approaches typically fall into two categories: video-based methods that offer rich diversity but lack 3D consistency and rendering efficiency, and 3D-based methods that provide geometric consistency but struggle with limited training data and mem&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21809v2-abstract-full').style.display = 'inline'; document.getElementById('2507.21809v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.21809v2-abstract-full" style="display: none;">
        Creating immersive and playable 3D worlds from texts or images remains a fundamental challenge in computer vision and graphics. Existing world generation approaches typically fall into two categories: video-based methods that offer rich diversity but lack 3D consistency and rendering efficiency, and 3D-based methods that provide geometric consistency but struggle with limited training data and memory-inefficient representations. To address these limitations, we present HunyuanWorld 1.0, a novel framework that combines the best of both worlds for generating immersive, explorable, and interactive 3D scenes from text and image conditions. Our approach features three key advantages: 1) 360° immersive experiences via panoramic world proxies; 2) mesh export capabilities for seamless compatibility with existing computer graphics pipelines; 3) disentangled object representations for augmented interactivity. The core of our framework is a semantically layered 3D mesh representation that leverages panoramic images as 360° world proxies for semantic-aware world decomposition and reconstruction, enabling the generation of diverse 3D worlds. Extensive experiments demonstrate that our method achieves state-of-the-art performance in generating coherent, explorable, and interactive 3D worlds while enabling versatile applications in virtual reality, physical simulation, game development, and interactive content creation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.21809v2-abstract-full').style.display = 'none'; document.getElementById('2507.21809v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 29 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Technical Report; Project Page: https://3d-models.hunyuan.tencent.com/world/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.20618">arXiv:2507.20618</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.20618">pdf</a>, <a href="https://arxiv.org/ps/2507.20618">ps</a>, <a href="https://arxiv.org/format/2507.20618">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Precise Measurement of Chromo-Electric Dipole Moment of the Charm Quark
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (697 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.20618v1-abstract-short" style="display: inline;">
        The combined symmetry of charge conjugation and parity ($C\!P$) is tested in the hadronic transition $ψ(3686)\toπ^+π^{-}J/ψ$, utilizing a dataset of 2.7 billion $ψ(3686)$ events collected by the BESIII detector at the BEPCII collider. The resulting asymmetry observable is $A_{cp} = (0.6\pm1.8_{\rm stat}\pm0.1_{\rm sys})\times10^{-4}$ by combining the two channels $J/ψ\to e^+e^-$ and&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20618v1-abstract-full').style.display = 'inline'; document.getElementById('2507.20618v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.20618v1-abstract-full" style="display: none;">
        The combined symmetry of charge conjugation and parity ($C\!P$) is tested in the hadronic transition $ψ(3686)\toπ^+π^{-}J/ψ$, utilizing a dataset of 2.7 billion $ψ(3686)$ events collected by the BESIII detector at the BEPCII collider. The resulting asymmetry observable is $A_{cp} = (0.6\pm1.8_{\rm stat}\pm0.1_{\rm sys})\times10^{-4}$ by combining the two channels $J/ψ\to e^+e^-$ and $J/ψ\toμ^+μ^-$ with unprecedented precision. Meanwhile, by considering the relationship between the chromo-electric dipole moment (CEDM) and the $A_{cp}$ observable derived from the quantum chromo-dynamics multipole expansion (QCDME) theory based on Chen-Kuang, as well as Cornell potential model, we yield the results of charm quark&#39;s CEDM with $d^{\prime}_{c} = (2.6\pm7.8_{\rm stat}\pm0.4_{\rm sys}\pm0.6_{\rm theo})\times10^{-16}$ $e\cdot$cm, and $d^{\prime}_{c} = (3.5\pm10.5_{\rm stat}\pm0.6_{\rm sys}\pm0.5_{\rm theo})\times10^{-16}$ $e\cdot$cm, respectively. These results correspond to an upper limit of $|d^{\prime}_{c} |&lt;2.1\times10^{-15}\ e\cdot$cm at a 90\% confidence level, an order of magnitude improvement in sensitivity compared to the previous direct bound using the same decay process. Our results provide insights into the dynamics of charmonium hadronic transitions, shedding light on their behavior in the context of $C\!P$ violation.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20618v1-abstract-full').style.display = 'none'; document.getElementById('2507.20618v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 3 figures, 1 table, etc</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.20534">arXiv:2507.20534</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.20534">pdf</a>, <a href="https://arxiv.org/ps/2507.20534">ps</a>, <a href="https://arxiv.org/format/2507.20534">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Kimi K2: Open Agentic Intelligence
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Kimi+Team"> Kimi Team</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Yifan Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+Y">Yiping Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+G">Guanduo Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Jiahao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+N">Ningxin Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+R">Ruijue Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yanru Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yuankun Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yutian Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Zhuofu Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cui%2C+J">Jialei Cui</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+H">Hao Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+M">Mengnan Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+A">Angang Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+C">Chenzhuang Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+D">Dikang Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+Y">Yulun Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+Y">Yu Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+Y">Yichen Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fu%2C+K">Kelin Fu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+B">Bofei Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+H">Hongcheng Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+P">Peizhong Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+T">Tong Gao</a>
      , et al. (144 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.20534v1-abstract-short" style="display: inline;">
        We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token efficiency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero loss spike.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20534v1-abstract-full').style.display = 'inline'; document.getElementById('2507.20534v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.20534v1-abstract-full" style="display: none;">
        We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token efficiency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments.
  Kimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding, mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints to facilitate future research and applications of agentic intelligence.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.20534v1-abstract-full').style.display = 'none'; document.getElementById('2507.20534v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">tech report of Kimi K2</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.19672">arXiv:2507.19672</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.19672">pdf</a>, <a href="https://arxiv.org/ps/2507.19672">ps</a>, <a href="https://arxiv.org/format/2507.19672">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+H">Haoran Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fang%2C+L">Luyang Fang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+R">Ruidong Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xinliang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+J">Jiazhang Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+H">Huimin Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+L">Lin Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Z">Ziyu Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Z">Zeliang Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+T">Tao Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yingchuan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zidan%2C+A+H">Arif Hassan Zidan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+J">Jinwen Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jincheng Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+M">Meizhi Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+H">Hanqi Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gong%2C+X">Xilin Gong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+W">Weidi Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+B">Bolun Sun</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yongkai Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+T">Terry Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+S">Shushan Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+Y">Yifan Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Junhao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiang%2C+H">Haotian Xiang</a>
      , et al. (25 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.19672v1-abstract-short" style="display: inline;">
        Due to the remarkable capabilities and growing impact of large language models (LLMs), they have been deeply integrated into many aspects of society. Thus, ensuring their alignment with human values and intentions has emerged as a critical challenge. This survey provides a comprehensive overview of practical alignment techniques, training protocols, and empirical findings in LLM alignment. We anal&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.19672v1-abstract-full').style.display = 'inline'; document.getElementById('2507.19672v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.19672v1-abstract-full" style="display: none;">
        Due to the remarkable capabilities and growing impact of large language models (LLMs), they have been deeply integrated into many aspects of society. Thus, ensuring their alignment with human values and intentions has emerged as a critical challenge. This survey provides a comprehensive overview of practical alignment techniques, training protocols, and empirical findings in LLM alignment. We analyze the development of alignment methods across diverse paradigms, characterizing the fundamental trade-offs between core alignment objectives. Our analysis shows that while supervised fine-tuning enables basic instruction-following, preference-based methods offer more flexibility for aligning with nuanced human intent. We discuss state-of-the-art techniques, including Direct Preference Optimization (DPO), Constitutional AI, brain-inspired methods, and alignment uncertainty quantification (AUQ), highlighting their approaches to balancing quality and efficiency. We review existing evaluation frameworks and benchmarking datasets, emphasizing limitations such as reward misspecification, distributional robustness, and scalable oversight. We summarize strategies adopted by leading AI labs to illustrate the current state of practice. We conclude by outlining open problems in oversight, value pluralism, robustness, and continuous alignment. This survey aims to inform both researchers and practitioners navigating the evolving landscape of LLM alignment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.19672v1-abstract-full').style.display = 'none'; document.getElementById('2507.19672v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">119 pages, 10 figures, 7 tables</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.19040">arXiv:2507.19040</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.19040">pdf</a>, <a href="https://arxiv.org/ps/2507.19040">ps</a>, <a href="https://arxiv.org/format/2507.19040">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Peng%2C+Y">Yizhou Peng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chao%2C+Y">Yi-Wen Chao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ng%2C+D">Dianwen Ng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+Y">Yukun Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ni%2C+C">Chongjia Ni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+B">Bin Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chng%2C+E+S">Eng Siong Chng</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.19040v1-abstract-short" style="display: inline;">
        Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine interactions by allowing real-time user interruptions and backchanneling, compared to traditional SDS that rely on turn-taking. However, existing benchmarks lack metrics for FD scenes, e.g., evaluating model performance during user interruptions. In this paper, we present a comprehensive FD benchmarking pipeline utilizin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.19040v1-abstract-full').style.display = 'inline'; document.getElementById('2507.19040v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.19040v1-abstract-full" style="display: none;">
        Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine interactions by allowing real-time user interruptions and backchanneling, compared to traditional SDS that rely on turn-taking. However, existing benchmarks lack metrics for FD scenes, e.g., evaluating model performance during user interruptions. In this paper, we present a comprehensive FD benchmarking pipeline utilizing LLMs, TTS, and ASR to address this gap. It assesses FDSDS&#39;s ability to handle user interruptions, manage delays, and maintain robustness in challenging scenarios with diverse novel metrics. We applied our benchmark to three open-source FDSDS (Moshi, Freeze-omni, and VITA-1.5) using over 40 hours of generated speech, with 293 simulated conversations and 1,200 interruptions. The results show that all models continue to face challenges, such as failing to respond to user interruptions, under frequent disruptions and noisy conditions. Demonstrations, data, and code will be released.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.19040v1-abstract-full').style.display = 'none'; document.getElementById('2507.19040v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to Interspeech 2025. 5 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.18576">arXiv:2507.18576</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.18576">pdf</a>, <a href="https://arxiv.org/ps/2507.18576">ps</a>, <a href="https://arxiv.org/format/2507.18576">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\circ}$ Law
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lab%2C+S+A">Shanghai AI Lab</a>, 
      
      <a href="/search/?searchtype=author&amp;query=%3A"> :</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+Y">Yicheng Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+G">Guanxu Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+M">Mingkang Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Y">Yunhao Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+C">Chiyu Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+L">Lingjie Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+S">Sirui Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+X">Xinquan Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+J">Jie Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+Y">Yu Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+D">Dengke Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+Y">Yizhuo Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+D">Dan Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+X">Xiaoshan Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+Y">Yi Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+Z">Zhichen Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+L">Lingxiao Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+Y">Yuyu Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+X">Xinshun Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fu%2C+Y">Yanwei Fu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+Y">Yuxuan Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ge%2C+R">Ruijun Ge</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gu%2C+T">Tianle Gu</a>
      , et al. (93 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.18576v3-abstract-short" style="display: inline;">
        We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18576v3-abstract-full').style.display = 'inline'; document.getElementById('2507.18576v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.18576v3-abstract-full" style="display: none;">
        We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha&#39; moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18576v3-abstract-full').style.display = 'none'; document.getElementById('2507.18576v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 24 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">47 pages, 18 figures, authors are listed in alphabetical order by their last names; v3 modifies minor issues</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.18172">arXiv:2507.18172</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.18172">pdf</a>, <a href="https://arxiv.org/ps/2507.18172">ps</a>, <a href="https://arxiv.org/format/2507.18172">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Instrumentation and Detectors">physics.ins-det</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Silicon single-photon detector achieving over 84% photon detection efficiency with flexible operation modes
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=An%2C+D">Dong An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+C">Chao Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+M">Ming-Yang Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guo%2C+A">Anran Guo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Junsong Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Ruizhi Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+H">Huaping Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+X">Xiu-Ping Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+X">Xiao-Hui Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Q">Qiang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Jun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pan%2C+J">Jian-Wei Pan</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.18172v1-abstract-short" style="display: inline;">
        Silicon single-photon detectors (Si SPDs) play a crucial role in detecting single photons in the visible spectrum. For various applications, photon detection efficiency (PDE) is the most critical characteristic for effectively collecting photons. Here, we present a Si SPD with a remarkable PDE of up to 84.4% at 785 nm, supporting multiple operation modes. We design and fabricate a thick-junction S&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18172v1-abstract-full').style.display = 'inline'; document.getElementById('2507.18172v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.18172v1-abstract-full" style="display: none;">
        Silicon single-photon detectors (Si SPDs) play a crucial role in detecting single photons in the visible spectrum. For various applications, photon detection efficiency (PDE) is the most critical characteristic for effectively collecting photons. Here, we present a Si SPD with a remarkable PDE of up to 84.4% at 785 nm, supporting multiple operation modes. We design and fabricate a thick-junction Si single-photon avalanche diode (SPAD) that enhances the avalanche probability through a backside-illumination structure, while minimizing noise through the design of a doping-compensated avalanche region. To maximize PDE, we implement a readout circuit with a 50 V quenching voltage, enabling operation in free-running, gating, or hybrid modes. The SPAD, along with its readout circuits and affiliated circuits, is integrated into a compact SPD module. In free-running mode, the module achieves a maximum PDE of 84.4%, with a dark count rate of 260 cps, and an afterpulse probability of 2.9% at 268 K. This work provides a practical solution for applications requiring ultra-high-efficiency Si SPD with multiple operation modes.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.18172v1-abstract-full').style.display = 'none'; document.getElementById('2507.18172v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by IEEE Journal of Selected Topics in Quantum Electronics</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.16632">arXiv:2507.16632</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.16632">pdf</a>, <a href="https://arxiv.org/ps/2507.16632">ps</a>, <a href="https://arxiv.org/format/2507.16632">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Sound">cs.SD</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Audio and Speech Processing">eess.AS</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Step-Audio 2 Technical Report
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+B">Boyong Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+C">Chao Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+C">Chen Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yi%2C+C">Cheng Yi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+C">Chengli Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tian%2C+F">Fei Tian</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+F">Feiyu Shen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+G">Gang Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+H">Haoyang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jingbei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+M">Mingrui Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+P">Peng Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+W">Wang You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X+T">Xiangyu Tony Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xingyuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+X">Xuerui Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+Y">Yayue Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yechang Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yuxin Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Y">Yuxin Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+Z">Zhao You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+B">Brian Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wan%2C+C">Changyi Wan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+H">Hanpeng Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhen%2C+J">Jiangjie Zhen</a>
      , et al. (84 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.16632v3-abstract-short" style="display: inline;">
        This paper presents Step-Audio 2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automatic speech recognition (ASR) and audio understanding. To facilitate genuine end-to-end speech convers&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16632v3-abstract-full').style.display = 'inline'; document.getElementById('2507.16632v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.16632v3-abstract-full" style="display: none;">
        This paper presents Step-Audio 2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automatic speech recognition (ASR) and audio understanding. To facilitate genuine end-to-end speech conversation, Step-Audio 2 incorporates the generation of discrete audio tokens into language modeling, significantly enhancing its responsiveness to paralinguistic information such as speaking styles and emotions. To effectively leverage the rich textual and acoustic knowledge in real-world data, Step-Audio 2 integrates retrieval-augmented generation (RAG) and is able to call external tools such as web search to mitigate hallucination and audio search to switch timbres. Trained on millions of hours of speech and audio data, Step-Audio 2 delivers intelligence and expressiveness across diverse conversational scenarios. Evaluation results demonstrate that Step-Audio 2 achieves state-of-the-art performance on various audio understanding and conversational benchmarks compared to other open-source and commercial solutions. Please visit https://github.com/stepfun-ai/Step-Audio2 for more information.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16632v3-abstract-full').style.display = 'none'; document.getElementById('2507.16632v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 22 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">v3: Added introduction and evaluation results of Step-Audio 2 mini</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.16524">arXiv:2507.16524</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.16524">pdf</a>, <a href="https://arxiv.org/ps/2507.16524">ps</a>, <a href="https://arxiv.org/format/2507.16524">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiaoyan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zeju Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+Y">Yifan Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qi%2C+J">Jiaxing Qi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Z">Zhifei Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+R">Ruifei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xiangde Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.16524v1-abstract-short" style="display: inline;">
        New era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or segmenting independent objects to perform these tasks, which limits their spatial awareness due to insufficient representation of the richness inherent in 3D scenes. To overc&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16524v1-abstract-full').style.display = 'inline'; document.getElementById('2507.16524v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.16524v1-abstract-full" style="display: none;">
        New era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or segmenting independent objects to perform these tasks, which limits their spatial awareness due to insufficient representation of the richness inherent in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D MLLM specifically designed to enhance spatial awareness for 3D vision-language tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM integrates an LLM backbone with a progressive spatial awareness scheme that progressively captures spatial information as the perception field expands, generating location-enriched 3D scene embeddings to serve as visual prompts. Furthermore, we introduce two novel tasks: 3D object distance measurement and 3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate the model&#39;s spatial awareness capabilities. Experimental results demonstrate that Spatial 3D-LLM achieves state-of-the-art performance across a wide range of 3D vision-language tasks, revealing the improvements stemmed from our progressive spatial awareness scheme of mining more profound spatial information. Our code is available at https://github.com/bjshuyuan/Spatial-3D-LLM.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16524v1-abstract-full').style.display = 'none'; document.getElementById('2507.16524v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by ICME2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.16317">arXiv:2507.16317</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.16317">pdf</a>, <a href="https://arxiv.org/ps/2507.16317">ps</a>, <a href="https://arxiv.org/format/2507.16317">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">astro-ph.IM</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Lunar Orbital VLBI Experiment: motivation, scientific purposes and status
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hong%2C+X">Xiaoyu Hong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+W">Weiren Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Q">Qinghui Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+D">Dengyun Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+C">Chi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shuai%2C+T">Tao Shuai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhong%2C+W">Weiye Zhong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+R">Renjie Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+Y">Yonghui Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Lihua Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiong%2C+L">Liang Xiong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tang%2C+Y">Yuhua Tang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zou%2C+Y">Yongliao Zou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+H">Haitao Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+G">Guangli Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+J">Jianfeng Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xue%2C+C">Changbin Xue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Geng%2C+H">Hao Geng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+J">Juan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+X">Xiaojing Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+Y">Yong Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+W">Weimin Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+L">Lei Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+F">Fang Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+X">Xiuzhong Zhang</a>
      , et al. (25 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.16317v1-abstract-short" style="display: inline;">
        The Lunar Orbital VLBI Experiment (LOVEX) is a scientific component of the Chinese Lunar Exploration Project (CLEP) Chang&#39;E-7. The spaceborne component of LOVEX is implemented onboard the relay satellite QueQiao-2, which was launched on 2024 March 20, and later placed into an elliptical selenocentric orbit. The LOVEX-specific payload consists of an X-band cryogenic receiver, a hydrogen maser frequ&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16317v1-abstract-full').style.display = 'inline'; document.getElementById('2507.16317v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.16317v1-abstract-full" style="display: none;">
        The Lunar Orbital VLBI Experiment (LOVEX) is a scientific component of the Chinese Lunar Exploration Project (CLEP) Chang&#39;E-7. The spaceborne component of LOVEX is implemented onboard the relay satellite QueQiao-2, which was launched on 2024 March 20, and later placed into an elliptical selenocentric orbit. The LOVEX-specific payload consists of an X-band cryogenic receiver, a hydrogen maser frequency standard, and VLBI data formatting and acquisition electronics. Several components of the QueQiao-2 nominal onboard instrumentation, such as the 4.2-meter antenna, the data storage device, and the downlink communication system, contribute to the overall spaceborne VLBI instrumentation. This allows us to form a space radio telescope capable of co-observing with Earth-based radio telescopes in VLBI mode. In this space VLBI system, the length of the baseline extends up to approximately 380,000 km. This paper presents the LOVEX scientific objectives, architecture, instrumentation, pre-launch tests, in-flight verification and calibration, and the first in-flight detections of interferometric response (&#39;&#39;fringes&#39;&#39;) achieved through observations of the quasar AO 0235+164 and the Chang&#39;E-6 orbital module, positioned at the Sun-Earth Lagrange point L2. These initial results demonstrate the successful performance of LOVEX, verifying its capability for both astronomical and spacecraft tracking observations at ultra-long VLBI baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.16317v1-abstract-full').style.display = 'none'; document.getElementById('2507.16317v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted for publication in Science China: Physics, Mechanics &amp; Astronomy</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.14430">arXiv:2507.14430</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.14430">pdf</a>, <a href="https://arxiv.org/ps/2507.14430">ps</a>, <a href="https://arxiv.org/format/2507.14430">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yan%2C+X">Xiaolin Yan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+Y">Yangxing Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zheng%2C+J">Jiazhang Zheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+C">Chi Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Du%2C+M">Mingyu Du</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+C">Caisheng Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+H">Haoyang Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ding%2C+M">Ming Ding</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yuan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liao%2C+Q">Qiuping Liao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+L">Linfeng Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mei%2C+Z">Zhili Mei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wan%2C+S">Siyu Wan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+L">Li Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhong%2C+R">Ruyi Zhong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+J">Jiangling Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xule Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hu%2C+H">Huihui Hu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yue%2C+J">Jiameng Yue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cheng%2C+R">Ruohui Cheng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Q">Qi Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+L">Liangqing Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+K">Ke Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chi Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jing%2C+C">Chufei Jing</a>
      , et al. (31 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.14430v2-abstract-short" style="display: inline;">
        Large language models (LLMs) have recently achieved significant advances in reasoning and demonstrated their advantages in solving challenging problems. Yet, their effectiveness in the semiconductor display industry remains limited due to a lack of domain-specific training and expertise. To bridge this gap, we present X-Intelligence 3.0, the first high-performance reasoning model specifically deve&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.14430v2-abstract-full').style.display = 'inline'; document.getElementById('2507.14430v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.14430v2-abstract-full" style="display: none;">
        Large language models (LLMs) have recently achieved significant advances in reasoning and demonstrated their advantages in solving challenging problems. Yet, their effectiveness in the semiconductor display industry remains limited due to a lack of domain-specific training and expertise. To bridge this gap, we present X-Intelligence 3.0, the first high-performance reasoning model specifically developed for the semiconductor display industry. This model is designed to deliver expert-level understanding and reasoning for the industry&#39;s complex challenges. Leveraging a carefully curated industry knowledge base, the model undergoes supervised fine-tuning and reinforcement learning to enhance its reasoning and comprehension capabilities. To further accelerate development, we implemented an automated evaluation framework that simulates expert-level assessments. We also integrated a domain-specific retrieval-augmented generation (RAG) mechanism, resulting in notable performance gains on benchmark datasets. Despite its relatively compact size of 32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B across multiple evaluations. This demonstrates its exceptional efficiency and establishes it as a powerful solution to the longstanding reasoning challenges faced by the semiconductor display industry.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.14430v2-abstract-full').style.display = 'none'; document.getElementById('2507.14430v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 July, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Technical Report</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.14186">arXiv:2507.14186</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.14186">pdf</a>, <a href="https://arxiv.org/ps/2507.14186">ps</a>, <a href="https://arxiv.org/format/2507.14186">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Networking and Internet Architecture">cs.NI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Signal Processing">eess.SP</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+X">Xiaojie Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+Z">Zhijie Cai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qi%2C+N">Nan Qi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dong%2C+C">Chao Dong</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+G">Guangxu Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+H">Haixia Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Q">Qihui Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jin%2C+S">Shi Jin</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.14186v1-abstract-short" style="display: inline;">
        The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.14186v1-abstract-full').style.display = 'inline'; document.getElementById('2507.14186v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.14186v1-abstract-full" style="display: none;">
        The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer an opportunity for data-driven low-altitude coverage prediction. However, collecting extensive low-altitude road test data is cost-prohibitive, often yielding only sparse samples per BS. This scarcity results in two primary challenges: imbalanced feature sampling due to limited variability in high-dimensional operational parameters against the backdrop of substantial changes in low-dimensional sampling locations, and diminished generalizability stemming from insufficient data samples. To overcome these obstacles, we introduce a dual strategy comprising expert knowledge-based feature compression and disentangled representation learning. The former reduces feature space complexity by leveraging communications expertise, while the latter enhances model generalizability through the integration of propagation models and distinct subnetworks that capture and aggregate the semantic representations of latent features. Experimental evaluation confirms the efficacy of our framework, yielding a 7% reduction in error compared to the best baseline algorithm. Real-network validations further attest to its reliability, achieving practical prediction accuracy with MAE errors at the 5dB level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.14186v1-abstract-full').style.display = 'none'; document.getElementById('2507.14186v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper has been submitted to IEEE for possible publication</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.13575">arXiv:2507.13575</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.13575">pdf</a>, <a href="https://arxiv.org/ps/2507.13575">ps</a>, <a href="https://arxiv.org/format/2507.13575">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Apple Intelligence Foundation Language Models: Tech Report 2025
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+E">Ethan Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Larsen%2C+A+B+L">Anders Boesen Lindbo Larsen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chen Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+X">Xiyou Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Qin%2C+J">Jun Qin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yap%2C+D+A">Dian Ang Yap</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raghavan%2C+N">Narendran Raghavan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chang%2C+X">Xuankai Chang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bowler%2C+M">Margit Bowler</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yildiz%2C+E">Eray Yildiz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Peebles%2C+J">John Peebles</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Coleman%2C+H+G">Hannah Gillis Coleman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ronchi%2C+M">Matteo Ronchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gray%2C+P">Peter Gray</a>, 
      
      <a href="/search/?searchtype=author&amp;query=You%2C+K">Keen You</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Spalvieri-Kruse%2C+A">Anthony Spalvieri-Kruse</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pang%2C+R">Ruoming Pang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Reed Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+Y">Yuli Yang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soroush%2C+E">Emad Soroush</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lu%2C+Z">Zhiyun Lu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+C">Crystal Xiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Situ%2C+R">Rong Situ</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huffaker%2C+J">Jordan Huffaker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Griffiths%2C+D">David Griffiths</a>
      , et al. (373 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.13575v3-abstract-short" style="display: inline;">
        We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: i a 3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts PT-MoE transform&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.13575v3-abstract-full').style.display = 'inline'; document.getElementById('2507.13575v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.13575v3-abstract-full" style="display: none;">
        We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: i a 3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts PT-MoE transformer that combines track parallelism, mixture-of-experts sparse computation, and interleaved global-local attention to deliver high quality with competitive cost on Apple&#39;s Private Cloud Compute platform. Both models are trained on large-scale multilingual and multimodal datasets sourced via responsible web crawling, licensed corpora, and high-quality synthetic data, then further refined with supervised fine-tuning and reinforcement learning on a new asynchronous platform. The resulting models support several additional languages while understanding images and executing tool calls. In public benchmarks and human evaluations, both the server model and the on-device model match or surpass comparably sized open baselines.
  A new Swift-centric Foundation Models framework exposes guided generation, constrained tool calling, and LoRA adapter fine-tuning, allowing developers to integrate these capabilities with a few lines of code. The latest advancements in Apple Intelligence models are grounded in our Responsible AI approach with safeguards like content filtering and locale-specific evaluation, as well as our commitment to protecting our users&#39; privacy with innovations like Private Cloud Compute.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.13575v3-abstract-full').style.display = 'none'; document.getElementById('2507.13575v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 27 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 July, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.13395">arXiv:2507.13395</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.13395">pdf</a>, <a href="https://arxiv.org/ps/2507.13395">ps</a>, <a href="https://arxiv.org/format/2507.13395">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gao%2C+X">Xuanqi Gao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+W">Weipeng Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhai%2C+J">Juan Zhai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+S">Shiqing Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+S">Siyi Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+X">Xinyang Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shen%2C+C">Chao Shen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.13395v1-abstract-short" style="display: inline;">
        The advent of neural machine translation (NMT) has revolutionized cross-lingual communication, yet preserving stylistic nuances remains a significant challenge. While existing approaches often require parallel corpora for style preservation, we introduce Babel, a novel framework that enhances stylistic fidelity in NMT using only monolingual corpora. Babel employs two key components: (1) a style de&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.13395v1-abstract-full').style.display = 'inline'; document.getElementById('2507.13395v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.13395v1-abstract-full" style="display: none;">
        The advent of neural machine translation (NMT) has revolutionized cross-lingual communication, yet preserving stylistic nuances remains a significant challenge. While existing approaches often require parallel corpora for style preservation, we introduce Babel, a novel framework that enhances stylistic fidelity in NMT using only monolingual corpora. Babel employs two key components: (1) a style detector based on contextual embeddings that identifies stylistic disparities between source and target texts, and (2) a diffusion-based style applicator that rectifies stylistic inconsistencies while maintaining semantic integrity. Our framework integrates with existing NMT systems as a post-processing module, enabling style-aware translation without requiring architectural modifications or parallel stylistic data. Extensive experiments on five diverse domains (law, literature, scientific writing, medicine, and educational content) demonstrate Babel&#39;s effectiveness: it identifies stylistic inconsistencies with 88.21% precision and improves stylistic preservation by 150% while maintaining a high semantic similarity score of 0.92. Human evaluation confirms that translations refined by Babel better preserve source text style while maintaining fluency and adequacy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.13395v1-abstract-full').style.display = 'none'; document.getElementById('2507.13395v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.12916">arXiv:2507.12916</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.12916">pdf</a>, <a href="https://arxiv.org/ps/2507.12916">ps</a>, <a href="https://arxiv.org/format/2507.12916">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TNNLS.2025.3581411">10.1109/TNNLS.2025.3581411 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+Y">Yifan Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+C">Chao Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+H">Hanqi Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+X">Xiaoyan Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+R">Ruifei Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Y">Yiwei Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Z">Zihao Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+Z">Zeju Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+X">Xiangde Liu</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.12916v1-abstract-short" style="display: inline;">
        Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend Large Language Models (LLMs) for tackling tasks of 3D scene understanding. Current methods rely heavily on 3D point clouds, but the 3D point cloud reconstruction of an indoor scene often results in information loss. Som&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.12916v1-abstract-full').style.display = 'inline'; document.getElementById('2507.12916v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.12916v1-abstract-full" style="display: none;">
        Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend Large Language Models (LLMs) for tackling tasks of 3D scene understanding. Current methods rely heavily on 3D point clouds, but the 3D point cloud reconstruction of an indoor scene often results in information loss. Some textureless planes or repetitive patterns are prone to omission and manifest as voids within the reconstructed 3D point clouds. Besides, objects with complex structures tend to introduce distortion of details caused by misalignments between the captured images and the dense reconstructed point clouds. 2D multi-view images present visual consistency with 3D point clouds and provide more detailed representations of scene components, which can naturally compensate for these deficiencies. Based on these insights, we propose Argus, a novel 3D multimodal framework that leverages multi-view images for enhanced 3D scene understanding with LLMs. In general, Argus can be treated as a 3D Large Multimodal Foundation Model (3D-LMM) since it takes various modalities as input(text instructions, 2D multi-view images, and 3D point clouds) and expands the capability of LLMs to tackle 3D tasks. Argus involves fusing and integrating multi-view images and camera poses into view-as-scene features, which interact with the 3D features to create comprehensive and detailed 3D-aware scene embeddings. Our approach compensates for the information loss while reconstructing 3D point clouds and helps LLMs better understand the 3D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.12916v1-abstract-full').style.display = 'none'; document.getElementById('2507.12916v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted by TNNLS2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.12619">arXiv:2507.12619</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.12619">pdf</a>, <a href="https://arxiv.org/ps/2507.12619">ps</a>, <a href="https://arxiv.org/format/2507.12619">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+R">Rui Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhi%2C+X">Xiaoyun Zhi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chi%2C+J">Jinxin Chi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+M">Menghan Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Huang%2C+L">Lixin Huang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+J">Jia Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+W">Weilun Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+X">Xing Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+W">Wenjia Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhu%2C+Z">Zhicheng Zhu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Luo%2C+D">Daowen Luo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Song%2C+Z">Zuquan Song</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yin%2C+X">Xin Yin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiang%2C+C">Chao Xiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Shuguang Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xiao%2C+W">Wencong Xiao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cooperman%2C+G">Gene Cooperman</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.12619v1-abstract-short" style="display: inline;">
        Large Language Models (LLMs) have become a cornerstone of modern AI, driving breakthroughs in natural language processing and expanding into multimodal jobs involving images, audio, and video. As with most computational software, it is important to distinguish between ordinary runtime performance and startup overhead. Prior research has focused on runtime performance: improving training efficiency&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.12619v1-abstract-full').style.display = 'inline'; document.getElementById('2507.12619v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.12619v1-abstract-full" style="display: none;">
        Large Language Models (LLMs) have become a cornerstone of modern AI, driving breakthroughs in natural language processing and expanding into multimodal jobs involving images, audio, and video. As with most computational software, it is important to distinguish between ordinary runtime performance and startup overhead. Prior research has focused on runtime performance: improving training efficiency and stability. This work focuses instead on the increasingly critical issue of startup overhead in training: the delay before training jobs begin execution. Startup overhead is particularly important in large, industrial-scale LLMs, where failures occur more frequently and multiple teams operate in iterative update-debug cycles. In one of our training clusters, more than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training startup overhead based on real production data. We analyze the components of startup cost, quantify its direct impact, and examine how it scales with job size. These insights motivate the design of Bootseer, a system-level optimization framework that addresses three primary startup bottlenecks: (a) container image loading, (b) runtime dependency installation, and (c) model checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and (c) striped HDFS-FUSE. Bootseer has been deployed in a production environment and evaluated on real LLM training workloads, demonstrating a 50% reduction in startup overhead.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.12619v1-abstract-full').style.display = 'none'; document.getElementById('2507.12619v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">18 pages, 14 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.11145">arXiv:2507.11145</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.11145">pdf</a>, <a href="https://arxiv.org/ps/2507.11145">ps</a>, <a href="https://arxiv.org/format/2507.11145">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Observation of the electromagnetic radiative decays of the \boldmath{$Λ(1520)$} and \boldmath{$Λ(1670)$} to \boldmath{$γΣ^0$}
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">M. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (697 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.11145v1-abstract-short" style="display: inline;">
        Using $(10087\pm 44)\times10^6$ $J/ψ$ events collected with the BESIII detector, we report the first observation of the electromagnetic radiative decays of the $Λ(1520)$ and $Λ(1670)$ to $γΣ^0$, with a statistical significance of $16.6σ$ and $23.5σ$, respectively. The ratio of the branching fractions $\frac{\mathcal{B}(Λ(1520)\toγΛ)}{\mathcal{B}(Λ(1520)\toγΣ^0)}$ is determined to be&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.11145v1-abstract-full').style.display = 'inline'; document.getElementById('2507.11145v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.11145v1-abstract-full" style="display: none;">
        Using $(10087\pm 44)\times10^6$ $J/ψ$ events collected with the BESIII detector, we report the first observation of the electromagnetic radiative decays of the $Λ(1520)$ and $Λ(1670)$ to $γΣ^0$, with a statistical significance of $16.6σ$ and $23.5σ$, respectively. The ratio of the branching fractions $\frac{\mathcal{B}(Λ(1520)\toγΛ)}{\mathcal{B}(Λ(1520)\toγΣ^0)}$ is determined to be $2.88\pm0.27(\text{stat.})\pm0.21(\text{syst.})$, which is in good agreement with flavor SU(3) symmetry. The branching fraction of $Λ(1520)\toγΣ^0$ is measured to be $\mathcal{B}(Λ(1520)\toγΣ^0)=(2.95\pm0.28(\text{stat.})\pm0.56(\text{syst.}))\times 10^{-3}$, corresponding to a partial width of $Γ(Λ(1520)\toγΣ^0)=(47.2\pm4.5(\text{stat.})\pm9.0(\text{syst.}))$ keV, which is inconsistent with predictions from the relativized constituent quark model and the Algebraic model. Additionally, we observe a clear resonant structure in the $γΣ^0$ mass spectrum around 1.67 GeV/$c^2$, attributed to the $Λ(1670)$. The product branching fraction $\mathcal{B}(J/ψ\to\barΛΛ(1670)+c.c.)\times\mathcal{B}(Λ(1670)\toγΣ^0)$ is measured for the first time as $(5.39\pm0.29(\text{stat.})\pm 0.44(\text{syst.}))\times 10^{-6}$. However, no corresponding structure is seen in the $γΛ$ mass spectrum, so an upper limit on the product branching fraction $\mathcal{B}(J/ψ\to\barΛΛ(1670)+c.c.)\times\mathcal{B}(Λ(1670)\toγΛ)$ is determined to be $5.97\times10^{-7}$ at the 90\% confidence level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.11145v1-abstract-full').style.display = 'none'; document.getElementById('2507.11145v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.10331">arXiv:2507.10331</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.10331">pdf</a>, <a href="https://arxiv.org/ps/2507.10331">ps</a>, <a href="https://arxiv.org/format/2507.10331">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Experiment">hep-ex</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Search for the charged lepton flavor violating decay $ψ(3686)\to e^{\pm}μ^{\mp}$
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=BESIII+Collaboration"> BESIII Collaboration</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ablikim%2C+M">M. Ablikim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Achasov%2C+M+N">M. N. Achasov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Adlarson%2C+P">P. Adlarson</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ai%2C+X+C">X. C. Ai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aliberti%2C+R">R. Aliberti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">A. Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=An%2C+Q">Q. An</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bai%2C+Y">Y. Bai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakina%2C+O">O. Bakina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ban%2C+Y">Y. Ban</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bao%2C+H+-">H. -R. Bao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Batozskaya%2C+V">V. Batozskaya</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Begzsuren%2C+K">K. Begzsuren</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berger%2C+N">N. Berger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berlowski%2C+M">M. Berlowski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M+B">M. B. Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">D. Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">F. Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianco%2C+E">E. Bianco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">A. Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyko%2C+I">I. Boyko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Briere%2C+R+A">R. A. Briere</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brueggemann%2C+A">A. Brueggemann</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cai%2C+H">H. Cai</a>
      , et al. (706 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.10331v1-abstract-short" style="display: inline;">
        By analyzing $(2367.0\pm11.1)\times10^6$ $ψ(3686)$ events collected in $e^+e^-$ collisions at $\sqrt{s}=3.686~\rm GeV$ with the BESIII detector at the BEPCII collider, we report the first search for the charged lepton flavor violating decay $ψ(3686)\to e^{\pm}μ^{\mp}$. No signal is found. An upper limit on the branching fraction $\mathcal{B}(ψ(3686)\to e^{\pm}μ^{\mp})$ is determined to be&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.10331v1-abstract-full').style.display = 'inline'; document.getElementById('2507.10331v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.10331v1-abstract-full" style="display: none;">
        By analyzing $(2367.0\pm11.1)\times10^6$ $ψ(3686)$ events collected in $e^+e^-$ collisions at $\sqrt{s}=3.686~\rm GeV$ with the BESIII detector at the BEPCII collider, we report the first search for the charged lepton flavor violating decay $ψ(3686)\to e^{\pm}μ^{\mp}$. No signal is found. An upper limit on the branching fraction $\mathcal{B}(ψ(3686)\to e^{\pm}μ^{\mp})$ is determined to be $1.4\times10^{-8}$ at the 90\% confidence level.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.10331v1-abstract-full').style.display = 'none'; document.getElementById('2507.10331v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 4 figures</span>
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
                                     
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
              class="pagination-link "
              aria-label="Page 2"
              aria-current="page">2
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=100"
              class="pagination-link "
              aria-label="Page 3"
              aria-current="page">3
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=150"
              class="pagination-link "
              aria-label="Page 4"
              aria-current="page">4
            </a>
          </li>
          
          <li>
            <a href="/search/?query=Chao+Ma&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=200"
              class="pagination-link "
              aria-label="Page 5"
              aria-current="page">5
            </a>
          </li>
          
          <li><span class="pagination-ellipsis">&hellip;</span></li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>