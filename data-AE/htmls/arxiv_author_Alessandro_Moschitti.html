<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;49 of 49 results for author: <span class="mathjax">Alessandro Moschitti</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Alessandro Moschitti">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Alessandro+Moschitti&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Alessandro Moschitti">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2508.07975">arXiv:2508.07975</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2508.07975">pdf</a>, <a href="https://arxiv.org/ps/2508.07975">ps</a>, <a href="https://arxiv.org/format/2508.07975">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Improving Document Retrieval Coherence for Semantically Equivalent Queries
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Campese%2C+S">Stefano Campese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lauriola%2C+I">Ivano Lauriola</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2508.07975v1-abstract-short" style="display: inline;">
        Dense Retrieval (DR) models have proven to be effective for Document Retrieval and Information Grounding tasks. Usually, these models are trained and optimized for improving the relevance of top-ranked documents for a given query. Previous work has shown that popular DR models are sensitive to the query and document lexicon: small variations of it may lead to a significant difference in the set of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.07975v1-abstract-full').style.display = 'inline'; document.getElementById('2508.07975v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2508.07975v1-abstract-full" style="display: none;">
        Dense Retrieval (DR) models have proven to be effective for Document Retrieval and Information Grounding tasks. Usually, these models are trained and optimized for improving the relevance of top-ranked documents for a given query. Previous work has shown that popular DR models are sensitive to the query and document lexicon: small variations of it may lead to a significant difference in the set of retrieved documents. In this paper, we propose a variation of the Multi-Negative Ranking loss for training DR that improves the coherence of models in retrieving the same documents with respect to semantically similar queries. The loss penalizes discrepancies between the top-k ranked documents retrieved for diverse but semantic equivalent queries. We conducted extensive experiments on various datasets, MS-MARCO, Natural Questions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes by our loss are subject to lower sensitivity, and, (ii) interestingly, higher accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2508.07975v1-abstract-full').style.display = 'none'; document.getElementById('2508.07975v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 August, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2502.08972">arXiv:2502.08972</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2502.08972">pdf</a>, <a href="https://arxiv.org/format/2502.08972">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Tuning-Free Personalized Alignment via Trial-Error-Explain In-Context Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cho%2C+H">Hyundong Cho</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+K">Karishma Sharma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jedema%2C+N">Nicolaas Jedema</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ribeiro%2C+L+F+R">Leonardo F. R. Ribeiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krishnan%2C+R">Ravi Krishnan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=May%2C+J">Jonathan May</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2502.08972v3-abstract-short" style="display: inline;">
        Language models are aligned to the collective voice of many, resulting in generic outputs that do not align with specific users&#39; styles. In this work, we present Trial-Error-Explain In-Context Learning (TICL), a tuning-free method that personalizes language models for text generation tasks with fewer than 10 examples per user. TICL iteratively expands an in-context learning prompt via a trial-erro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.08972v3-abstract-full').style.display = 'inline'; document.getElementById('2502.08972v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2502.08972v3-abstract-full" style="display: none;">
        Language models are aligned to the collective voice of many, resulting in generic outputs that do not align with specific users&#39; styles. In this work, we present Trial-Error-Explain In-Context Learning (TICL), a tuning-free method that personalizes language models for text generation tasks with fewer than 10 examples per user. TICL iteratively expands an in-context learning prompt via a trial-error-explain process, adding model-generated negative samples and explanations that provide fine-grained guidance towards a specific user&#39;s style. TICL achieves favorable win rates on pairwise comparisons with LLM-as-a-judge up to 91.5% against the previous state-of-the-art and outperforms competitive tuning-free baselines for personalized alignment tasks of writing emails, essays and news articles. Both lexical and qualitative analyses show that the negative samples and explanations enable language models to learn stylistic context more effectively and overcome the bias towards structural and formal phrases observed in their zero-shot outputs. By front-loading inference compute to create a user-specific in-context learning prompt that does not require extra generation steps at test time, TICL presents a novel yet simple approach for personalized alignment.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2502.08972v3-abstract-full').style.display = 'none'; document.getElementById('2502.08972v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 February, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NAACL 2025 Findings</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.14672">arXiv:2409.14672</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.14672">pdf</a>, <a href="https://arxiv.org/format/2409.14672">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Speechworthy Instruction-tuned Language Models
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cho%2C+H">Hyundong Cho</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jedema%2C+N">Nicolaas Jedema</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ribeiro%2C+L+F+R">Leonardo F. R. Ribeiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sharma%2C+K">Karishma Sharma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Szekely%2C+P">Pedro Szekely</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Janssen%2C+R">Ruben Janssen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=May%2C+J">Jonathan May</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.14672v1-abstract-short" style="display: inline;">
        Current instruction-tuned language models are exclusively trained with textual preference data and thus are often not aligned with the unique requirements of other modalities, such as speech. To better align language models with the speech domain, we explore (i) prompting strategies grounded in radio-industry best practices and (ii) preference learning using a novel speech-based preference data of&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.14672v1-abstract-full').style.display = 'inline'; document.getElementById('2409.14672v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.14672v1-abstract-full" style="display: none;">
        Current instruction-tuned language models are exclusively trained with textual preference data and thus are often not aligned with the unique requirements of other modalities, such as speech. To better align language models with the speech domain, we explore (i) prompting strategies grounded in radio-industry best practices and (ii) preference learning using a novel speech-based preference data of 20K samples, generated with a wide spectrum of prompts that induce varying dimensions of speech-suitability and labeled by annotators who listen to response pairs. Both human and automatic evaluation show that both prompting and preference learning increase the speech-suitability of popular instruction-tuned LLMs. Interestingly, we find that prompting and preference learning can be additive; combining them achieves the best win rates in head-to-head comparison, resulting in responses that are preferred or tied to the base model in 76.2% of comparisons on average. Lastly, we share lexical, syntactical, and qualitative analyses to showcase how each method contributes to improving the speech-suitability of generated responses.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.14672v1-abstract-full').style.display = 'none'; document.getElementById('2409.14672v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">EMNLP2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.10172">arXiv:2406.10172</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.10172">pdf</a>, <a href="https://arxiv.org/format/2406.10172">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Datasets for Multilingual Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Campese%2C+S">Stefano Campese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agostini%2C+F">Federico Agostini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.10172v1-abstract-short" style="display: inline;">
        Answer Sentence Selection (AS2) is a critical task for designing effective retrieval-based Question Answering (QA) systems. Most advancements in AS2 focus on English due to the scarcity of annotated datasets for other languages. This lack of resources prevents the training of effective AS2 models in different languages, creating a performance gap between QA systems in English and other locales. In&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.10172v1-abstract-full').style.display = 'inline'; document.getElementById('2406.10172v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.10172v1-abstract-full" style="display: none;">
        Answer Sentence Selection (AS2) is a critical task for designing effective retrieval-based Question Answering (QA) systems. Most advancements in AS2 focus on English due to the scarcity of annotated datasets for other languages. This lack of resources prevents the training of effective AS2 models in different languages, creating a performance gap between QA systems in English and other locales. In this paper, we introduce new high-quality datasets for AS2 in five European languages (French, German, Italian, Portuguese, and Spanish), obtained through supervised Automatic Machine Translation (AMT) of existing English AS2 datasets such as ASNQ, WikiQA, and TREC-QA using a Large Language Model (LLM). We evaluated our approach and the quality of the translated datasets through multiple experiments with different Transformer architectures. The results indicate that our datasets are pivotal in producing robust and powerful multilingual AS2 models, significantly contributing to closing the performance gap between English and other languages.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.10172v1-abstract-full').style.display = 'none'; document.getElementById('2406.10172v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.03592">arXiv:2406.03592</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.03592">pdf</a>, <a href="https://arxiv.org/format/2406.03592">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Measuring Retrieval Complexity in Question Answering Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jedema%2C+N+P">Nicolaas Paul Jedema</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ribeiro%2C+L+F+R">Leonardo F. R. Ribeiro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.03592v1-abstract-short" style="display: inline;">
        In this paper, we investigate which questions are challenging for retrieval-based Question Answering (QA). We (i) propose retrieval complexity (RC), a novel metric conditioned on the completeness of retrieved documents, which measures the difficulty of answering questions, and (ii) propose an unsupervised pipeline to measure RC given an arbitrary retrieval system. Our proposed pipeline measures RC&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.03592v1-abstract-full').style.display = 'inline'; document.getElementById('2406.03592v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.03592v1-abstract-full" style="display: none;">
        In this paper, we investigate which questions are challenging for retrieval-based Question Answering (QA). We (i) propose retrieval complexity (RC), a novel metric conditioned on the completeness of retrieved documents, which measures the difficulty of answering questions, and (ii) propose an unsupervised pipeline to measure RC given an arbitrary retrieval system. Our proposed pipeline measures RC more accurately than alternative estimators, including LLMs, on six challenging QA benchmarks. Further investigation reveals that RC scores strongly correlate with both QA performance and expert judgment across five of the six studied benchmarks, indicating that RC is an effective measure of question difficulty. Subsequent categorization of high-RC questions shows that they span a broad set of question shapes, including multi-hop, compositional, and temporal QA, indicating that RC scores can categorize a new subset of complex questions. Our system can also have a major impact on retrieval-based systems by helping to identify more challenging questions on existing datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.03592v1-abstract-full').style.display = 'none'; document.getElementById('2406.03592v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 June, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ACL 2024 (findings)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2309.12250">arXiv:2309.12250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2309.12250">pdf</a>, <a href="https://arxiv.org/format/2309.12250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kedziorski%2C+R+K">Rik Koncel Kedziorski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2309.12250v1-abstract-short" style="display: inline;">
        Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Senten&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.12250v1-abstract-full').style.display = 'inline'; document.getElementById('2309.12250v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2309.12250v1-abstract-full" style="display: none;">
        Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2309.12250v1-abstract-full').style.display = 'none'; document.getElementById('2309.12250v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 September, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to IJCNLP-AACL 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2305.16302">arXiv:2305.16302</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2305.16302">pdf</a>, <a href="https://arxiv.org/format/2305.16302">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.18653/v1/2023.findings-acl.885">10.18653/v1/2023.findings-acl.885 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Lingual Knowledge Distillation for Answer Sentence Selection in Low-Resource Languages
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+S">Shivanshu Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chadha%2C+A">Ankit Chadha</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2305.16302v1-abstract-short" style="display: inline;">
        While impressive performance has been achieved on the task of Answer Sentence Selection (AS2) for English, the same does not hold for languages that lack large labeled datasets. In this work, we propose Cross-Lingual Knowledge Distillation (CLKD) from a strong English AS2 teacher as a method to train AS2 models for low-resource languages in the tasks without the need of labeled data for the target&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.16302v1-abstract-full').style.display = 'inline'; document.getElementById('2305.16302v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2305.16302v1-abstract-full" style="display: none;">
        While impressive performance has been achieved on the task of Answer Sentence Selection (AS2) for English, the same does not hold for languages that lack large labeled datasets. In this work, we propose Cross-Lingual Knowledge Distillation (CLKD) from a strong English AS2 teacher as a method to train AS2 models for low-resource languages in the tasks without the need of labeled data for the target language. To evaluate our method, we introduce 1) Xtr-WikiQA, a translation-based WikiQA dataset for 9 additional languages, and 2) TyDi-AS2, a multilingual AS2 dataset with over 70K questions spanning 8 typologically diverse languages. We conduct extensive experiments on Xtr-WikiQA and TyDi-AS2 with multiple teachers, diverse monolingual and multilingual pretrained language models (PLMs) as students, and both monolingual and multilingual training. The results demonstrate that CLKD either outperforms or rivals even supervised fine-tuning with the same amount of labeled data and a combination of machine translation and the teacher model. Our method can potentially enable stronger AS2 models for low-resource languages, while TyDi-AS2 can serve as the largest multilingual AS2 dataset for further studies in the research community.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.16302v1-abstract-full').style.display = 'none'; document.getElementById('2305.16302v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 25 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ACL 2023 as a long paper (Findings). Datasets are available at https://huggingface.co/datasets/AmazonScience/xtr-wiki_qa and https://huggingface.co/datasets/AmazonScience/tydi-as2</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Findings of the Association for Computational Linguistics: ACL 2023
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2305.15358">arXiv:2305.15358</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2305.15358">pdf</a>, <a href="https://arxiv.org/format/2305.15358">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Context-Aware Transformer Pre-Training for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Liello%2C+L">Luca Di Liello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2305.15358v1-abstract-short" style="display: inline;">
        Answer Sentence Selection (AS2) is a core component for building an accurate Question Answering pipeline. AS2 models rank a set of candidate sentences based on how likely they answer a given question. The state of the art in AS2 exploits pre-trained transformers by transferring them on large annotated datasets, while using local contextual information around the candidate sentence. In this paper,&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.15358v1-abstract-full').style.display = 'inline'; document.getElementById('2305.15358v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2305.15358v1-abstract-full" style="display: none;">
        Answer Sentence Selection (AS2) is a core component for building an accurate Question Answering pipeline. AS2 models rank a set of candidate sentences based on how likely they answer a given question. The state of the art in AS2 exploits pre-trained transformers by transferring them on large annotated datasets, while using local contextual information around the candidate sentence. In this paper, we propose three pre-training objectives designed to mimic the downstream fine-tuning task of contextual AS2. This allows for specializing LMs when fine-tuning for contextual AS2. Our experiments on three public and two large-scale industrial datasets show that our pre-training approaches (applied to RoBERTa and ELECTRA) can improve baseline contextual AS2 accuracy by up to 8% on some datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.15358v1-abstract-full').style.display = 'none'; document.getElementById('2305.15358v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ACL 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2305.15344">arXiv:2305.15344</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2305.15344">pdf</a>, <a href="https://arxiv.org/format/2305.15344">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Answer Generation using Supervision from Automatic Question Answering Evaluators
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2305.15344v1-abstract-short" style="display: inline;">
        Recent studies show that sentence-level extractive QA, i.e., based on Answer Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA) models, which generate answers using the top-k answer sentences ranked by AS2 models (a la retrieval-augmented generation style). In this paper, we propose a novel training paradigm for GenQA using supervision from automatic QA evaluation models (GAV&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.15344v1-abstract-full').style.display = 'inline'; document.getElementById('2305.15344v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2305.15344v1-abstract-full" style="display: none;">
        Recent studies show that sentence-level extractive QA, i.e., based on Answer Sentence Selection (AS2), is outperformed by Generation-based QA (GenQA) models, which generate answers using the top-k answer sentences ranked by AS2 models (a la retrieval-augmented generation style). In this paper, we propose a novel training paradigm for GenQA using supervision from automatic QA evaluation models (GAVA). Specifically, we propose three strategies to transfer knowledge from these QA evaluation models to a GenQA model: (i) augmenting training data with answers generated by the GenQA model and labelled by GAVA (either statically, before training, or (ii) dynamically, at every training epoch); and (iii) using the GAVA score for weighting the generator loss during the learning of the GenQA model. We evaluate our proposed methods on two academic and one industrial dataset, obtaining a significant improvement in answering accuracy over the previous state of the art.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2305.15344v1-abstract-full').style.display = 'none'; document.getElementById('2305.15344v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 May, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ACL 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2304.01003">arXiv:2304.01003</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2304.01003">pdf</a>, <a href="https://arxiv.org/format/2304.01003">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        QUADRo: Dataset and Models for QUestion-Answer Database Retrieval
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Campese%2C+S">Stefano Campese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lauriola%2C+I">Ivano Lauriola</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2304.01003v1-abstract-short" style="display: inline;">
        An effective paradigm for building Automated Question Answering systems is the re-use of previously answered questions, e.g., for FAQs or forum applications. Given a database (DB) of question/answer (q/a) pairs, it is possible to answer a target question by scanning the DB for similar questions. In this paper, we scale this approach to open domain, making it competitive with other standard methods&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.01003v1-abstract-full').style.display = 'inline'; document.getElementById('2304.01003v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2304.01003v1-abstract-full" style="display: none;">
        An effective paradigm for building Automated Question Answering systems is the re-use of previously answered questions, e.g., for FAQs or forum applications. Given a database (DB) of question/answer (q/a) pairs, it is possible to answer a target question by scanning the DB for similar questions. In this paper, we scale this approach to open domain, making it competitive with other standard methods, e.g., unstructured document or graph based. For this purpose, we (i) build a large scale DB of 6.3M q/a pairs, using public questions, (ii) design a new system based on neural IR and a q/a pair reranker, and (iii) construct training and test data to perform comparative experiments with our models. We demonstrate that Transformer-based models using (q,a) pairs outperform models only based on question representation, for both neural search and reranking. Additionally, we show that our DB-based approach is competitive with Web-based methods, i.e., a QA system built on top the BING search engine, demonstrating the challenge of finding relevant information. Finally, we make our data and models available for future research.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2304.01003v1-abstract-full').style.display = 'none'; document.getElementById('2304.01003v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2210.13536">arXiv:2210.13536</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2210.13536">pdf</a>, <a href="https://arxiv.org/format/2210.13536">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Effective Pre-Training Objectives for Transformer-based Autoencoders
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Liello%2C+L">Luca Di Liello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2210.13536v1-abstract-short" style="display: inline;">
        In this paper, we study trade-offs between efficiency, cost and accuracy when pre-training Transformer encoders with different pre-training objectives. For this purpose, we analyze features of common objectives and combine them to create new effective pre-training approaches. Specifically, we designed light token generators based on a straightforward statistical approach, which can replace ELECTRA&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.13536v1-abstract-full').style.display = 'inline'; document.getElementById('2210.13536v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2210.13536v1-abstract-full" style="display: none;">
        In this paper, we study trade-offs between efficiency, cost and accuracy when pre-training Transformer encoders with different pre-training objectives. For this purpose, we analyze features of common objectives and combine them to create new effective pre-training approaches. Specifically, we designed light token generators based on a straightforward statistical approach, which can replace ELECTRA computationally heavy generators, thus highly reducing cost. Our experiments also show that (i) there are more efficient alternatives to BERT&#39;s MLM, and (ii) it is possible to efficiently pre-train Transformer-based models using lighter generators without a significant drop in performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.13536v1-abstract-full').style.display = 'none'; document.getElementById('2210.13536v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 October, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at EMNLP 2022 Findings</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2210.12865">arXiv:2210.12865</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2210.12865">pdf</a>, <a href="https://arxiv.org/format/2210.12865">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Knowledge Transfer from Answer Ranking to Answer Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2210.12865v1-abstract-short" style="display: inline;">
        Recent studies show that Question Answering (QA) based on Answer Sentence Selection (AS2) can be improved by generating an improved answer from the top-k ranked answer sentences (termed GenQA). This allows for synthesizing the information from multiple candidates into a concise, natural-sounding answer. However, creating large-scale supervised training data for GenQA models is very challenging. In&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.12865v1-abstract-full').style.display = 'inline'; document.getElementById('2210.12865v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2210.12865v1-abstract-full" style="display: none;">
        Recent studies show that Question Answering (QA) based on Answer Sentence Selection (AS2) can be improved by generating an improved answer from the top-k ranked answer sentences (termed GenQA). This allows for synthesizing the information from multiple candidates into a concise, natural-sounding answer. However, creating large-scale supervised training data for GenQA models is very challenging. In this paper, we propose to train a GenQA model by transferring knowledge from a trained AS2 model, to overcome the aforementioned issue. First, we use an AS2 model to produce a ranking over answer candidates for a set of questions. Then, we use the top ranked candidate as the generation target, and the next k top ranked candidates as context for training a GenQA model. We also propose to use the AS2 model prediction scores for loss weighting and score-conditioned input/output shaping, to aid the knowledge transfer. Our evaluation on three public and one large industrial datasets demonstrates the superiority of our approach over the AS2 baseline, and GenQA trained using supervised data.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2210.12865v1-abstract-full').style.display = 'none'; document.getElementById('2210.12865v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 October, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at EMNLP 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.10455">arXiv:2205.10455</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.10455">pdf</a>, <a href="https://arxiv.org/format/2205.10455">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Pre-training Transformer Models with Sentence-Level Objectives for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Liello%2C+L">Luca Di Liello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.10455v2-abstract-short" style="display: inline;">
        An important task for designing QA systems is answer sentence selection (AS2): selecting the sentence containing (or constituting) the answer to a question from a set of retrieved relevant documents. In this paper, we propose three novel sentence-level transformer pre-training objectives that incorporate paragraph-level semantics within and across documents, to improve the performance of transform&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.10455v2-abstract-full').style.display = 'inline'; document.getElementById('2205.10455v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.10455v2-abstract-full" style="display: none;">
        An important task for designing QA systems is answer sentence selection (AS2): selecting the sentence containing (or constituting) the answer to a question from a set of retrieved relevant documents. In this paper, we propose three novel sentence-level transformer pre-training objectives that incorporate paragraph-level semantics within and across documents, to improve the performance of transformers for AS2, and mitigate the requirement of large labeled datasets. Specifically, the model is tasked to predict whether: (i) two sentences are extracted from the same paragraph, (ii) a given sentence is extracted from a given paragraph, and (iii) two paragraphs are extracted from the same document. Our experiments on three public and one industrial AS2 datasets demonstrate the empirical superiority of our pre-trained transformers over baseline models such as RoBERTa and ELECTRA for AS2.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.10455v2-abstract-full').style.display = 'none'; document.getElementById('2205.10455v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 October, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 20 May, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at EMNLP 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.01228">arXiv:2205.01228</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.01228">pdf</a>, <a href="https://arxiv.org/format/2205.01228">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Paragraph-based Transformer Pre-training for Multi-Sentence Inference
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Liello%2C+L">Luca Di Liello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.01228v2-abstract-short" style="display: inline;">
        Inference tasks such as answer sentence selection (AS2) or fact verification are typically solved by fine-tuning transformer-based models as individual sentence-pair classifiers. Recent studies show that these tasks benefit from modeling dependencies across multiple candidate sentences jointly. In this paper, we first show that popular pre-trained transformers perform poorly when used for fine-tun&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.01228v2-abstract-full').style.display = 'inline'; document.getElementById('2205.01228v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.01228v2-abstract-full" style="display: none;">
        Inference tasks such as answer sentence selection (AS2) or fact verification are typically solved by fine-tuning transformer-based models as individual sentence-pair classifiers. Recent studies show that these tasks benefit from modeling dependencies across multiple candidate sentences jointly. In this paper, we first show that popular pre-trained transformers perform poorly when used for fine-tuning on multi-candidate inference tasks. We then propose a new pre-training objective that models the paragraph-level semantics across multiple input sentences. Our evaluation on three AS2 and one fact verification datasets demonstrates the superiority of our pre-training technique over the traditional ones for transformers used as joint models for multi-candidate inference tasks, as well as when used as cross-encoders for sentence-pair formulations of these tasks. Our code and pre-trained models are released at https://github.com/amazon-research/wqa-multi-sentence-inference .
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.01228v2-abstract-full').style.display = 'none'; document.getElementById('2205.01228v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 July, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 May, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at NAACL 2022</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.09598">arXiv:2203.09598</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.09598">pdf</a>, <a href="https://arxiv.org/format/2203.09598">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        DP-KB: Data Programming with Knowledge Bases Improves Transformer Fine Tuning for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Jedema%2C+N">Nic Jedema</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gupta%2C+M">Manish Gupta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.09598v1-abstract-short" style="display: inline;">
        While transformers demonstrate impressive performance on many knowledge intensive (KI) tasks, their ability to serve as implicit knowledge bases (KBs) remains limited, as shown on several slot-filling, question-answering (QA), fact verification, and entity-linking tasks. In this paper, we implement an efficient, data-programming technique that enriches training data with KB-derived context and imp&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.09598v1-abstract-full').style.display = 'inline'; document.getElementById('2203.09598v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.09598v1-abstract-full" style="display: none;">
        While transformers demonstrate impressive performance on many knowledge intensive (KI) tasks, their ability to serve as implicit knowledge bases (KBs) remains limited, as shown on several slot-filling, question-answering (QA), fact verification, and entity-linking tasks. In this paper, we implement an efficient, data-programming technique that enriches training data with KB-derived context and improves transformer utilization of encoded knowledge when fine-tuning for a particular QA task, namely answer sentence selection (AS2). Our method outperforms state of the art transformer approach on WikiQA and TrecQA, two widely studied AS2 benchmarks, increasing by 2.0% p@1, 1.3% MAP, 1.1% MRR, and 4.4% p@1, 0.9% MAP, 2.4% MRR, respectively. To demonstrate our improvements in an industry setting, we additionally evaluate our approach on a proprietary dataset of Alexa QA pairs, and show increase of 2.3% F1 and 2.0% MAP. We additionally find that these improvements remain even when KB context is omitted at inference time, allowing for the use of our models within existing transformer workflows without additional latency or deployment costs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.09598v1-abstract-full').style.display = 'none'; document.getElementById('2203.09598v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 March, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Workshop on Databases and AI @NeurIPS 2021, Oral Presentation</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2203.03549">arXiv:2203.03549</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2203.03549">pdf</a>, <a href="https://arxiv.org/format/2203.03549">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.48550/arXiv.2203.03549">10.48550/arXiv.2203.03549 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Question-Answer Sentence Graph for Joint Modeling Answer Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Iyer%2C+R+G">Roshni G. Iyer</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sun%2C+Y">Yizhou Sun</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2203.03549v2-abstract-short" style="display: inline;">
        This research studies graph-based approaches for Answer Sentence Selection (AS2), an essential component for retrieval-based Question Answering (QA) systems. During offline learning, our model constructs a small-scale relevant training graph per question in an unsupervised manner, and integrates with Graph Neural Networks. Graph nodes are question sentence to answer sentence pairs. We train and in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.03549v2-abstract-full').style.display = 'inline'; document.getElementById('2203.03549v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2203.03549v2-abstract-full" style="display: none;">
        This research studies graph-based approaches for Answer Sentence Selection (AS2), an essential component for retrieval-based Question Answering (QA) systems. During offline learning, our model constructs a small-scale relevant training graph per question in an unsupervised manner, and integrates with Graph Neural Networks. Graph nodes are question sentence to answer sentence pairs. We train and integrate state-of-the-art (SOTA) models for computing scores between question-question, question-answer, and answer-answer pairs, and use thresholding on relevance scores for creating graph edges. Online inference is then performed to solve the AS2 task on unseen queries. Experiments on two well-known academic benchmarks and a real-world dataset show that our approach consistently outperforms SOTA QA baseline models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2203.03549v2-abstract-full').style.display = 'none'; document.getElementById('2203.03549v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 April, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 16 February, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.05984">arXiv:2201.05984</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.05984">pdf</a>, <a href="https://arxiv.org/format/2201.05984">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        In Situ Answer Sentence Selection at Web-scale
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zeyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.05984v1-abstract-short" style="display: inline;">
        Current answer sentence selection (AS2) applied in open-domain question answering (ODQA) selects answers by ranking a large set of possible candidates, i.e., sentences, extracted from the retrieved text. In this paper, we present Passage-based Extracting Answer Sentence In-place (PEASI), a novel design for AS2 optimized for Web-scale setting, that, instead, computes such answer without processing&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05984v1-abstract-full').style.display = 'inline'; document.getElementById('2201.05984v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.05984v1-abstract-full" style="display: none;">
        Current answer sentence selection (AS2) applied in open-domain question answering (ODQA) selects answers by ranking a large set of possible candidates, i.e., sentences, extracted from the retrieved text. In this paper, we present Passage-based Extracting Answer Sentence In-place (PEASI), a novel design for AS2 optimized for Web-scale setting, that, instead, computes such answer without processing each candidate individually. Specifically, we design a Transformer-based framework that jointly (i) reranks passages retrieved for a question and (ii) identifies a probable answer from the top passages in place. We train PEASI in a multi-task learning framework that encourages feature sharing between the components: passage reranker and passage-based answer sentence extractor. To facilitate our development, we construct a new Web-sourced large-scale QA dataset consisting of 800,000+ labeled passages/sentences for 60,000+ questions. The experiments show that our proposed design effectively outperforms the current state-of-the-art setting for AS2, i.e., a point-wise model for ranking sentences independently, by 6.51% in accuracy, from 48.86% to 55.37%. In addition, PEASI is exceptionally efficient in computing answer sentences, requiring only ~20% inferences compared to the standard setting, i.e., reranking all possible candidates. We believe the release of PEASI, both the dataset and our proposed design, can contribute to advancing the research and development in deploying question answering services at Web scale.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05984v1-abstract-full').style.display = 'none'; document.getElementById('2201.05984v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.05981">arXiv:2201.05981</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.05981">pdf</a>, <a href="https://arxiv.org/format/2201.05981">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Double Retrieval and Ranking for Accurate Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zeyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.05981v1-abstract-short" style="display: inline;">
        Recent work has shown that an answer verification step introduced in Transformer-based answer selection models can significantly improve the state of the art in Question Answering. This step is performed by aggregating the embeddings of top $k$ answer candidates to support the verification of a target answer. Although the approach is intuitive and sound still shows two limitations: (i) the support&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05981v1-abstract-full').style.display = 'inline'; document.getElementById('2201.05981v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.05981v1-abstract-full" style="display: none;">
        Recent work has shown that an answer verification step introduced in Transformer-based answer selection models can significantly improve the state of the art in Question Answering. This step is performed by aggregating the embeddings of top $k$ answer candidates to support the verification of a target answer. Although the approach is intuitive and sound still shows two limitations: (i) the supporting candidates are ranked only according to the relevancy with the question and not with the answer, and (ii) the support provided by the other answer candidates is suboptimal as these are retrieved independently of the target answer. In this paper, we address both drawbacks by proposing (i) a double reranking model, which, for each target answer, selects the best support; and (ii) a second neural retrieval stage designed to encode question and answer pair as the query, which finds more specific verification information. The results on three well-known datasets for AS2 show consistent and significant improvement of the state of the art.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05981v1-abstract-full').style.display = 'none'; document.getElementById('2201.05981v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2201.05767">arXiv:2201.05767</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2201.05767">pdf</a>, <a href="https://arxiv.org/format/2201.05767">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.18653/v1/2022.findings-emnlp.537">10.18653/v1/2022.findings-emnlp.537 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Ensemble Transformer for Efficient and Accurate Ranking Tasks: an Application to Question Answering Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Matsubara%2C+Y">Yoshitomo Matsubara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lind%2C+E">Eric Lind</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2201.05767v2-abstract-short" style="display: inline;">
        Large transformer models can highly improve Answer Sentence Selection (AS2) tasks, but their high computational costs prevent their use in many real-world applications. In this paper, we explore the following research question: How can we make the AS2 models more accurate without significantly increasing their model complexity? To address the question, we propose a Multiple Heads Student architect&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05767v2-abstract-full').style.display = 'inline'; document.getElementById('2201.05767v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2201.05767v2-abstract-full" style="display: none;">
        Large transformer models can highly improve Answer Sentence Selection (AS2) tasks, but their high computational costs prevent their use in many real-world applications. In this paper, we explore the following research question: How can we make the AS2 models more accurate without significantly increasing their model complexity? To address the question, we propose a Multiple Heads Student architecture (named CERBERUS), an efficient neural network designed to distill an ensemble of large transformers into a single smaller model. CERBERUS consists of two components: a stack of transformer layers that is used to encode inputs, and a set of ranking heads; unlike traditional distillation technique, each of them is trained by distilling a different large transformer architecture in a way that preserves the diversity of the ensemble members. The resulting model captures the knowledge of heterogeneous transformer models by using just a few extra parameters. We show the effectiveness of CERBERUS on three English datasets for AS2; our proposed approach outperforms all single-model distillations we consider, rivaling the state-of-the-art large AS2 models that have 2.7x more parameters and run 2.5x slower. Code for our model is available at https://github.com/amazon-research/wqa-cerberus
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2201.05767v2-abstract-full').style.display = 'none'; document.getElementById('2201.05767v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 December, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 January, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to EMNLP 2022 as a long paper (Findings). Model code is available at https://github.com/amazon-research/wqa-cerberus</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Findings of the Association for Computational Linguistics: EMNLP 2022
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.07150">arXiv:2110.07150</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.07150">pdf</a>, <a href="https://arxiv.org/format/2110.07150">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Lingual Open-Domain Question Answering with Answer Sentence Generation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Muller%2C+B">Benjamin Muller</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koncel-Kedziorski%2C+R">Rik Koncel-Kedziorski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lind%2C+E">Eric Lind</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.07150v3-abstract-short" style="display: inline;">
        Open-Domain Generative Question Answering has achieved impressive performance in English by combining document-level retrieval with answer generation. These approaches, which we refer to as GenQA, can generate complete sentences, effectively answering both factoid and non-factoid questions. In this paper, we extend GenQA to the multilingual and cross-lingual settings. For this purpose, we first in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.07150v3-abstract-full').style.display = 'inline'; document.getElementById('2110.07150v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.07150v3-abstract-full" style="display: none;">
        Open-Domain Generative Question Answering has achieved impressive performance in English by combining document-level retrieval with answer generation. These approaches, which we refer to as GenQA, can generate complete sentences, effectively answering both factoid and non-factoid questions. In this paper, we extend GenQA to the multilingual and cross-lingual settings. For this purpose, we first introduce GenTyDiQA, an extension of the TyDiQA dataset with well-formed and complete answers for Arabic, Bengali, English, Japanese, and Russian. Based on GenTyDiQA, we design a cross-lingual generative model that produces full-sentence answers by exploiting passages written in multiple languages, including languages different from the question. Our cross-lingual generative system outperforms answer sentence selection baselines for all 5 languages and monolingual generative pipelines for three out of five languages studied.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.07150v3-abstract-full').style.display = 'none'; document.getElementById('2110.07150v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 December, 2022; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 October, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">AACL 2022 Long Paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.07009">arXiv:2109.07009</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.07009">pdf</a>, <a href="https://arxiv.org/format/2109.07009">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Will this Question be Answered? Question Filtering via Answer Model Distillation for Efficient Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.07009v1-abstract-short" style="display: inline;">
        In this paper we propose a novel approach towards improving the efficiency of Question Answering (QA) systems by filtering out questions that will not be answered by them. This is based on an interesting new finding: the answer confidence scores of state-of-the-art QA systems can be approximated well by models solely using the input question text. This enables preemptive filtering of questions tha&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.07009v1-abstract-full').style.display = 'inline'; document.getElementById('2109.07009v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.07009v1-abstract-full" style="display: none;">
        In this paper we propose a novel approach towards improving the efficiency of Question Answering (QA) systems by filtering out questions that will not be answered by them. This is based on an interesting new finding: the answer confidence scores of state-of-the-art QA systems can be approximated well by models solely using the input question text. This enables preemptive filtering of questions that are not answered by the system due to their answer confidence scores being lower than the system threshold. Specifically, we learn Transformer-based question models by distilling Transformer-based answering models. Our experiments on three popular QA datasets and one industrial QA benchmark demonstrate the ability of our question models to approximate the Precision/Recall curves of the target QA system well. These question models, when used as filters, can effectively trade off lower computation cost of QA systems for lower Recall, e.g., reducing computation by ~60%, while only losing ~3-4% of Recall.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.07009v1-abstract-full').style.display = 'none'; document.getElementById('2109.07009v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at EMNLP 2021 Main Conference (Long)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.04217">arXiv:2107.04217</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.04217">pdf</a>, <a href="https://arxiv.org/format/2107.04217">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Joint Models for Answer Verification in Question Answering Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+Z">Zeyu Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.04217v1-abstract-short" style="display: inline;">
        This paper studies joint models for selecting correct answer sentences among the top $k$ provided by answer sentence selection (AS2) modules, which are core components of retrieval-based Question Answering (QA) systems. Our work shows that a critical step to effectively exploit an answer set regards modeling the interrelated information between pair of answers. For this purpose, we build a three-w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.04217v1-abstract-full').style.display = 'inline'; document.getElementById('2107.04217v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.04217v1-abstract-full" style="display: none;">
        This paper studies joint models for selecting correct answer sentences among the top $k$ provided by answer sentence selection (AS2) modules, which are core components of retrieval-based Question Answering (QA) systems. Our work shows that a critical step to effectively exploit an answer set regards modeling the interrelated information between pair of answers. For this purpose, we build a three-way multi-classifier, which decides if an answer supports, refutes, or is neutral with respect to another one. More specifically, our neural architecture integrates a state-of-the-art AS2 model with the multi-classifier, and a joint layer connecting all components. We tested our models on WikiQA, TREC-QA, and a real-world dataset. The results show that our models obtain the new state of the art in AS2.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.04217v1-abstract-full').style.display = 'none'; document.getElementById('2107.04217v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 July, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ACL 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2106.00955">arXiv:2106.00955</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2106.00955">pdf</a>, <a href="https://arxiv.org/ps/2106.00955">ps</a>, <a href="https://arxiv.org/format/2106.00955">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Answer Generation for Retrieval-based Question Answering Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Hsu%2C+C">Chao-Chun Hsu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lind%2C+E">Eric Lind</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2106.00955v1-abstract-short" style="display: inline;">
        Recent advancements in transformer-based models have greatly improved the ability of Question Answering (QA) systems to provide correct answers; in particular, answer sentence selection (AS2) models, core components of retrieval-based systems, have achieved impressive results. While generally effective, these models fail to provide a satisfying answer when all retrieved candidates are of poor qual&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00955v1-abstract-full').style.display = 'inline'; document.getElementById('2106.00955v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2106.00955v1-abstract-full" style="display: none;">
        Recent advancements in transformer-based models have greatly improved the ability of Question Answering (QA) systems to provide correct answers; in particular, answer sentence selection (AS2) models, core components of retrieval-based systems, have achieved impressive results. While generally effective, these models fail to provide a satisfying answer when all retrieved candidates are of poor quality, even if they contain correct information. In AS2, models are trained to select the best answer sentence among a set of candidates retrieved for a given question. In this work, we propose to generate answers from a set of AS2 top candidates. Rather than selecting the best candidate, we train a sequence to sequence transformer model to generate an answer from a candidate set. Our tests on three English AS2 datasets show improvement up to 32 absolute points in accuracy over the state of the art.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2106.00955v1-abstract-full').style.display = 'none'; document.getElementById('2106.00955v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 June, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Short paper, Accepted at Findings of ACL 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.09694">arXiv:2104.09694</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.09694">pdf</a>, <a href="https://arxiv.org/ps/2104.09694">ps</a>, <a href="https://arxiv.org/format/2104.09694">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Efficient pre-training objectives for Transformers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Liello%2C+L">Luca Di Liello</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gabburo%2C+M">Matteo Gabburo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.09694v1-abstract-short" style="display: inline;">
        The Transformer architecture deeply changed the natural language processing, outperforming all previous state-of-the-art models. However, well-known Transformer models like BERT, RoBERTa, and GPT-2 require a huge compute budget to create a high quality contextualised representation. In this paper, we study several efficient pre-training objectives for Transformers-based models. By testing these ob&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09694v1-abstract-full').style.display = 'inline'; document.getElementById('2104.09694v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.09694v1-abstract-full" style="display: none;">
        The Transformer architecture deeply changed the natural language processing, outperforming all previous state-of-the-art models. However, well-known Transformer models like BERT, RoBERTa, and GPT-2 require a huge compute budget to create a high quality contextualised representation. In this paper, we study several efficient pre-training objectives for Transformers-based models. By testing these objectives on different tasks, we determine which of the ELECTRA model&#39;s new features is the most relevant. We confirm that Transformers pre-training is improved when the input does not contain masked tokens and that the usage of the whole output to compute the loss reduces training time. Moreover, inspired by ELECTRA, we study a model composed of two blocks; a discriminator and a simple generator based on a statistical model with no impact on the computational performances. Besides, we prove that eliminating the MASK token and considering the whole output during the loss computation are essential choices to improve performance. Furthermore, we show that it is possible to efficiently train BERT-like models using a discriminative approach as in ELECTRA but without a complex generator, which is expensive. Finally, we show that ELECTRA benefits heavily from a state-of-the-art hyper-parameters search.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.09694v1-abstract-full').style.display = 'none'; document.getElementById('2104.09694v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.08943">arXiv:2104.08943</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.08943">pdf</a>, <a href="https://arxiv.org/format/2104.08943">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Reference-based Weak Supervision for Answer Sentence Selection using Web Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Krishnamurthy%2C+V">Vivek Krishnamurthy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.08943v1-abstract-short" style="display: inline;">
        Answer sentence selection (AS2) modeling requires annotated data, i.e., hand-labeled question-answer pairs. We present a strategy to collect weakly supervised answers for a question based on its reference to improve AS2 modeling. Specifically, we introduce Reference-based Weak Supervision (RWS), a fully automatic large-scale data pipeline that harvests high-quality weakly-supervised answers from a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.08943v1-abstract-full').style.display = 'inline'; document.getElementById('2104.08943v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.08943v1-abstract-full" style="display: none;">
        Answer sentence selection (AS2) modeling requires annotated data, i.e., hand-labeled question-answer pairs. We present a strategy to collect weakly supervised answers for a question based on its reference to improve AS2 modeling. Specifically, we introduce Reference-based Weak Supervision (RWS), a fully automatic large-scale data pipeline that harvests high-quality weakly-supervised answers from abundant Web data requiring only a question-reference pair as input. We study the efficacy and robustness of RWS in the setting of TANDA, a recent state-of-the-art fine-tuning approach specialized for AS2. Our experiments indicate that the produced data consistently bolsters TANDA. We achieve the state of the art in terms of P@1, 90.1%, and MAP, 92.9%, on WikiQA.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.08943v1-abstract-full').style.display = 'none'; document.getElementById('2104.08943v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10250">arXiv:2102.10250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10250">pdf</a>, <a href="https://arxiv.org/ps/2102.10250">ps</a>, <a href="https://arxiv.org/format/2102.10250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multilingual Answer Sentence Reranking via Automatically Translated Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10250v1-abstract-short" style="display: inline;">
        We present a study on the design of multilingual Answer Sentence Selection (AS2) models, which are a core component of modern Question Answering (QA) systems. The main idea is to transfer data, created from one resource rich language, e.g., English, to other languages, less rich in terms of resources. The main findings of this paper are: (i) the training data for AS2 translated into a target langu&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10250v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10250v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10250v1-abstract-full" style="display: none;">
        We present a study on the design of multilingual Answer Sentence Selection (AS2) models, which are a core component of modern Question Answering (QA) systems. The main idea is to transfer data, created from one resource rich language, e.g., English, to other languages, less rich in terms of resources. The main findings of this paper are: (i) the training data for AS2 translated into a target language can be used to effectively fine-tune a Transformer-based model for that language; (ii) one multilingual Transformer model it is enough to rank answers in multiple languages; and (iii) mixed-language question/answer pairs can be used to fine-tune models to select answers from any language, where the input question is just in one language. This highly reduces the complexity and technical requirement of a multilingual QA system. Our experiments validate the findings above, showing a modest drop, at most 3%, with respect to the state-of-the-art English model.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10250v1-abstract-full').style.display = 'none'; document.getElementById('2102.10250v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10246">arXiv:2102.10246</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10246">pdf</a>, <a href="https://arxiv.org/format/2102.10246">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        CDA: a Cost Efficient Content-based Multilingual Web Document Aligner
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10246v1-abstract-short" style="display: inline;">
        We introduce a Content-based Document Alignment approach (CDA), an efficient method to align multilingual web documents based on content in creating parallel training data for machine translation (MT) systems operating at the industrial level. CDA works in two steps: (i) projecting documents of a web domain to a shared multilingual space; then (ii) aligning them based on the similarity of their re&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10246v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10246v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10246v1-abstract-full" style="display: none;">
        We introduce a Content-based Document Alignment approach (CDA), an efficient method to align multilingual web documents based on content in creating parallel training data for machine translation (MT) systems operating at the industrial level. CDA works in two steps: (i) projecting documents of a web domain to a shared multilingual space; then (ii) aligning them based on the similarity of their representations in such space. We leverage lexical translation models to build vector representations using TF-IDF. CDA achieves performance comparable with state-of-the-art systems in the WMT-16 Bilingual Document Alignment Shared Task benchmark while operating in multilingual space. Besides, we created two web-scale datasets to examine the robustness of CDA in an industrial setting involving up to 28 languages and millions of documents. The experiments show that CDA is robust, cost-effective, and is significantly superior in (i) processing large and noisy web data and (ii) scaling to new and low-resourced languages.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10246v1-abstract-full').style.display = 'none'; document.getElementById('2102.10246v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EACL 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.10243">arXiv:2102.10243</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.10243">pdf</a>, <a href="https://arxiv.org/format/2102.10243">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Machine Translation Customization via Automatic Training Data Selection from the Web
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.10243v1-abstract-short" style="display: inline;">
        Machine translation (MT) systems, especially when designed for an industrial setting, are trained with general parallel data derived from the Web. Thus, their style is typically driven by word/structure distribution coming from the average of many domains. In contrast, MT customers want translations to be specialized to their domain, for which they are typically able to provide text samples. We de&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10243v1-abstract-full').style.display = 'inline'; document.getElementById('2102.10243v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.10243v1-abstract-full" style="display: none;">
        Machine translation (MT) systems, especially when designed for an industrial setting, are trained with general parallel data derived from the Web. Thus, their style is typically driven by word/structure distribution coming from the average of many domains. In contrast, MT customers want translations to be specialized to their domain, for which they are typically able to provide text samples. We describe an approach for customizing MT systems on specific domains by selecting data similar to the target customer data to train neural translation models. We build document classifiers using monolingual target data, e.g., provided by the customers to select parallel training data from Web crawled data. Finally, we train MT models on our automatically selected data, obtaining a system specialized to the target domain. We tested our approach on the benchmark from WMT-18 Translation Task for News domains enabling comparisons with state-of-the-art MT systems. The results show that our models outperform the top systems while using less data and smaller models.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.10243v1-abstract-full').style.display = 'none'; document.getElementById('2102.10243v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 February, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ECIR 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2101.12093">arXiv:2101.12093</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2101.12093">pdf</a>, <a href="https://arxiv.org/format/2101.12093">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Modeling Context in Answer Sentence Selection Systems on a Latency Budget
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Han%2C+R">Rujun Han</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2101.12093v2-abstract-short" style="display: inline;">
        Answer Sentence Selection (AS2) is an efficient approach for the design of open-domain Question Answering (QA) systems. In order to achieve low latency, traditional AS2 models score question-answer pairs individually, ignoring any information from the document each potential answer was extracted from. In contrast, more computationally expensive models designed for machine reading comprehension tas&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.12093v2-abstract-full').style.display = 'inline'; document.getElementById('2101.12093v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2101.12093v2-abstract-full" style="display: none;">
        Answer Sentence Selection (AS2) is an efficient approach for the design of open-domain Question Answering (QA) systems. In order to achieve low latency, traditional AS2 models score question-answer pairs individually, ignoring any information from the document each potential answer was extracted from. In contrast, more computationally expensive models designed for machine reading comprehension tasks typically receive one or more passages as input, which often results in better accuracy. In this work, we present an approach to efficiently incorporate contextual information in AS2 models. For each answer candidate, we first use unsupervised similarity techniques to extract relevant sentences from its source document, which we then feed into an efficient transformer architecture fine-tuned for AS2. Our best approach, which leverages a multi-way attention architecture to efficiently encode context, improves 6% to 11% over noncontextual state of the art in AS2 with minimal impact on system latency. All experiments in this work were conducted in English.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2101.12093v2-abstract-full').style.display = 'none'; document.getElementById('2101.12093v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 February, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 28 January, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted as a short paper at EACL 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2006.01285">arXiv:2006.01285</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2006.01285">pdf</a>, <a href="https://arxiv.org/format/2006.01285">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Context-based Transformer Models for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lauriola%2C+I">Ivano Lauriola</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2006.01285v1-abstract-short" style="display: inline;">
        An important task for the design of Question Answering systems is the selection of the sentence containing (or constituting) the answer from documents relevant to the asked question. Most previous work has only used the target sentence to compute its score with the question as the models were not powerful enough to also effectively encode additional contextual information. In this paper, we analyz&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.01285v1-abstract-full').style.display = 'inline'; document.getElementById('2006.01285v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2006.01285v1-abstract-full" style="display: none;">
        An important task for the design of Question Answering systems is the selection of the sentence containing (or constituting) the answer from documents relevant to the asked question. Most previous work has only used the target sentence to compute its score with the question as the models were not powerful enough to also effectively encode additional contextual information. In this paper, we analyze the role of the contextual information in the sentence selection task, proposing a Transformer based architecture that leverages two types of contexts, local and global. The former describes the paragraph containing the sentence, aiming at solving implicit references, whereas the latter describes the entire document containing the candidate sentence, providing content-based information. The results on three different benchmarks show that the combination of local and global contexts in a Transformer model significantly improves the accuracy in Answer Sentence Selection.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2006.01285v1-abstract-full').style.display = 'none'; document.getElementById('2006.01285v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 1 June, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.02534">arXiv:2005.02534</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2005.02534">pdf</a>, <a href="https://arxiv.org/format/2005.02534">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Cascade Transformer: an Application for Efficient Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Soldaini%2C+L">Luca Soldaini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.02534v2-abstract-short" style="display: inline;">
        Large transformer-based language models have been shown to be very effective in many classification tasks. However, their computational complexity prevents their use in applications requiring the classification of a large set of candidates. While previous works have investigated approaches to reduce model size, relatively little attention has been paid to techniques to improve batch throughput dur&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.02534v2-abstract-full').style.display = 'inline'; document.getElementById('2005.02534v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.02534v2-abstract-full" style="display: none;">
        Large transformer-based language models have been shown to be very effective in many classification tasks. However, their computational complexity prevents their use in applications requiring the classification of a large set of candidates. While previous works have investigated approaches to reduce model size, relatively little attention has been paid to techniques to improve batch throughput during inference. In this paper, we introduce the Cascade Transformer, a simple yet effective technique to adapt transformer-based models into a cascade of rankers. Each ranker is used to prune a subset of candidates in a batch, thus dramatically increasing throughput at inference time. Partial encodings from the transformer model are shared among rerankers, providing further speed-up. When compared to a state-of-the-art transformer model, our approach reduces computation by 37% with almost no impact on accuracy, as measured on two English Question Answering datasets.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.02534v2-abstract-full').style.display = 'none'; document.getElementById('2005.02534v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 May, 2020; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 May, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to ACL 2020 (long)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.00705">arXiv:2005.00705</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2005.00705">pdf</a>, <a href="https://arxiv.org/format/2005.00705">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        AVA: an Automatic eValuation Approach to Question Answering Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.00705v1-abstract-short" style="display: inline;">
        We introduce AVA, an automatic evaluation approach for Question Answering, which given a set of questions associated with Gold Standard answers, can estimate system Accuracy. AVA uses Transformer-based language models to encode question, answer, and reference text. This allows for effectively measuring the similarity between the reference and an automatic answer, biased towards the question semant&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.00705v1-abstract-full').style.display = 'inline'; document.getElementById('2005.00705v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.00705v1-abstract-full" style="display: none;">
        We introduce AVA, an automatic evaluation approach for Question Answering, which given a set of questions associated with Gold Standard answers, can estimate system Accuracy. AVA uses Transformer-based language models to encode question, answer, and reference text. This allows for effectively measuring the similarity between the reference and an automatic answer, biased towards the question semantics. To design, train and test AVA, we built multiple large training, development, and test sets on both public and industrial benchmarks. Our innovative solutions achieve up to 74.7% in F1 score in predicting human judgement for single answers. Additionally, AVA can be used to evaluate the overall system Accuracy with an RMSE, ranging from 0.02 to 0.09, depending on the availability of multiple references.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.00705v1-abstract-full').style.display = 'none'; document.getElementById('2005.00705v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 May, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        NAACL 2021
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2003.02349">arXiv:2003.02349</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2003.02349">pdf</a>, <a href="https://arxiv.org/ps/2003.02349">ps</a>, <a href="https://arxiv.org/format/2003.02349">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Study on Efficiency, Accuracy and Document Structure for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bonadiman%2C+D">Daniele Bonadiman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2003.02349v1-abstract-short" style="display: inline;">
        An essential task of most Question Answering (QA) systems is to re-rank the set of answer candidates, i.e., Answer Sentence Selection (A2S). These candidates are typically sentences either extracted from one or more documents preserving their natural order or retrieved by a search engine. Most state-of-the-art approaches to the task use huge neural models, such as BERT, or complex attentive archit&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.02349v1-abstract-full').style.display = 'inline'; document.getElementById('2003.02349v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2003.02349v1-abstract-full" style="display: none;">
        An essential task of most Question Answering (QA) systems is to re-rank the set of answer candidates, i.e., Answer Sentence Selection (A2S). These candidates are typically sentences either extracted from one or more documents preserving their natural order or retrieved by a search engine. Most state-of-the-art approaches to the task use huge neural models, such as BERT, or complex attentive architectures. In this paper, we argue that by exploiting the intrinsic structure of the original rank together with an effective word-relatedness encoder, we can achieve competitive results with respect to the state of the art while retaining high efficiency. Our model takes 9.5 seconds to train on the WikiQA dataset, i.e., very fast in comparison with the $\sim 18$ minutes required by a standard BERT-base fine-tuning.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2003.02349v1-abstract-full').style.display = 'none'; document.getElementById('2003.02349v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 March, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1912.01972">arXiv:1912.01972</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1912.01972">pdf</a>, <a href="https://arxiv.org/format/1912.01972">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SemEval-2016 Task 3: Community Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%C3%A0rquez%2C+L">Lluís Màrquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Magdy%2C+W">Walid Magdy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mubarak%2C+H">Hamdy Mubarak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Freihat%2C+A+A">Abed Alhakim Freihat</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glass%2C+J">James Glass</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Randeree%2C+B">Bilal Randeree</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1912.01972v1-abstract-short" style="display: inline;">
        This paper describes the SemEval--2016 Task 3 on Community Question Answering, which we offered in English and Arabic. For English, we had three subtasks: Question--Comment Similarity (subtask A), Question--Question Similarity (B), and Question--External Comment Similarity (C). For Arabic, we had another subtask: Rerank the correct answers for a new question (D). Eighteen teams participated in the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.01972v1-abstract-full').style.display = 'inline'; document.getElementById('1912.01972v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1912.01972v1-abstract-full" style="display: none;">
        This paper describes the SemEval--2016 Task 3 on Community Question Answering, which we offered in English and Arabic. For English, we had three subtasks: Question--Comment Similarity (subtask A), Question--Question Similarity (B), and Question--External Comment Similarity (C). For Arabic, we had another subtask: Rerank the correct answers for a new question (D). Eighteen teams participated in the task, submitting a total of 95 runs (38 primary and 57 contrastive) for the four subtasks. A variety of approaches and features were used by the participating systems to address the different subtasks, which are summarized in this paper. The best systems achieved an official score (MAP) of 79.19, 76.70, 55.41, and 45.83 in subtasks A, B, C, and D, respectively. These scores are significantly better than those for the baselines that we provided. For subtask A, the best system improved over the 2015 winner by 3 points absolute in terms of Accuracy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.01972v1-abstract-full').style.display = 'none'; document.getElementById('1912.01972v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 December, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">community question answering, question-question similarity, question-comment similarity, answer reranking, English, Arabic. arXiv admin note: substantial text overlap with arXiv:1912.00730</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        SemEval-2016
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1912.00730">arXiv:1912.00730</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1912.00730">pdf</a>, <a href="https://arxiv.org/format/1912.00730">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SemEval-2017 Task 3: Community Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hoogeveen%2C+D">Doris Hoogeveen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%C3%A0rquez%2C+L">Lluís Màrquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mubarak%2C+H">Hamdy Mubarak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baldwin%2C+T">Timothy Baldwin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Verspoor%2C+K">Karin Verspoor</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1912.00730v1-abstract-short" style="display: inline;">
        We describe SemEval-2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016:(A) Question-Comment Similarity,(B) Question-Question Similarity,(C) Question-External Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.00730v1-abstract-full').style.display = 'inline'; document.getElementById('1912.00730v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1912.00730v1-abstract-full" style="display: none;">
        We describe SemEval-2017 Task 3 on Community Question Answering. This year, we reran the four subtasks from SemEval-2016:(A) Question-Comment Similarity,(B) Question-Question Similarity,(C) Question-External Comment Similarity, and (D) Rerank the correct answers for a new question in Arabic, providing all the data from 2015 and 2016 for training, and fresh data for testing. Additionally, we added a new subtask E in order to enable experimentation with Multi-domain Question Duplicate Detection in a larger-scale scenario, using StackExchange subforums. A total of 23 teams participated in the task, and submitted a total of 85 runs (36 primary and 49 contrastive) for subtasks A-D. Unfortunately, no teams participated in subtask E. A variety of approaches and features were used by the participating systems to address the different subtasks. The best systems achieved an official score (MAP) of 88.43, 47.22, 15.46, and 61.16 in subtasks A, B, C, and D, respectively. These scores are better than the baselines, especially for subtasks A-C.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1912.00730v1-abstract-full').style.display = 'none'; document.getElementById('1912.00730v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 December, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">community question answering, question-question similarity, question-comment similarity, answer reranking, Multi-domain Question Duplicate Detection, StackExchange, English, Arabic</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        SemEval-2017
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.11403">arXiv:1911.11403</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.11403">pdf</a>, <a href="https://arxiv.org/format/1911.11403">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        SemEval-2015 Task 3: Answer Selection in Community Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%C3%A0rquez%2C+L">Lluís Màrquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Magdy%2C+W">Walid Magdy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glass%2C+J">James Glass</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Randeree%2C+B">Bilal Randeree</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.11403v1-abstract-short" style="display: inline;">
        Community Question Answering (cQA) provides new interesting research directions to the traditional Question Answering (QA) field, e.g., the exploitation of the interaction between users and the structure of related posts. In this context, we organized SemEval-2015 Task 3 on &#34;Answer Selection in cQA&#34;, which included two subtasks: (a) classifying answers as &#34;good&#34;, &#34;bad&#34;, or &#34;potentially relevant&#34; w&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.11403v1-abstract-full').style.display = 'inline'; document.getElementById('1911.11403v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.11403v1-abstract-full" style="display: none;">
        Community Question Answering (cQA) provides new interesting research directions to the traditional Question Answering (QA) field, e.g., the exploitation of the interaction between users and the structure of related posts. In this context, we organized SemEval-2015 Task 3 on &#34;Answer Selection in cQA&#34;, which included two subtasks: (a) classifying answers as &#34;good&#34;, &#34;bad&#34;, or &#34;potentially relevant&#34; with respect to the question, and (b) answering a YES/NO question with &#34;yes&#34;, &#34;no&#34;, or &#34;unsure&#34;, based on the list of all answers. We set subtask A for Arabic and English on two relatively different cQA domains, i.e., the Qatar Living website for English, and a Quran-related website for Arabic. We used crowdsourcing on Amazon Mechanical Turk to label a large English training dataset, which we released to the research community. Thirteen teams participated in the challenge with a total of 61 submissions: 24 primary and 37 contrastive. The best systems achieved an official score (macro-averaged F1) of 57.19 and 63.7 for the English subtasks A and B, and 78.55 for the Arabic subtask A.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.11403v1-abstract-full').style.display = 'none'; document.getElementById('1911.11403v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 November, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">community question answering, answer selection, English, Arabic</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        SemEval-2015
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.08755">arXiv:1911.08755</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.08755">pdf</a>, <a href="https://arxiv.org/ps/1911.08755">ps</a>, <a href="https://arxiv.org/format/1911.08755">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Information Retrieval">cs.IR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Global Thread-Level Inference for Comment Classification in Community Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Joty%2C+S">Shafiq Joty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barr%C3%B3n-Cede%C3%B1o%2C+A">Alberto Barrón-Cedeño</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martino%2C+G+D+S">Giovanni Da San Martino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Filice%2C+S">Simone Filice</a>, 
      
      <a href="/search/?searchtype=author&amp;query=M%C3%A0rquez%2C+L">Lluís Màrquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.08755v1-abstract-short" style="display: inline;">
        Community question answering, a recent evolution of question answering in the Web context, allows a user to quickly consult the opinion of a number of people on a particular topic, thus taking advantage of the wisdom of the crowd. Here we try to help the user by deciding automatically which answers are good and which are bad for a given question. In particular, we focus on exploiting the output st&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.08755v1-abstract-full').style.display = 'inline'; document.getElementById('1911.08755v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.08755v1-abstract-full" style="display: none;">
        Community question answering, a recent evolution of question answering in the Web context, allows a user to quickly consult the opinion of a number of people on a particular topic, thus taking advantage of the wisdom of the crowd. Here we try to help the user by deciding automatically which answers are good and which are bad for a given question. In particular, we focus on exploiting the output structure at the thread level in order to make more consistent global decisions. More specifically, we exploit the relations between pairs of comments at any distance in the thread, which we incorporate in a graph-cut and in an ILP frameworks. We evaluated our approach on the benchmark dataset of SemEval-2015 Task 3. Results improved over the state of the art, confirming the importance of using thread level information.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.08755v1-abstract-full').style.display = 'none'; document.getElementById('1911.08755v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 November, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">community question answering, thread-level inference, graph-cut, inductive logic programming</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        EMNLP-2015
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1911.04118">arXiv:1911.04118</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1911.04118">pdf</a>, <a href="https://arxiv.org/format/1911.04118">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        TANDA: Transfer and Adapt Pre-Trained Transformer Models for Answer Sentence Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Garg%2C+S">Siddhant Garg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vu%2C+T">Thuy Vu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1911.04118v2-abstract-short" style="display: inline;">
        We propose TANDA, an effective technique for fine-tuning pre-trained Transformer models for natural language tasks. Specifically, we first transfer a pre-trained model into a model for a general task by fine-tuning it with a large and high-quality dataset. We then perform a second fine-tuning step to adapt the transferred model to the target domain. We demonstrate the benefits of our approach for&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.04118v2-abstract-full').style.display = 'inline'; document.getElementById('1911.04118v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1911.04118v2-abstract-full" style="display: none;">
        We propose TANDA, an effective technique for fine-tuning pre-trained Transformer models for natural language tasks. Specifically, we first transfer a pre-trained model into a model for a general task by fine-tuning it with a large and high-quality dataset. We then perform a second fine-tuning step to adapt the transferred model to the target domain. We demonstrate the benefits of our approach for answer sentence selection, which is a well-known inference task in Question Answering. We built a large scale dataset to enable the transfer step, exploiting the Natural Questions dataset. Our approach establishes the state of the art on two well-known benchmarks, WikiQA and TREC-QA, achieving MAP scores of 92% and 94.3%, respectively, which largely outperform the previous highest scores of 83.4% and 87.5%, obtained in very recent work. We empirically show that TANDA generates more stable and robust models reducing the effort required for selecting optimal hyper-parameters. Additionally, we show that the transfer step of TANDA makes the adaptation step more robust to noise. This enables a more effective use of noisy datasets for fine-tuning. Finally, we also confirm the positive impact of TANDA in an industrial setting, using domain specific datasets subject to different types of noise.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1911.04118v2-abstract-full').style.display = 'none'; document.getElementById('1911.04118v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 November, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 11 November, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI 2020), Oral Presentation</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1902.05309">arXiv:1902.05309</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1902.05309">pdf</a>, <a href="https://arxiv.org/format/1902.05309">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Transfer Learning for Sequence Labeling Using Source Model and Target Data
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+L">Lingzhen Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1902.05309v1-abstract-short" style="display: inline;">
        In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in addi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.05309v1-abstract-full').style.display = 'inline'; document.getElementById('1902.05309v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1902.05309v1-abstract-full" style="display: none;">
        In this paper, we propose an approach for transferring the knowledge of a neural model for sequence labeling, learned from the source domain, to a new model trained on a target domain, where new label categories appear. Our transfer learning (TL) techniques enable to adapt the source model using the target data and new categories, without accessing to the source data. Our solution consists in adding new neurons in the output layer of the target model and transferring parameters from the source model, which are then fine-tuned with the target data. Additionally, we propose a neural adapter to learn the difference between the source and the target label distribution, which provides additional important information to the target model. Our experiments on Named Entity Recognition show that (i) the learned knowledge in the source model can be effectively transferred when the target data contains new categories and (ii) our neural adapter further improves such transfer.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1902.05309v1-abstract-full').style.display = 'none'; document.getElementById('1902.05309v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 14 February, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 4 figures, 3 tables, accepted paper in the Thirty-Third AAAI Conference on Artificial Intelligence (AAAI-19)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1809.02255">arXiv:1809.02255</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1809.02255">pdf</a>, <a href="https://arxiv.org/format/1809.02255">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Adversarial Domain Adaptation for Duplicate Question Detection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Shah%2C+D+J">Darsh J Shah</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+T">Tao Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romeo%2C+S">Salvatore Romeo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1809.02255v1-abstract-short" style="display: inline;">
        We address the problem of detecting duplicate questions in forums, which is an important step towards automating the process of answering new questions. As finding and annotating such potential duplicates manually is very tedious and costly, automatic methods based on machine learning are a viable alternative. However, many forums do not have annotated data, i.e., questions labeled by experts as d&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.02255v1-abstract-full').style.display = 'inline'; document.getElementById('1809.02255v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1809.02255v1-abstract-full" style="display: none;">
        We address the problem of detecting duplicate questions in forums, which is an important step towards automating the process of answering new questions. As finding and annotating such potential duplicates manually is very tedious and costly, automatic methods based on machine learning are a viable alternative. However, many forums do not have annotated data, i.e., questions labeled by experts as duplicates, and thus a promising solution is to use domain adaptation from another forum that has such annotations. Here we focus on adversarial domain adaptation, deriving important findings about when it performs well and what properties of the domains are important in this regard. Our experiments with StackExchange data show an average improvement of 5.6% over the best baseline across multiple pairs of domains.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1809.02255v1-abstract-full').style.display = 'none'; document.getElementById('1809.02255v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 September, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">EMNLP 2018 short paper - camera ready. 8 pages</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1806.08009">arXiv:1806.08009</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1806.08009">pdf</a>, <a href="https://arxiv.org/format/1806.08009">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Injecting Relational Structural Representation in Neural Networks for Question Similarity
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Uva%2C+A">Antonio Uva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonadiman%2C+D">Daniele Bonadiman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1806.08009v1-abstract-short" style="display: inline;">
        Effectively using full syntactic parsing information in Neural Networks (NNs) to solve relational tasks, e.g., question similarity, is still an open problem. In this paper, we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) pre&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.08009v1-abstract-full').style.display = 'inline'; document.getElementById('1806.08009v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1806.08009v1-abstract-full" style="display: none;">
        Effectively using full syntactic parsing information in Neural Networks (NNs) to solve relational tasks, e.g., question similarity, is still an open problem. In this paper, we propose to inject structural representations in NNs by (i) learning an SVM model using Tree Kernels (TKs) on relatively few pairs of questions (few thousands) as gold standard (GS) training data is typically scarce, (ii) predicting labels on a very large corpus of question pairs, and (iii) pre-training NNs on such large corpus. The results on Quora and SemEval question similarity datasets show that NNs trained with our approach can learn more accurate models, especially after fine tuning on GS.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1806.08009v1-abstract-full').style.display = 'none'; document.getElementById('1806.08009v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 June, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">ACL2018</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1804.08012">arXiv:1804.08012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1804.08012">pdf</a>, <a href="https://arxiv.org/ps/1804.08012">ps</a>, <a href="https://arxiv.org/format/1804.08012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Integrating Stance Detection and Fact Checking in a Unified Corpus
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Baly%2C+R">Ramy Baly</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mohtarami%2C+M">Mitra Mohtarami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glass%2C+J">James Glass</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marquez%2C+L">Lluis Marquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1804.08012v1-abstract-short" style="display: inline;">
        A reasonable approach for fact checking a claim involves retrieving potentially relevant documents from different sources (e.g., news websites, social media, etc.), determining the stance of each document with respect to the claim, and finally making a prediction about the claim&#39;s factuality by aggregating the strength of the stances, while taking the reliability of the source into account. Moreov&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.08012v1-abstract-full').style.display = 'inline'; document.getElementById('1804.08012v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1804.08012v1-abstract-full" style="display: none;">
        A reasonable approach for fact checking a claim involves retrieving potentially relevant documents from different sources (e.g., news websites, social media, etc.), determining the stance of each document with respect to the claim, and finally making a prediction about the claim&#39;s factuality by aggregating the strength of the stances, while taking the reliability of the source into account. Moreover, a fact checking system should be able to explain its decision by providing relevant extracts (rationales) from the documents. Yet, this setup is not directly supported by existing datasets, which treat fact checking, document retrieval, source credibility, stance detection and rationale extraction as independent tasks. In this paper, we support the interdependencies between these tasks as annotations in the same corpus. We implement this setup on an Arabic fact checking corpus, the first of its kind.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.08012v1-abstract-full').style.display = 'none'; document.getElementById('1804.08012v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 April, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Stance Detection, Fact-Checking, Veracity, Arabic, NAACL-2018</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1804.07581">arXiv:1804.07581</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1804.07581">pdf</a>, <a href="https://arxiv.org/format/1804.07581">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Automatic Stance Detection Using End-to-End Memory Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mohtarami%2C+M">Mitra Mohtarami</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baly%2C+R">Ramy Baly</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Glass%2C+J">James Glass</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marquez%2C+L">Lluis Marquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1804.07581v1-abstract-short" style="display: inline;">
        We present a novel end-to-end memory network for stance detection, which jointly (i) predicts whether a document agrees, disagrees, discusses or is unrelated with respect to a given target claim, and also (ii) extracts snippets of evidence for that prediction. The network operates at the paragraph level and integrates convolutional and recurrent neural networks, as well as a similarity matrix as p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.07581v1-abstract-full').style.display = 'inline'; document.getElementById('1804.07581v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1804.07581v1-abstract-full" style="display: none;">
        We present a novel end-to-end memory network for stance detection, which jointly (i) predicts whether a document agrees, disagrees, discusses or is unrelated with respect to a given target claim, and also (ii) extracts snippets of evidence for that prediction. The network operates at the paragraph level and integrates convolutional and recurrent neural networks, as well as a similarity matrix as part of the overall architecture. The experimental evaluation on the Fake News Challenge dataset shows state-of-the-art performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1804.07581v1-abstract-full').style.display = 'none'; document.getElementById('1804.07581v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 April, 2018; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2018.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory networks; Neural Networks; Distributed Representations</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1710.01487">arXiv:1710.01487</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1710.01487">pdf</a>, <a href="https://arxiv.org/format/1710.01487">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Cross-Language Question Re-Ranking
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Martino%2C+G+D+S">Giovanni Da San Martino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romeo%2C+S">Salvatore Romeo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barron-Cedeno%2C+A">Alberto Barron-Cedeno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joty%2C+S">Shafiq Joty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marquez%2C+L">Lluis Marquez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1710.01487v1-abstract-short" style="display: inline;">
        We study how to find relevant questions in community forums when the language of the new questions is different from that of the existing questions in the forum. In particular, we explore the Arabic-English language pair. We compare a kernel-based system with a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.01487v1-abstract-full').style.display = 'inline'; document.getElementById('1710.01487v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1710.01487v1-abstract-full" style="display: none;">
        We study how to find relevant questions in community forums when the language of the new questions is different from that of the existing questions in the forum. In particular, we explore the Arabic-English language pair. We compare a kernel-based system with a feed-forward neural network in a scenario where a large parallel corpus is available for training a machine translation system, bilingual dictionaries, and cross-language word embeddings. We observe that both approaches degrade the performance of the system when working on the translated text, especially the kernel-based system, which depends heavily on a syntactic kernel. We address this issue using a cross-language tree kernel, which compares the original Arabic tree to the English trees of the related questions. We show that this kernel almost closes the performance gap with respect to the monolingual system. On the neural network side, we use the parallel corpus to train cross-language embeddings, which we then use to represent the Arabic input and the English related questions in the same space. The results also improve to close to those of the monolingual neural network. Overall, the kernel system shows a better performance compared to the neural network in all cases.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.01487v1-abstract-full').style.display = 'none'; document.getElementById('1710.01487v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 4 October, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">SIGIR-2017; Community Question Answering; Cross-language Approaches; Question Retrieval; Kernel-based Methods; Neural Networks; Distributed Representations</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        SIGIR 2017: 1145-1148
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1710.00689">arXiv:1710.00689</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1710.00689">pdf</a>, <a href="https://arxiv.org/ps/1710.00689">ps</a>, <a href="https://arxiv.org/format/1710.00689">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Building Chatbots from Forum Data: Model Selection Using Question Answering Metrics
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Boyanov%2C+M">Martin Boyanov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koychev%2C+I">Ivan Koychev</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Nakov%2C+P">Preslav Nakov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Martino%2C+G+D+S">Giovanni Da San Martino</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1710.00689v1-abstract-short" style="display: inline;">
        We propose to use question answering (QA) data from Web forums to train chatbots from scratch, i.e., without dialog training data. First, we extract pairs of question and answer sentences from the typically much longer texts of questions and answers in a forum. We then use these shorter texts to train seq2seq models in a more efficient way. We further improve the parameter optimization using a new&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.00689v1-abstract-full').style.display = 'inline'; document.getElementById('1710.00689v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1710.00689v1-abstract-full" style="display: none;">
        We propose to use question answering (QA) data from Web forums to train chatbots from scratch, i.e., without dialog training data. First, we extract pairs of question and answer sentences from the typically much longer texts of questions and answers in a forum. We then use these shorter texts to train seq2seq models in a more efficient way. We further improve the parameter optimization using a new model selection strategy based on QA measures. Finally, we propose to use extrinsic evaluation with respect to a QA task as an automatic evaluation method for chatbots. The evaluation shows that the model achieves a MAP of 63.5% on the extrinsic task. Moreover, it can answer correctly 49.5% of the questions when they are similar to questions asked in the forum, and 47.3% of the questions when they are more conversational in style.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1710.00689v1-abstract-full').style.display = 'none'; document.getElementById('1710.00689v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 October, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">RANLP-2017</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          68T50
        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1702.03706">arXiv:1702.03706</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1702.03706">pdf</a>, <a href="https://arxiv.org/format/1702.03706">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multitask Learning with Deep Neural Networks for Community Question Answering
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bonadiman%2C+D">Daniele Bonadiman</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Uva%2C+A">Antonio Uva</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1702.03706v1-abstract-short" style="display: inline;">
        In this paper, we developed a deep neural network (DNN) that learns to solve simultaneously the three tasks of the cQA challenge proposed by the SemEval-2016 Task 3, i.e., question-comment similarity, question-question similarity and new question-comment similarity. The latter is the main task, which can exploit the previous two for achieving better results. Our DNN is trained jointly on all the t&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1702.03706v1-abstract-full').style.display = 'inline'; document.getElementById('1702.03706v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1702.03706v1-abstract-full" style="display: none;">
        In this paper, we developed a deep neural network (DNN) that learns to solve simultaneously the three tasks of the cQA challenge proposed by the SemEval-2016 Task 3, i.e., question-comment similarity, question-question similarity and new question-comment similarity. The latter is the main task, which can exploit the previous two for achieving better results. Our DNN is trained jointly on all the three cQA tasks and learns to encode questions and comments into a single vector representation shared across the multiple tasks. The results on the official challenge test set show that our approach produces higher accuracy and faster convergence rates than the individual neural networks. Additionally, our method, which does not use any manual feature engineering, approaches the state of the art established with methods that make heavy use of it.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1702.03706v1-abstract-full').style.display = 'none'; document.getElementById('1702.03706v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 February, 2017; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2017.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1610.05522">arXiv:1610.05522</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1610.05522">pdf</a>, <a href="https://arxiv.org/format/1610.05522">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Addressing Community Question Answering in English and Arabic
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Martino%2C+G+D+S">Giovanni Da San Martino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barr%C3%B3n-Cede%C3%B1o%2C+A">Alberto Barrón-Cedeño</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romeo%2C+S">Salvatore Romeo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joty%2C+S">Shafiq Joty</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Obaidli%2C+F+A+A">Fahad A. Al Obaidli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tymoshenko%2C+K">Kateryna Tymoshenko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Uva%2C+A">Antonio Uva</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1610.05522v1-abstract-short" style="display: inline;">
        This paper studies the impact of different types of features applied to learning to re-rank questions in community Question Answering. We tested our models on two datasets released in SemEval-2016 Task 3 on &#34;Community Question Answering&#34;. Task 3 targeted real-life Web fora both in English and Arabic. Our models include bag-of-words features (BoW), syntactic tree kernels (TKs), rank features, embed&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1610.05522v1-abstract-full').style.display = 'inline'; document.getElementById('1610.05522v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1610.05522v1-abstract-full" style="display: none;">
        This paper studies the impact of different types of features applied to learning to re-rank questions in community Question Answering. We tested our models on two datasets released in SemEval-2016 Task 3 on &#34;Community Question Answering&#34;. Task 3 targeted real-life Web fora both in English and Arabic. Our models include bag-of-words features (BoW), syntactic tree kernels (TKs), rank features, embeddings, and machine translation evaluation features. To the best of our knowledge, structural kernels have barely been applied to the question reranking task, where they have to model paraphrase relations. In the case of the English question re-ranking task, we compare our learning to rank (L2R) algorithms against a strong baseline given by the Google-generated ranking (GR). The results show that i) the shallow structures used in our TKs are robust enough to noisy data and ii) improving GR is possible, but effective BoW features and TKs along with an accurate model of GR features in the used L2R algorithm are required. In the case of the Arabic question re-ranking task, for the first time we applied tree kernels on syntactic trees of Arabic sentences. Our approaches to both tasks obtained the second best results on SemEval-2016 subtasks B on English and D on Arabic.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1610.05522v1-abstract-full').style.display = 'none'; document.getElementById('1610.05522v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 October, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2016.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">presented at Second WebQA workshop, SIGIR2016 (http://plg2.cs.uwaterloo.ca/~avtyurin/WebQA2016/)</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          I.2.7; H.3.4
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1604.01178">arXiv:1604.01178</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1604.01178">pdf</a>, <a href="https://arxiv.org/format/1604.01178">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Modeling Relational Information in Question-Answer Pairs with Convolutional Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Severyn%2C+A">Aliaksei Severyn</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1604.01178v1-abstract-short" style="display: inline;">
        In this paper, we propose convolutional neural networks for learning an optimal representation of question and answer sentences. Their main aspect is the use of relational information given by the matches between words from the two members of the pair. The matches are encoded as embeddings with additional parameters (dimensions), which are tuned by the network. These allows for better capturing in&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.01178v1-abstract-full').style.display = 'inline'; document.getElementById('1604.01178v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1604.01178v1-abstract-full" style="display: none;">
        In this paper, we propose convolutional neural networks for learning an optimal representation of question and answer sentences. Their main aspect is the use of relational information given by the matches between words from the two members of the pair. The matches are encoded as embeddings with additional parameters (dimensions), which are tuned by the network. These allows for better capturing interactions between questions and answers, resulting in a significant boost in accuracy. We test our models on two widely used answer sentence selection benchmarks. The results clearly show the effectiveness of our relational information, which allows our relatively simple network to approach the state of the art.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1604.01178v1-abstract-full').style.display = 'none'; document.getElementById('1604.01178v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 April, 2016; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2016.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1512.05726">arXiv:1512.05726</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1512.05726">pdf</a>, <a href="https://arxiv.org/format/1512.05726">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Neural and Evolutionary Computing">cs.NE</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Semi-supervised Question Retrieval with Gated Convolutions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lei%2C+T">Tao Lei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Joshi%2C+H">Hrishikesh Joshi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Barzilay%2C+R">Regina Barzilay</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jaakkola%2C+T">Tommi Jaakkola</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tymoshenko%2C+K">Katerina Tymoshenko</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Moschitti%2C+A">Alessandro Moschitti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marquez%2C+L">Lluis Marquez</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1512.05726v2-abstract-short" style="display: inline;">
        Question answering forums are rapidly growing in size with no effective automated ability to refer to and reuse answers already available for previous posted questions. In this paper, we develop a methodology for finding semantically related questions. The task is difficult since 1) key pieces of information are often buried in extraneous details in the question body and 2) available annotations o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1512.05726v2-abstract-full').style.display = 'inline'; document.getElementById('1512.05726v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1512.05726v2-abstract-full" style="display: none;">
        Question answering forums are rapidly growing in size with no effective automated ability to refer to and reuse answers already available for previous posted questions. In this paper, we develop a methodology for finding semantically related questions. The task is difficult since 1) key pieces of information are often buried in extraneous details in the question body and 2) available annotations on similar questions are scarce and fragmented. We design a recurrent and convolutional model (gated convolution) to effectively map questions to their semantic representations. The models are pre-trained within an encoder-decoder framework (from body to title) on the basis of the entire raw corpus, and fine-tuned discriminatively from limited annotations. Our evaluation demonstrates that our model yields substantial gains over a standard IR baseline and various neural network architectures (including CNNs, LSTMs and GRUs).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1512.05726v2-abstract-full').style.display = 'none'; document.getElementById('1512.05726v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 3 April, 2016; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 December, 2015;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2015.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">NAACL 2016</span>
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>