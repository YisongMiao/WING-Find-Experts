<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;20 of 20 results for author: <span class="mathjax">Nathan Sturtevant</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Nathan Sturtevant">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Nathan+Sturtevant&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Nathan Sturtevant">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      




<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.17730">arXiv:2507.17730</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.17730">pdf</a>, <a href="https://arxiv.org/ps/2507.17730">ps</a>, <a href="https://arxiv.org/format/2507.17730">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Online Submission and Evaluation System Design for Competition Operations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+Z">Zhe Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harabor%2C+D">Daniel Harabor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hechnenberger%2C+R">Ryan Hechnenberger</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.17730v1-abstract-short" style="display: inline;">
        Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.17730v1-abstract-full').style.display = 'inline'; document.getElementById('2507.17730v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.17730v1-abstract-full" style="display: none;">
        Research communities have developed benchmark datasets across domains to compare the performance of algorithms and techniques However, tracking the progress in these research areas is not easy, as publications appear in different venues at the same time, and many of them claim to represent the state-of-the-art. To address this, research communities often organise periodic competitions to evaluate the performance of various algorithms and techniques, thereby tracking advancements in the field. However, these competitions pose a significant operational burden. The organisers must manage and evaluate a large volume of submissions. Furthermore, participants typically develop their solutions in diverse environments, leading to compatibility issues during the evaluation of their submissions. This paper presents an online competition system that automates the submission and evaluation process for a competition. The competition system allows organisers to manage large numbers of submissions efficiently, utilising isolated environments to evaluate submissions. This system has already been used successfully for several competitions, including the Grid-Based Pathfinding Competition and the League of Robot Runners competition.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.17730v1-abstract-full').style.display = 'none'; document.getElementById('2507.17730v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This work was presented at the Workshop on the International Planning Competition (WIPC 2024)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.11916">arXiv:2507.11916</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.11916">pdf</a>, <a href="https://arxiv.org/ps/2507.11916">ps</a>, <a href="https://arxiv.org/format/2507.11916">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Distributed, Parallel, and Cluster Computing">cs.DC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Futuhi%2C+E">Ehsan Futuhi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.11916v1-abstract-short" style="display: inline;">
        The rapid advancement of GPU technology has unlocked powerful parallel processing capabilities, creating new opportunities to enhance classic search algorithms. A recent successful application of GPUs is in compressing large pattern database (PDB) heuristics using neural networks while preserving heuristic admissibility. However, very few algorithms have been designed to exploit GPUs during search&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.11916v1-abstract-full').style.display = 'inline'; document.getElementById('2507.11916v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.11916v1-abstract-full" style="display: none;">
        The rapid advancement of GPU technology has unlocked powerful parallel processing capabilities, creating new opportunities to enhance classic search algorithms. A recent successful application of GPUs is in compressing large pattern database (PDB) heuristics using neural networks while preserving heuristic admissibility. However, very few algorithms have been designed to exploit GPUs during search. Several variants of A* exist that batch GPU computations. In this paper we introduce a method for batching GPU computations in depth first search. In particular, we describe a new cost-bounded depth-first search (CB-DFS) method that leverages the combined parallelism of modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*}, an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an extensions of Budgeted Tree Search. Our approach builds on the general approach used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality guarantees. We evaluate the approach on the 3x3 Rubik&#39;s Cube and 4x4 sliding tile puzzle (STP), showing that GPU operations can be efficiently batched in DFS. Additionally, we conduct extensive experiments to analyze the effects of hyperparameters, neural network heuristic size, and hardware resources on performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.11916v1-abstract-full').style.display = 'none'; document.getElementById('2507.11916v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.18868">arXiv:2504.18868</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.18868">pdf</a>, <a href="https://arxiv.org/format/2504.18868">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Approximating Nash Equilibria in General-Sum Games via Meta-Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sychrovsk%C3%BD%2C+D">David Sychrovský</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Solinas%2C+C">Christopher Solinas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=MacQueen%2C+R">Revan MacQueen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+K">Kevin Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wright%2C+J+R">James R. Wright</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bowling%2C+M">Michael Bowling</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.18868v1-abstract-short" style="display: inline;">
        Nash equilibrium is perhaps the best-known solution concept in game theory. Such a solution assigns a strategy to each player which offers no incentive to unilaterally deviate. While a Nash equilibrium is guaranteed to always exist, the problem of finding one in general-sum games is PPAD-complete, generally considered intractable. Regret minimization is an efficient framework for approximating Nas&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18868v1-abstract-full').style.display = 'inline'; document.getElementById('2504.18868v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.18868v1-abstract-full" style="display: none;">
        Nash equilibrium is perhaps the best-known solution concept in game theory. Such a solution assigns a strategy to each player which offers no incentive to unilaterally deviate. While a Nash equilibrium is guaranteed to always exist, the problem of finding one in general-sum games is PPAD-complete, generally considered intractable. Regret minimization is an efficient framework for approximating Nash equilibria in two-player zero-sum games. However, in general-sum games, such algorithms are only guaranteed to converge to a coarse-correlated equilibrium (CCE), a solution concept where players can correlate their strategies. In this work, we use meta-learning to minimize the correlations in strategies produced by a regret minimizer. This encourages the regret minimizer to find strategies that are closer to a Nash equilibrium. The meta-learned regret minimizer is still guaranteed to converge to a CCE, but we give a bound on the distance to Nash equilibrium in terms of our meta-loss. We evaluate our approach in general-sum imperfect information games. Our algorithms provide significantly better approximations of Nash equilibria than state-of-the-art regret minimization techniques.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18868v1-abstract-full').style.display = 'none'; document.getElementById('2504.18868v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.10075">arXiv:2503.10075</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.10075">pdf</a>, <a href="https://arxiv.org/format/2503.10075">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Parallelizing Multi-objective A* Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ahmadi%2C+S">Saman Ahmadi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Raith%2C+A">Andrea Raith</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harabor%2C+D">Daniel Harabor</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jalili%2C+M">Mahdi Jalili</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.10075v1-abstract-short" style="display: inline;">
        The Multi-objective Shortest Path (MOSP) problem is a classic network optimization problem that aims to find all Pareto-optimal paths between two points in a graph with multiple edge costs. Recent studies on multi-objective search with A* (MOA*) have demonstrated superior performance in solving difficult MOSP instances. This paper presents a novel search framework that allows efficient paralleliza&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.10075v1-abstract-full').style.display = 'inline'; document.getElementById('2503.10075v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.10075v1-abstract-full" style="display: none;">
        The Multi-objective Shortest Path (MOSP) problem is a classic network optimization problem that aims to find all Pareto-optimal paths between two points in a graph with multiple edge costs. Recent studies on multi-objective search with A* (MOA*) have demonstrated superior performance in solving difficult MOSP instances. This paper presents a novel search framework that allows efficient parallelization of MOA* with different objective orders. The framework incorporates a unique upper bounding strategy that helps the search reduce the problem&#39;s dimensionality to one in certain cases. Experimental results demonstrate that the proposed framework can enhance the performance of recent A*-based solutions, with the speed-up proportional to the problem dimension.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.10075v1-abstract-full').style.display = 'none'; document.getElementById('2503.10075v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 page, 2 tables, 2 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.21104">arXiv:2412.21104</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.21104">pdf</a>, <a href="https://arxiv.org/format/2412.21104">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3233/FAIA240991">10.3233/FAIA240991 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On Parallel External-Memory Bidirectional Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Siag%2C+L">Lior Siag</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Shperberg%2C+S+S">Shahaf S. Shperberg</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Felner%2C+A">Ariel Felner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.21104v2-abstract-short" style="display: inline;">
        Parallelization and External Memory (PEM) techniques have significantly enhanced the capabilities of search algorithms when solving large-scale problems. Previous research on PEM has primarily centered on unidirectional algorithms, with only one publication on bidirectional PEM that focuses on the meet-in-the-middle (MM) algorithm. Building upon this foundation, this paper presents a framework tha&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.21104v2-abstract-full').style.display = 'inline'; document.getElementById('2412.21104v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.21104v2-abstract-full" style="display: none;">
        Parallelization and External Memory (PEM) techniques have significantly enhanced the capabilities of search algorithms when solving large-scale problems. Previous research on PEM has primarily centered on unidirectional algorithms, with only one publication on bidirectional PEM that focuses on the meet-in-the-middle (MM) algorithm. Building upon this foundation, this paper presents a framework that integrates both uni- and bi-directional best-first search algorithms into this framework. We then develop a PEM variant of the state-of-the-art bidirectional heuristic search (BiHS) algorithm BAE* (PEM-BAE*). As previous work on BiHS did not focus on scaling problem sizes, this work enables us to evaluate bidirectional algorithms on hard problems. Empirical evaluation shows that PEM-BAE* outperforms the PEM variants of A* and the MM algorithm, as well as a parallel variant of IDA*. These findings mark a significant milestone, revealing that bidirectional search algorithms clearly outperform unidirectional search algorithms across several domains, even when equipped with state-of-the-art heuristics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.21104v2-abstract-full').style.display = 'none'; document.getElementById('2412.21104v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 31 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 30 December, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">10 pages, includes conference paper and appendix</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2411.09089">arXiv:2411.09089</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2411.09089">pdf</a>, <a href="https://arxiv.org/format/2411.09089">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Set-Based Retrograde Analysis: Precomputing the Solution to 24-card Bridge Double Dummy Deals
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stone%2C+I">Isaac Stone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Schaeffer%2C+J">Jonathan Schaeffer</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2411.09089v1-abstract-short" style="display: inline;">
        Retrograde analysis is used in game-playing programs to solve states at the end of a game, working backwards toward the start of the game. The algorithm iterates through and computes the perfect-play value for as many states as resources allow. We introduce setrograde analysis which achieves the same results by operating on sets of states that have the same game value. The algorithm is demonstrate&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.09089v1-abstract-full').style.display = 'inline'; document.getElementById('2411.09089v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2411.09089v1-abstract-full" style="display: none;">
        Retrograde analysis is used in game-playing programs to solve states at the end of a game, working backwards toward the start of the game. The algorithm iterates through and computes the perfect-play value for as many states as resources allow. We introduce setrograde analysis which achieves the same results by operating on sets of states that have the same game value. The algorithm is demonstrated by computing exact solutions for Bridge double dummy card-play. For deals with 24 cards remaining to be played ($10^{27}$ states, which can be reduced to $10^{15}$ states using preexisting techniques), we strongly solve all deals. The setrograde algorithm performs a factor of $10^3$ fewer search operations than a standard retrograde algorithm, producing a database with a factor of $10^4$ fewer entries. For applicable domains, this allows retrograde searching to reach unprecedented search depths.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2411.09089v1-abstract-full').style.display = 'none'; document.getElementById('2411.09089v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 November, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2410.03733">arXiv:2410.03733</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2410.03733">pdf</a>, <a href="https://arxiv.org/format/2410.03733">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Evaluating the Effects of AI Directors for Quest Selection
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+K+K">Kristen K. Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guzdial%2C+M">Matthew Guzdial</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N">Nathan Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2410.03733v1-abstract-short" style="display: inline;">
        Modern commercial games are designed for mass appeal, not for individual players, but there is a unique opportunity in video games to better fit the individual through adapting game elements. In this paper, we focus on AI Directors, systems which can dynamically modify a game, that personalize the player experience to match the player&#39;s preference. In the past, some AI Director studies have provid&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.03733v1-abstract-full').style.display = 'inline'; document.getElementById('2410.03733v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2410.03733v1-abstract-full" style="display: none;">
        Modern commercial games are designed for mass appeal, not for individual players, but there is a unique opportunity in video games to better fit the individual through adapting game elements. In this paper, we focus on AI Directors, systems which can dynamically modify a game, that personalize the player experience to match the player&#39;s preference. In the past, some AI Director studies have provided inconclusive results, so their effect on player experience is not clear. We take three AI Directors and directly compare them in a human subject study to test their effectiveness on quest selection. Our results show that a non-random AI Director provides a better player experience than a random AI Director.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2410.03733v1-abstract-full').style.display = 'none'; document.getElementById('2410.03733v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2408.09028">arXiv:2408.09028</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2408.09028">pdf</a>, <a href="https://arxiv.org/ps/2408.09028">ps</a>, <a href="https://arxiv.org/format/2408.09028">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        On the Completeness of Conflict-Based Search: Temporally-Relative Duplicate Pruning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Walker%2C+T+T">Thayne T Walker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2408.09028v1-abstract-short" style="display: inline;">
        Conflict-Based Search (CBS) algorithm for the multi-agent pathfinding (MAPF) problem is that it is incomplete for problems which have no solution; if no mitigating procedure is run in parallel, CBS will run forever when given an unsolvable problem instance. In this work, we introduce Temporally-Relative Duplicate Pruning (TRDP), a technique for duplicate detection and removal in both classic and c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.09028v1-abstract-full').style.display = 'inline'; document.getElementById('2408.09028v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2408.09028v1-abstract-full" style="display: none;">
        Conflict-Based Search (CBS) algorithm for the multi-agent pathfinding (MAPF) problem is that it is incomplete for problems which have no solution; if no mitigating procedure is run in parallel, CBS will run forever when given an unsolvable problem instance. In this work, we introduce Temporally-Relative Duplicate Pruning (TRDP), a technique for duplicate detection and removal in both classic and continuous-time MAPF domains. TRDP is a simple procedure which closes the long-standing theoretic loophole of incompleteness for CBS by detecting and avoiding the expansion of duplicate states. TRDP is shown both theoretically and empirically to ensure termination without a significant impact on runtime in the majority of problem instances. In certain cases, TRDP is shown to increase performance significantly
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2408.09028v1-abstract-full').style.display = 'none'; document.getElementById('2408.09028v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 August, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">9 pages, 4 figures, 2 tables</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        

        
          <span class="has-text-black-bis has-text-weight-semibold">ACM Class:</span>
          F.2.2; I.2.8
        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2404.13150">arXiv:2404.13150</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2404.13150">pdf</a>, <a href="https://arxiv.org/ps/2404.13150">ps</a>, <a href="https://arxiv.org/format/2404.13150">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Transformer Based Planning in the Observation Space with Applications to Trick Taking Card Games
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rebstock%2C+D">Douglas Rebstock</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Solinas%2C+C">Christopher Solinas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buro%2C+M">Michael Buro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2404.13150v1-abstract-short" style="display: inline;">
        Traditional search algorithms have issues when applied to games of imperfect information where the number of possible underlying states and trajectories are very large. This challenge is particularly evident in trick-taking card games. While state sampling techniques such as Perfect Information Monte Carlo (PIMC) search has shown success in these contexts, they still have major limitations.
  We p&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.13150v1-abstract-full').style.display = 'inline'; document.getElementById('2404.13150v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2404.13150v1-abstract-full" style="display: none;">
        Traditional search algorithms have issues when applied to games of imperfect information where the number of possible underlying states and trajectories are very large. This challenge is particularly evident in trick-taking card games. While state sampling techniques such as Perfect Information Monte Carlo (PIMC) search has shown success in these contexts, they still have major limitations.
  We present Generative Observation Monte Carlo Tree Search (GO-MCTS), which utilizes MCTS on observation sequences generated by a game specific model. This method performs the search within the observation space and advances the search using a model that depends solely on the agent&#39;s observations. Additionally, we demonstrate that transformers are well-suited as the generative model in this context, and we demonstrate a process for iteratively training the transformer via population-based self-play.
  The efficacy of GO-MCTS is demonstrated in various games of imperfect information, such as Hearts, Skat, and &#34;The Crew: The Quest for Planet Nine,&#34; with promising results.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2404.13150v1-abstract-full').style.display = 'none'; document.getElementById('2404.13150v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 April, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.16106">arXiv:2312.16106</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.16106">pdf</a>, <a href="https://arxiv.org/format/2312.16106">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Clique Analysis and Bypassing in Continuous-Time Conflict-Based Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Walker%2C+T+T">Thayne T. Walker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Felner%2C+A">Ariel Felner</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.16106v1-abstract-short" style="display: inline;">
        While the study of unit-cost Multi-Agent Pathfinding (MAPF) problems has been popular, many real-world problems require continuous time and costs due to various movement models. In this context, this paper studies symmetry-breaking enhancements for Continuous-Time Conflict-Based Search (CCBS), a solver for continuous-time MAPF. Resolving conflict symmetries in MAPF can require an exponential amoun&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.16106v1-abstract-full').style.display = 'inline'; document.getElementById('2312.16106v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.16106v1-abstract-full" style="display: none;">
        While the study of unit-cost Multi-Agent Pathfinding (MAPF) problems has been popular, many real-world problems require continuous time and costs due to various movement models. In this context, this paper studies symmetry-breaking enhancements for Continuous-Time Conflict-Based Search (CCBS), a solver for continuous-time MAPF. Resolving conflict symmetries in MAPF can require an exponential amount of work. We adapt known enhancements from unit-cost domains for CCBS: bypassing, which resolves cost symmetries and biclique constraints which resolve spatial conflict symmetries. We formulate a novel combination of biclique constraints with disjoint splitting for spatial conflict symmetries. Finally, we show empirically that these enhancements yield a statistically significant performance improvement versus previous state of the art, solving problems for up to 10% or 20% more agents in the same amount of time on dense graphs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.16106v1-abstract-full').style.display = 'none'; document.getElementById('2312.16106v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 December, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.14651">arXiv:2311.14651</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.14651">pdf</a>, <a href="https://arxiv.org/format/2311.14651">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Science and Game Theory">cs.GT</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        History Filtering in Imperfect Information Games: Algorithms and Complexity
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Solinas%2C+C">Christopher Solinas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rebstock%2C+D">Douglas Rebstock</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buro%2C+M">Michael Buro</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.14651v1-abstract-short" style="display: inline;">
        Historically applied exclusively to perfect information games, depth-limited search with value functions has been key to recent advances in AI for imperfect information games. Most prominent approaches with strong theoretical guarantees require subgame decomposition - a process in which a subgame is computed from public information and player beliefs. However, subgame decomposition can itself requ&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.14651v1-abstract-full').style.display = 'inline'; document.getElementById('2311.14651v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.14651v1-abstract-full" style="display: none;">
        Historically applied exclusively to perfect information games, depth-limited search with value functions has been key to recent advances in AI for imperfect information games. Most prominent approaches with strong theoretical guarantees require subgame decomposition - a process in which a subgame is computed from public information and player beliefs. However, subgame decomposition can itself require non-trivial computations, and its tractability depends on the existence of efficient algorithms for either full enumeration or generation of the histories that form the root of the subgame. Despite this, no formal analysis of the tractability of such computations has been established in prior work, and application domains have often consisted of games, such as poker, for which enumeration is trivial on modern hardware. Applying these ideas to more complex domains requires understanding their cost.
  In this work, we introduce and analyze the computational aspects and tractability of filtering histories for subgame decomposition. We show that constructing a single history from the root of the subgame is generally intractable, and then provide a necessary and sufficient condition for efficient enumeration. We also introduce a novel Markov Chain Monte Carlo-based generation algorithm for trick-taking card games - a domain where enumeration is often prohibitively expensive. Our experiments demonstrate its improved scalability in the trick-taking card game Oh Hell. These contributions clarify when and how depth-limited search via subgame decomposition can be an effective tool for sequential decision-making in imperfect information settings.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.14651v1-abstract-full').style.display = 'none'; document.getElementById('2311.14651v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 November, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.04148">arXiv:2110.04148</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.04148">pdf</a>, <a href="https://arxiv.org/format/2110.04148">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Definition-Context-Purpose Paradigm and Other Insights from Industry Professionals About the Definition of a Quest
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Yu%2C+K+K">Kristen K. Yu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Guzdial%2C+M">Matthew Guzdial</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.04148v1-abstract-short" style="display: inline;">
        Among academic communities there is no single agreed upon definition of a quest. The industry perspective on this topic is also largely unknown. Thus, thee purpose of this paper is to gain an understanding of the definition of a quest from industry professionals to better inform the academic community. We interviewed fifteen game developers with experience designing or implementing quests or narra&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.04148v1-abstract-full').style.display = 'inline'; document.getElementById('2110.04148v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.04148v1-abstract-full" style="display: none;">
        Among academic communities there is no single agreed upon definition of a quest. The industry perspective on this topic is also largely unknown. Thus, thee purpose of this paper is to gain an understanding of the definition of a quest from industry professionals to better inform the academic community. We interviewed fifteen game developers with experience designing or implementing quests or narratives, and process the interviews using thematic analysis to identify trends. We identified a variety of personal developer definitions. However, we also discovered several themes that may inform future academic work. We introduce the definition-context-purpose paradigm as a synthesis of these trends: elements of a quest, purpose of a quest, and context of a quest. Finally, we discuss the developer&#39;s reaction to a recently proposed quest definition as part of a push towards a general quest definition.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.04148v1-abstract-full').style.display = 'none'; document.getElementById('2110.04148v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 2 figures, AIIDE 2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the 17th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment 2021 (AIIDE-21)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2110.04147">arXiv:2110.04147</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2110.04147">pdf</a>, <a href="https://arxiv.org/format/2110.04147">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Human-Computer Interaction">cs.HC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The Impact of Visualizing Design Gradients for Human Designers
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Guzdial%2C+M">Matthew Guzdial</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N">Nathan Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yang%2C+C">Carolyn Yang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2110.04147v1-abstract-short" style="display: inline;">
        Mixed-initiative Procedural Content Generation (PCG) refers to tools or systems in which a human designer works with an algorithm to produce game content. This area of research remains relatively under-explored, with the majority of mixed-initiative PCG level design systems using a common set of search-based PCG algorithms. In this paper, we introduce a mixed-initiative tool employing Exhaustive P&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.04147v1-abstract-full').style.display = 'inline'; document.getElementById('2110.04147v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2110.04147v1-abstract-full" style="display: none;">
        Mixed-initiative Procedural Content Generation (PCG) refers to tools or systems in which a human designer works with an algorithm to produce game content. This area of research remains relatively under-explored, with the majority of mixed-initiative PCG level design systems using a common set of search-based PCG algorithms. In this paper, we introduce a mixed-initiative tool employing Exhaustive PCG (EPCG) for puzzle level design to further explore mixed-initiative PCG. We run an online human subject study in which individuals use the tool with an EPCG component turned on or off. Our analysis of the results demonstrates that, although a majority of users did not prefer the tool, it made the level design process significantly easier, and that the tool impacted the subjects&#39; design process. This paper describes the study results and draws lessons for mixed-initiative PCG tool design.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2110.04147v1-abstract-full').style.display = 'none'; document.getElementById('2110.04147v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 October, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 1 figure, AIIDE 2021</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Proceedings of the 17th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment 2021 (AIIDE-21)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1908.09707">arXiv:1908.09707</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1908.09707">pdf</a>, <a href="https://arxiv.org/format/1908.09707">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computational Geometry">cs.CG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Graphics">cs.GR</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Systems and Control">eess.SY</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Collision Detection for Agents in Multi-Agent Pathfinding
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Walker%2C+T+T">Thayne T. Walker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1908.09707v3-abstract-short" style="display: inline;">
        Recent work on the multi-agent pathfinding problem (MAPF) has begun to study agents with motion that is more complex, for example, with non-unit action durations and kinematic constraints. An important aspect of MAPF is collision detection. Many collision detection approaches exist, but often suffer from issues such as high computational cost or causing false negative or false positive detections.&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1908.09707v3-abstract-full').style.display = 'inline'; document.getElementById('1908.09707v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1908.09707v3-abstract-full" style="display: none;">
        Recent work on the multi-agent pathfinding problem (MAPF) has begun to study agents with motion that is more complex, for example, with non-unit action durations and kinematic constraints. An important aspect of MAPF is collision detection. Many collision detection approaches exist, but often suffer from issues such as high computational cost or causing false negative or false positive detections. In practice, these issues can result in problems that range from inefficiency and annoyance to catastrophic. The main contribution of this technical report is to provide a high-level overview of major categories of collision detection, along with methods of collision detection and anticipatory collision avoidance for agents that are both computationally efficient and highly accurate.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1908.09707v3-abstract-full').style.display = 'none'; document.getElementById('1908.09707v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 November, 2019; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 August, 2019;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1907.13062">arXiv:1907.13062</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1907.13062">pdf</a>, <a href="https://arxiv.org/ps/1907.13062">ps</a>, <a href="https://arxiv.org/format/1907.13062">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Data Structures and Algorithms">cs.DS</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Iterative Budgeted Exponential Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Helmert%2C+M">Malte Helmert</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lattimore%2C+T">Tor Lattimore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lelis%2C+L+H+S">Levi H. S. Lelis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Orseau%2C+L">Laurent Orseau</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1907.13062v1-abstract-short" style="display: inline;">
        We tackle two long-standing problems related to re-expansions in heuristic search algorithms. For graph search, A* can require $Ω(2^{n})$ expansions, where $n$ is the number of states within the final $f$ bound. Existing algorithms that address this problem like B and B&#39; improve this bound to $Ω(n^2)$. For tree search, IDA* can also require $Ω(n^2)$ expansions. We describe a new algorithmic framew&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.13062v1-abstract-full').style.display = 'inline'; document.getElementById('1907.13062v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1907.13062v1-abstract-full" style="display: none;">
        We tackle two long-standing problems related to re-expansions in heuristic search algorithms. For graph search, A* can require $Ω(2^{n})$ expansions, where $n$ is the number of states within the final $f$ bound. Existing algorithms that address this problem like B and B&#39; improve this bound to $Ω(n^2)$. For tree search, IDA* can also require $Ω(n^2)$ expansions. We describe a new algorithmic framework that iteratively controls an expansion budget and solution cost limit, giving rise to new graph and tree search algorithms for which the number of expansions is $O(n \log C)$, where $C$ is the optimal solution cost. Our experiments show that the new algorithms are robust in scenarios where existing algorithms fail. In the case of tree search, our new algorithms have no overhead over IDA* in scenarios to which IDA* is well suited and can therefore be recommended as a general replacement for IDA*.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1907.13062v1-abstract-full').style.display = 'none'; document.getElementById('1907.13062v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 July, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2019.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.08291">arXiv:1906.08291</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.08291">pdf</a>, <a href="https://arxiv.org/format/1906.08291">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Multi-Agent Pathfinding: Definitions, Variants, and Benchmarks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Stern%2C+R">Roni Stern</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N">Nathan Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Felner%2C+A">Ariel Felner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Koenig%2C+S">Sven Koenig</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ma%2C+H">Hang Ma</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Walker%2C+T">Thayne Walker</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Li%2C+J">Jiaoyang Li</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Atzmon%2C+D">Dor Atzmon</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cohen%2C+L">Liron Cohen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kumar%2C+T+K+S">T. K. Satish Kumar</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Boyarski%2C+E">Eli Boyarski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bartak%2C+R">Roman Bartak</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.08291v1-abstract-short" style="display: inline;">
        The MAPF problem is the fundamental problem of planning paths for multiple agents, where the key constraint is that the agents will be able to follow these paths concurrently without colliding with each other. Applications of MAPF include automated warehouses and autonomous vehicles. Research on MAPF has been flourishing in the past couple of years. Different MAPF research papers make different as&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.08291v1-abstract-full').style.display = 'inline'; document.getElementById('1906.08291v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.08291v1-abstract-full" style="display: none;">
        The MAPF problem is the fundamental problem of planning paths for multiple agents, where the key constraint is that the agents will be able to follow these paths concurrently without colliding with each other. Applications of MAPF include automated warehouses and autonomous vehicles. Research on MAPF has been flourishing in the past couple of years. Different MAPF research papers make different assumptions, e.g., whether agents can traverse the same road at the same time, and have different objective functions, e.g., minimize makespan or sum of agents&#39; actions costs. These assumptions and objectives are sometimes implicitly assumed or described informally. This makes it difficult to establish appropriate baselines for comparison in research papers, as well as making it difficult for practitioners to find the papers relevant to their concrete application. This paper aims to fill this gap and support researchers and practitioners by providing a unifying terminology for describing common MAPF assumptions and objectives. In addition, we also provide pointers to two MAPF benchmarks. In particular, we introduce a new grid-based benchmark for MAPF, and demonstrate experimentally that it poses a challenge to contemporary MAPF algorithms.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.08291v1-abstract-full').style.display = 'none'; document.getElementById('1906.08291v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to SoCS 2019: The 12th Annual Symposium on Combinatorial Search</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1906.02912">arXiv:1906.02912</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1906.02912">pdf</a>, <a href="https://arxiv.org/format/1906.02912">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Exponential-Binary State-Space Search
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N">Nathan Sturtevant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Helmert%2C+M">Malte Helmert</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1906.02912v1-abstract-short" style="display: inline;">
        Iterative deepening search is used in applications where the best cost bound for state-space search is unknown. The iterative deepening process is used to avoid overshooting the appropriate cost bound and doing too much work as a result. However, iterative deepening search also does too much work if the cost bound grows too slowly. This paper proposes a new framework for iterative deepening search&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.02912v1-abstract-full').style.display = 'inline'; document.getElementById('1906.02912v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1906.02912v1-abstract-full" style="display: none;">
        Iterative deepening search is used in applications where the best cost bound for state-space search is unknown. The iterative deepening process is used to avoid overshooting the appropriate cost bound and doing too much work as a result. However, iterative deepening search also does too much work if the cost bound grows too slowly. This paper proposes a new framework for iterative deepening search called exponential-binary state-space search. The approach interleaves exponential and binary searches to find the desired cost bound, reducing the worst-case overhead from polynomial to logarithmic. Exponential-binary search can be used with bounded depth-first search to improve the worst-case performance of IDA* and with breadth-first heuristic search to improve the worst-case performance of search with inconsistent heuristics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1906.02912v1-abstract-full').style.display = 'none'; document.getElementById('1906.02912v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 June, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This paper and another independent IJCAI 2019 submission have been merged into a single paper that subsumes both of them (Helmert et. al., 2019). This paper is placed here only for historical context. Please only cite the subsuming paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1905.10911">arXiv:1905.10911</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1905.10911">pdf</a>, <a href="https://arxiv.org/format/1905.10911">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Policy Based Inference in Trick-Taking Card Games
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rebstock%2C+D">Douglas Rebstock</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Solinas%2C+C">Christopher Solinas</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Buro%2C+M">Michael Buro</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1905.10911v1-abstract-short" style="display: inline;">
        Trick-taking card games feature a large amount of private information that slowly gets revealed through a long sequence of actions. This makes the number of histories exponentially large in the action sequence length, as well as creating extremely large information sets. As a result, these games become too large to solve. To deal with these issues many algorithms employ inference, the estimation o&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1905.10911v1-abstract-full').style.display = 'inline'; document.getElementById('1905.10911v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1905.10911v1-abstract-full" style="display: none;">
        Trick-taking card games feature a large amount of private information that slowly gets revealed through a long sequence of actions. This makes the number of histories exponentially large in the action sequence length, as well as creating extremely large information sets. As a result, these games become too large to solve. To deal with these issues many algorithms employ inference, the estimation of the probability of states within an information set. In this paper, we demonstrate a Policy Based Inference (PI) algorithm that uses player modelling to infer the probability we are in a given state. We perform experiments in the German trick-taking card game Skat, in which we show that this method vastly improves the inference as compared to previous work, and increases the performance of the state-of-the-art Skat AI system Kermit when it is employed into its determinized search algorithm.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1905.10911v1-abstract-full').style.display = 'none'; document.getElementById('1905.10911v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 26 May, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2019.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">accepted to IEEE Conference on Games 2019 (CoG-2019)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1703.03868">arXiv:1703.03868</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1703.03868">pdf</a>, <a href="https://arxiv.org/format/1703.03868">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Front-to-End Bidirectional Heuristic Search with Near-Optimal Node Expansions
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Chen%2C+J">Jingwei Chen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Holte%2C+R+C">Robert C. Holte</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zilles%2C+S">Sandra Zilles</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1703.03868v2-abstract-short" style="display: inline;">
        It is well-known that any admissible unidirectional heuristic search algorithm must expand all states whose $f$-value is smaller than the optimal solution cost when using a consistent heuristic. Such states are called &#34;surely expanded&#34; (s.e.). A recent study characterized s.e. pairs of states for bidirectional search with consistent heuristics: if a pair of states is s.e. then at least one of the&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.03868v2-abstract-full').style.display = 'inline'; document.getElementById('1703.03868v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1703.03868v2-abstract-full" style="display: none;">
        It is well-known that any admissible unidirectional heuristic search algorithm must expand all states whose $f$-value is smaller than the optimal solution cost when using a consistent heuristic. Such states are called &#34;surely expanded&#34; (s.e.). A recent study characterized s.e. pairs of states for bidirectional search with consistent heuristics: if a pair of states is s.e. then at least one of the two states must be expanded. This paper derives a lower bound, VC, on the minimum number of expansions required to cover all s.e. pairs, and present a new admissible front-to-end bidirectional heuristic search algorithm, Near-Optimal Bidirectional Search (NBS), that is guaranteed to do no more than 2VC expansions. We further prove that no admissible front-to-end algorithm has a worst case better than 2VC. Experimental results show that NBS competes with or outperforms existing bidirectional search algorithms, and often outperforms A* as well.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1703.03868v2-abstract-full').style.display = 'none'; document.getElementById('1703.03868v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 May, 2017; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 March, 2017;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2017.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted to IJCAI 2017. Camera ready version with new timing results</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1406.0486">arXiv:1406.0486</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1406.0486">pdf</a>, <a href="https://arxiv.org/format/1406.0486">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Monte Carlo Tree Search with Heuristic Evaluations using Implicit Minimax Backups
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Lanctot%2C+M">Marc Lanctot</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Winands%2C+M+H+M">Mark H. M. Winands</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pepels%2C+T">Tom Pepels</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sturtevant%2C+N+R">Nathan R. Sturtevant</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1406.0486v4-abstract-short" style="display: inline;">
        Monte Carlo Tree Search (MCTS) has improved the performance of game engines in domains such as Go, Hex, and general game playing. MCTS has been shown to outperform classic alpha-beta search in games where good heuristic evaluations are difficult to obtain. In recent years, combining ideas from traditional minimax search in MCTS has been shown to be advantageous in some domains, such as Lines of Ac&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.0486v4-abstract-full').style.display = 'inline'; document.getElementById('1406.0486v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1406.0486v4-abstract-full" style="display: none;">
        Monte Carlo Tree Search (MCTS) has improved the performance of game engines in domains such as Go, Hex, and general game playing. MCTS has been shown to outperform classic alpha-beta search in games where good heuristic evaluations are difficult to obtain. In recent years, combining ideas from traditional minimax search in MCTS has been shown to be advantageous in some domains, such as Lines of Action, Amazons, and Breakthrough. In this paper, we propose a new way to use heuristic evaluations to guide the MCTS search by storing the two sources of information, estimated win rates and heuristic evaluations, separately. Rather than using the heuristic evaluations to replace the playouts, our technique backs them up implicitly during the MCTS simulations. These minimax values are then used to guide future simulations. We show that using implicit minimax backups leads to stronger play performance in Kalah, Breakthrough, and Lines of Action.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1406.0486v4-abstract-full').style.display = 'none'; document.getElementById('1406.0486v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2014; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 June, 2014;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2014.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">24 pages, 7 figures, 9 tables, expanded version of paper presented at IEEE Conference on Computational Intelligence and Games (CIG) 2014 conference</span>
    </p>
    

    

    
  </li>

</ol>


  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>