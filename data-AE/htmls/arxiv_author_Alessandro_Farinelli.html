<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<!-- new favicon config and versions by realfavicongenerator.net -->
<link rel="apple-touch-icon" sizes="180x180" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon-16x16.png">
<link rel="manifest" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/site.webmanifest">
<link rel="mask-icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/safari-pinned-tab.svg" color="#b31b1b">
<link rel="shortcut icon" href="https://static.arxiv.org/static/base/1.0.0a5/images/icons/favicon.ico">
<meta name="msapplication-TileColor" content="#b31b1b">
<meta name="msapplication-config" content="images/icons/browserconfig.xml">
<meta name="theme-color" content="#b31b1b">
<!-- end favicon config -->
<title>Search | arXiv e-print repository</title>
<script defer src="https://static.arxiv.org/static/base/1.0.0a5/fontawesome-free-5.11.2-web/js/all.js"></script>
<link rel="stylesheet" href="https://static.arxiv.org/static/base/1.0.0a5/css/arxivstyle.css" />
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    messageStyle: "none",
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true,
      ignoreClass: '.*',
      processClass: 'mathjax.*'
    },
    TeX: {
        extensions: ["AMSmath.js", "AMSsymbols.js", "noErrors.js"],
        noErrors: {
          inlineDelimiters: ["$","$"],
          multiLine: false,
          style: {
            "font-size": "normal",
            "border": ""
          }
        }
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>
<script src='//static.arxiv.org/MathJax-2.7.3/MathJax.js'></script>
<script src="https://static.arxiv.org/static/base/1.0.0a5/js/notification.js"></script>

    
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/bulma-tooltip.min.css" />
  <link rel="stylesheet" href="https://static.arxiv.org/static/search/0.5.6/css/search.css" />
  <script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>

  <script src="https://static.arxiv.org/static/search/0.5.6/js/fieldset.js"></script>
  <style>
  radio#cf-customfield_11400 {
    display: none;
  }
  </style>

  </head>
  <body>
  
  
  <header><a href="#main-container" class="is-sr-only">Skip to main content</a>
    
    <!-- contains Cornell logo and sponsor statement -->
<div class="attribution level is-marginless" role="banner">
  <div class="level-left">
    <a class="level-item" href="https://cornell.edu/"><img src="https://static.arxiv.org/static/base/1.0.0a5/images/cornell-reduced-white-SMALL.svg" alt="Cornell University" width="200" aria-label="logo" /></a>
  </div>
  <div class="level-right is-marginless"><p class="sponsors level-item is-marginless"><span id="support-ack-url">We gratefully acknowledge support from<br /> the Simons Foundation, <a href="https://info.arxiv.org/about/ourmembers.html">member institutions</a>, and all contributors. <a href="https://info.arxiv.org/about/donate.html">Donate</a></span></p></div>
</div>
<!-- contains arXiv identity and search bar -->
<div class="identity level is-marginless">
  <div class="level-left">
    <div class="level-item">
      <a class="arxiv" href="https://arxiv.org/" aria-label="arxiv-logo">
        <img src="https://static.arxiv.org/static/base/1.0.0a5/images/arxiv-logo-one-color-white.svg" aria-label="logo" alt="arxiv logo" width="85" style="width:85px;"/>
      </a>
    </div>
  </div>
  
  <div class="search-block level-right">
    <form class="level-item mini-search" method="GET" action="https://arxiv.org/search">
      <div class="field has-addons">
        <div class="control">
          <input class="input is-small" type="text" name="query" placeholder="Search..." aria-label="Search term or terms" />
          <p class="help"><a href="https://info.arxiv.org/help">Help</a> | <a href="https://arxiv.org/search/advanced">Advanced Search</a></p>
        </div>
        <div class="control">
          <div class="select is-small">
            <select name="searchtype" aria-label="Field to search">
              <option value="all" selected="selected">All fields</option>
              <option value="title">Title</option>
              <option value="author">Author</option>
              <option value="abstract">Abstract</option>
              <option value="comments">Comments</option>
              <option value="journal_ref">Journal reference</option>
              <option value="acm_class">ACM classification</option>
              <option value="msc_class">MSC classification</option>
              <option value="report_num">Report number</option>
              <option value="paper_id">arXiv identifier</option>
              <option value="doi">DOI</option>
              <option value="orcid">ORCID</option>
              <option value="author_id">arXiv author ID</option>
              <option value="help">Help pages</option>
              <option value="full_text">Full text</option>
            </select>
          </div>
        </div>
        <input type="hidden" name="source" value="header">
        <button class="button is-small is-cul-darker">Search</button>
      </div>
    </form>
  </div>
</div> <!-- closes identity -->

<div class="container">
    <div class="user-tools is-size-7 has-text-right has-text-weight-bold" role="navigation" aria-label="User menu">
      <a href="https://arxiv.org/login">Login</a>
    </div>
</div>
    
  </header>
  <main class="container" id="main-container">
    


    
  <div class="level is-marginless">
    <div class="level-left">
      <h1 class="title is-clearfix">
    
        Showing 1&ndash;50 of 53 results for author: <span class="mathjax">Alessandro Farinelli</span>
    
</h1>
    </div>
    <div class="level-right is-hidden-mobile">
      <!-- feedback for mobile is moved to footer -->
      <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
    </div>
  </div>
    <div class="content">
      
  <form method="GET" action="/search/"  aria-role="search">
    

    
    <div class="field has-addons-tablet">
      <div class="control is-expanded">
        <label for="query" class="hidden-label">Search term or terms</label>
        
          <input class="input is-medium" id="query" name="query" placeholder="Search term..." type="text" value="Alessandro Farinelli">
        
        
      </div>
      <div class="select control is-medium">
        <label class="is-hidden" for="searchtype">Field</label>
        <select class="is-medium" id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
      </div>
      <div class="control">
          <button class="button is-link is-medium">Search</button>
      </div>
    </div>
    <div class="field">
      <div class="control is-size-7">
        
        <label class="radio">
          <input checked id="abstracts-0" name="abstracts" type="radio" value="show"> Show abstracts
        </label>
        
        <label class="radio">
          <input id="abstracts-1" name="abstracts" type="radio" value="hide"> Hide abstracts
        </label>
        
      </div>
    </div>
    <div class="is-clearfix" style="height: 2.5em"> 
      <div class="is-pulled-right">
        
        <a href="/search/advanced?terms-0-term=Alessandro+Farinelli&amp;terms-0-field=author&amp;size=50&amp;order=-announced_date_first">Advanced Search</a>
        
      </div>
    </div>
    <input type="hidden" name="order" value="-announced_date_first">
    <input type="hidden" name="size" value="50">
  </form>

  

  
      
<div class="level breathe-horizontal">
  <div class="level-left">
    <form method="GET" action="/search/">
      <div style="display: none;">
        
          
            <select id="searchtype" name="searchtype"><option value="all">All fields</option><option value="title">Title</option><option selected value="author">Author(s)</option><option value="abstract">Abstract</option><option value="comments">Comments</option><option value="journal_ref">Journal reference</option><option value="acm_class">ACM classification</option><option value="msc_class">MSC classification</option><option value="report_num">Report number</option><option value="paper_id">arXiv identifier</option><option value="doi">DOI</option><option value="orcid">ORCID</option><option value="license">License (URI)</option><option value="author_id">arXiv author ID</option><option value="help">Help pages</option><option value="full_text">Full text</option></select>
          
        
          
            <input id="query" name="query" type="text" value="Alessandro Farinelli">
          
        
          
        
          
        
          
            <ul id="abstracts"><li><input checked id="abstracts-0" name="abstracts" type="radio" value="show"> <label for="abstracts-0">Show abstracts</label></li><li><input id="abstracts-1" name="abstracts" type="radio" value="hide"> <label for="abstracts-1">Hide abstracts</label></li></ul>
          
        
      </div>
      <div class="box field is-grouped is-grouped-multiline level-item">
        <div class="control">
          <span class="select is-small">
            <select id="size" name="size"><option value="25">25</option><option selected value="50">50</option><option value="100">100</option><option value="200">200</option></select>
          </span>
          <label for="size">results per page</label>.
        </div>
        <div class="control">
          <label for="order">Sort results by</label>
          <span class="select is-small">
            <select id="order" name="order"><option selected value="-announced_date_first">Announcement date (newest first)</option><option value="announced_date_first">Announcement date (oldest first)</option><option value="-submitted_date">Submission date (newest first)</option><option value="submitted_date">Submission date (oldest first)</option><option value="">Relevance</option></select>
          </span>
        </div>
        <div class="control">
          <button class="button is-small is-link">Go</button>
        </div>
      </div>
    </form>
  </div>
</div>
      


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
      
    </ul>
  </nav>
  



<ol class="breathe-horizontal" start="1"> 


  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2507.05405">arXiv:2507.05405</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2507.05405">pdf</a>, <a href="https://arxiv.org/ps/2507.05405">ps</a>, <a href="https://arxiv.org/format/2507.05405">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cicalese%2C+F">Ferdinando Cicalese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2507.05405v1-abstract-short" style="display: inline;">
        We present $\textbf{P}$robabilistically $\textbf{T}$ightened $\textbf{Li}$near $\textbf{R}$elaxation-based $\textbf{P}$erturbation $\textbf{A}$nalysis ($\texttt{PT-LiRPA}$), a novel framework that combines over-approximation techniques from LiRPA-based approaches with a sampling-based method to compute tight intermediate reachable sets. In detail, we show that with negligible computational overhea&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.05405v1-abstract-full').style.display = 'inline'; document.getElementById('2507.05405v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2507.05405v1-abstract-full" style="display: none;">
        We present $\textbf{P}$robabilistically $\textbf{T}$ightened $\textbf{Li}$near $\textbf{R}$elaxation-based $\textbf{P}$erturbation $\textbf{A}$nalysis ($\texttt{PT-LiRPA}$), a novel framework that combines over-approximation techniques from LiRPA-based approaches with a sampling-based method to compute tight intermediate reachable sets. In detail, we show that with negligible computational overhead, $\texttt{PT-LiRPA}$ exploiting the estimated reachable sets, significantly tightens the lower and upper linear bounds of a neural network&#39;s output, reducing the computational cost of formal verification tools while providing probabilistic guarantees on verification soundness. Extensive experiments on standard formal verification benchmarks, including the International Verification of Neural Networks Competition, show that our $\texttt{PT-LiRPA}$-based verifier improves robustness certificates by up to 3.31X and 2.26X compared to related work. Importantly, our probabilistic approach results in a valuable solution for challenging competition entries where state-of-the-art formal verification methods fail, allowing us to provide answers with high confidence (i.e., at least 99%).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2507.05405v1-abstract-full').style.display = 'none'; document.getElementById('2507.05405v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 July, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2506.08367">arXiv:2506.08367</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2506.08367">pdf</a>, <a href="https://arxiv.org/ps/2506.08367">ps</a>, <a href="https://arxiv.org/format/2506.08367">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Instrumentation and Methods for Astrophysics">astro-ph.IM</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Astrophysics of Galaxies">astro-ph.GA</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Solar and Stellar Astrophysics">astro-ph.SR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Observatory Science with eXTP
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhou%2C+P">Ping Zhou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mao%2C+J">Jirong Mao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+L">Liang Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Patruno%2C+A">Alessandro Patruno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bozzo%2C+E">Enrico Bozzo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xu%2C+Y">Yanjun Xu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Santangelo%2C+A">Andrea Santangelo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zane%2C+S">Silvia Zane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zhang%2C+S">Shuang-Nan Zhang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Feng%2C+H">Hua Feng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cavecchi%2C+Y">Yuri Cavecchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Marco%2C+B">Barbara De Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fan%2C+J">Junhui Fan</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Hou%2C+X">Xian Hou</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jiang%2C+P">Pengfei Jiang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Romano%2C+P">Patrizia Romano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sala%2C+G">Gloria Sala</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tao%2C+L">Lian Tao</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Veledina%2C+A">Alexandra Veledina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Vink%2C+J">Jacco Vink</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+S">Song Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+J">Junxian Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yidi Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weng%2C+S">Shanshan Weng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+Q">Qingwen Wu</a>
      , et al. (75 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2506.08367v1-abstract-short" style="display: inline;">
        Scheduled for launch in 2030, the enhanced X-ray Timing and Polarization (eXTP) telescope is a Chinese space-based mission aimed at studying extreme conditions and phenomena in astrophysics. eXTP will feature three main payloads: Spectroscopy Focusing Arrays (SFAs), Polarimetry Focusing Arrays (PFAs), and a Wide-field Camera (W2C). This white paper outlines observatory science, incorporating key s&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2506.08367v1-abstract-full').style.display = 'inline'; document.getElementById('2506.08367v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2506.08367v1-abstract-full" style="display: none;">
        Scheduled for launch in 2030, the enhanced X-ray Timing and Polarization (eXTP) telescope is a Chinese space-based mission aimed at studying extreme conditions and phenomena in astrophysics. eXTP will feature three main payloads: Spectroscopy Focusing Arrays (SFAs), Polarimetry Focusing Arrays (PFAs), and a Wide-field Camera (W2C). This white paper outlines observatory science, incorporating key scientific advances and instrumental changes since the publication of the previous white paper [1]. We will discuss perspectives of eXTP on the research domains of flare stars, supernova remnants, pulsar wind nebulae, cataclysmic variables, X-ray binaries, ultraluminous X-ray sources, AGN, and pulsar-based positioning and timekeeping.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2506.08367v1-abstract-full').style.display = 'none'; document.getElementById('2506.08367v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 June, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to the SCIENCE CHINA Physics, Mechanics &amp; Astronomy</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2505.05235">arXiv:2505.05235</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2505.05235">pdf</a>, <a href="https://arxiv.org/format/2505.05235">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mastroeni%2C+I">Isabella Mastroeni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2505.05235v1-abstract-short" style="display: inline;">
        Traditional methods for formal verification (FV) of deep neural networks (DNNs) are constrained by a binary encoding of safety properties, where a model is classified as either safe or unsafe (robust or not robust). This binary encoding fails to capture the nuanced safety levels within a model, often resulting in either overly restrictive or too permissive requirements. In this paper, we introduce&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.05235v1-abstract-full').style.display = 'inline'; document.getElementById('2505.05235v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2505.05235v1-abstract-full" style="display: none;">
        Traditional methods for formal verification (FV) of deep neural networks (DNNs) are constrained by a binary encoding of safety properties, where a model is classified as either safe or unsafe (robust or not robust). This binary encoding fails to capture the nuanced safety levels within a model, often resulting in either overly restrictive or too permissive requirements. In this paper, we introduce a novel problem formulation called Abstract DNN-Verification, which verifies a hierarchical structure of unsafe outputs, providing a more granular analysis of the safety aspect for a given DNN. Crucially, by leveraging abstract interpretation and reasoning about output reachable sets, our approach enables assessing multiple safety levels during the FV process, requiring the same (in the worst case) or even potentially less computational effort than the traditional binary verification approach. Specifically, we demonstrate how this formulation allows rank adversarial inputs according to their abstract safety level violation, offering a more detailed evaluation of the model&#39;s safety and robustness. Our contributions include a theoretical exploration of the relationship between our novel abstract safety formulation and existing approaches that employ abstract interpretation for robustness verification, complexity analysis of the novel problem introduced, and an empirical evaluation considering both a complex deep reinforcement learning task (based on Habitat 3.0) and standard DNN-Verification benchmarks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.05235v1-abstract-full').style.display = 'none'; document.getElementById('2505.05235v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 May, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2505.03668">arXiv:2505.03668</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2505.03668">pdf</a>, <a href="https://arxiv.org/format/2505.03668">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Symbolic Persistent Macro-Actions for POMDP Solving Over Time
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Veronese%2C+C">Celeste Veronese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2505.03668v1-abstract-short" style="display: inline;">
        This paper proposes an integration of temporal logical reasoning and Partially Observable Markov Decision Processes (POMDPs) to achieve interpretable decision-making under uncertainty with macro-actions. Our method leverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus (EC) to generate \emph{persistent} (i.e., constant) macro-actions, which guide Monte Carlo Tree Search (MCTS)&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.03668v1-abstract-full').style.display = 'inline'; document.getElementById('2505.03668v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2505.03668v1-abstract-full" style="display: none;">
        This paper proposes an integration of temporal logical reasoning and Partially Observable Markov Decision Processes (POMDPs) to achieve interpretable decision-making under uncertainty with macro-actions. Our method leverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus (EC) to generate \emph{persistent} (i.e., constant) macro-actions, which guide Monte Carlo Tree Search (MCTS)-based POMDP solvers over a time horizon, significantly reducing inference time while ensuring robust performance. Such macro-actions are learnt via Inductive Logic Programming (ILP) from a few traces of execution (belief-action pairs), thus eliminating the need for manually designed heuristics and requiring only the specification of the POMDP transition model. In the Pocman and Rocksample benchmark scenarios, our learned macro-actions demonstrate increased expressiveness and generality when compared to time-independent heuristics, indeed offering substantial computational efficiency improvements.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2505.03668v1-abstract-full').style.display = 'none'; document.getElementById('2505.03668v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 May, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at 9th Conference on Neurosymbolic Learning and Reasoning</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.21643">arXiv:2504.21643</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.21643">pdf</a>, <a href="https://arxiv.org/format/2504.21643">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trotti%2C+F">Francesco Trotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.21643v1-abstract-short" style="display: inline;">
        Achieving safe autonomous navigation systems is critical for deploying robots in dynamic and uncertain real-world environments. In this paper, we propose a hierarchical control framework leveraging neural network verification techniques to design control barrier functions (CBFs) and policy correction mechanisms that ensure safe reinforcement learning navigation policies. Our approach relies on pro&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.21643v1-abstract-full').style.display = 'inline'; document.getElementById('2504.21643v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.21643v1-abstract-full" style="display: none;">
        Achieving safe autonomous navigation systems is critical for deploying robots in dynamic and uncertain real-world environments. In this paper, we propose a hierarchical control framework leveraging neural network verification techniques to design control barrier functions (CBFs) and policy correction mechanisms that ensure safe reinforcement learning navigation policies. Our approach relies on probabilistic enumeration to identify unsafe regions of operation, which are then used to construct a safe CBF-based control layer applicable to arbitrary policies. We validate our framework both in simulation and on a real robot, using a standard mobile robot benchmark and a highly dynamic aquatic environmental monitoring task. These experiments demonstrate the ability of the proposed solution to correct unsafe actions while preserving efficient navigation behavior. Our results show the promise of developing hierarchical verification-based systems to enable safe and robust navigation behaviors in complex scenarios.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.21643v1-abstract-full').style.display = 'none'; document.getElementById('2504.21643v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2504.18253">arXiv:2504.18253</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2504.18253">pdf</a>, <a href="https://arxiv.org/ps/2504.18253">ps</a>, <a href="https://arxiv.org/format/2504.18253">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Depth-Constrained ASV Navigation with Deep RL and Limited Sensing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zhalehmehrabi%2C+A">Amirhossein Zhalehmehrabi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Santo%2C+F+D">Francesco Dal Santo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Trotti%2C+F">Francesco Trotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2504.18253v2-abstract-short" style="display: inline;">
        Autonomous Surface Vehicles (ASVs) play a crucial role in maritime operations, yet their navigation in shallow-water environments remains challenging due to dynamic disturbances and depth constraints. Traditional navigation strategies struggle with limited sensor information, making safe and efficient operation difficult. In this paper, we propose a reinforcement learning (RL) framework for ASV na&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18253v2-abstract-full').style.display = 'inline'; document.getElementById('2504.18253v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2504.18253v2-abstract-full" style="display: none;">
        Autonomous Surface Vehicles (ASVs) play a crucial role in maritime operations, yet their navigation in shallow-water environments remains challenging due to dynamic disturbances and depth constraints. Traditional navigation strategies struggle with limited sensor information, making safe and efficient operation difficult. In this paper, we propose a reinforcement learning (RL) framework for ASV navigation under depth constraints, where the vehicle must reach a target while avoiding unsafe areas with only a single depth measurement per timestep from a downward-facing Single Beam Echosounder (SBES). To enhance environmental awareness, we integrate Gaussian Process (GP) regression into the RL framework, enabling the agent to progressively estimate a bathymetric depth map from sparse sonar readings. This approach improves decision-making by providing a richer representation of the environment. Furthermore, we demonstrate effective sim-to-real transfer, ensuring that trained policies generalize well to real-world aquatic conditions. Experimental results validate our method&#39;s capability to improve ASV navigation performance while maintaining safety in challenging shallow-water environments.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2504.18253v2-abstract-full').style.display = 'none'; document.getElementById('2504.18253v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 June, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 25 April, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 8 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.17658">arXiv:2503.17658</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.17658">pdf</a>, <a href="https://arxiv.org/format/2503.17658">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">stat.ML</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Sentinel: Multi-Patch Transformer with Temporal and Channel Attention for Time Series Forecasting
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Villaboni%2C+D">Davide Villaboni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Danesi%2C+I+L">Ivan Luciano Danesi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.17658v1-abstract-short" style="display: inline;">
        Transformer-based time series forecasting has recently gained strong interest due to the ability of transformers to model sequential data. Most of the state-of-the-art architectures exploit either temporal or inter-channel dependencies, limiting their effectiveness in multivariate time-series forecasting where both types of dependencies are crucial. We propose Sentinel, a full transformer-based ar&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.17658v1-abstract-full').style.display = 'inline'; document.getElementById('2503.17658v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.17658v1-abstract-full" style="display: none;">
        Transformer-based time series forecasting has recently gained strong interest due to the ability of transformers to model sequential data. Most of the state-of-the-art architectures exploit either temporal or inter-channel dependencies, limiting their effectiveness in multivariate time-series forecasting where both types of dependencies are crucial. We propose Sentinel, a full transformer-based architecture composed of an encoder able to extract contextual information from the channel dimension, and a decoder designed to capture causal relations and dependencies across the temporal dimension. Additionally, we introduce a multi-patch attention mechanism, which leverages the patching process to structure the input sequence in a way that can be naturally integrated into the transformer architecture, replacing the multi-head splitting process. Extensive experiments on standard benchmarks demonstrate that Sentinel, because of its ability to &#34;monitor&#34; both the temporal and the inter-channel dimension, achieves better or comparable performance with respect to state-of-the-art approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.17658v1-abstract-full').style.display = 'none'; document.getElementById('2503.17658v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 March, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2503.03885">arXiv:2503.03885</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2503.03885">pdf</a>, <a href="https://arxiv.org/ps/2503.03885">ps</a>, <a href="https://arxiv.org/format/2503.03885">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Seldonian Reinforcement Learning for Ad Hoc Teamwork
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Zorzi%2C+E">Edoardo Zorzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bakopoulos%2C+L">Leonidas Bakopoulos</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Chalkiadakis%2C+G">Georgios Chalkiadakis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2503.03885v2-abstract-short" style="display: inline;">
        Most offline RL algorithms return optimal policies but do not provide statistical guarantees on desirable behaviors. This could generate reliability issues in safety-critical applications, such as in some multiagent domains where agents, and possibly humans, need to interact to reach their goals without harming each other. In this work, we propose a novel offline RL approach, inspired by Seldonian&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.03885v2-abstract-full').style.display = 'inline'; document.getElementById('2503.03885v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2503.03885v2-abstract-full" style="display: none;">
        Most offline RL algorithms return optimal policies but do not provide statistical guarantees on desirable behaviors. This could generate reliability issues in safety-critical applications, such as in some multiagent domains where agents, and possibly humans, need to interact to reach their goals without harming each other. In this work, we propose a novel offline RL approach, inspired by Seldonian optimization, which returns policies with good performance and statistically guaranteed properties with respect to predefined desirable behaviors. In particular, our focus is on Ad Hoc Teamwork settings, where agents must collaborate with new teammates without prior coordination. Our method requires only a pre-collected dataset, a set of candidate policies for our agent, and a specification about the possible policies followed by the other players -- it does not require further interactions, training, or assumptions on the type and architecture of the policies. We test our algorithm in Ad Hoc Teamwork problems and show that it consistently finds reliable policies while improving sample efficiency with respect to standard ML baselines.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2503.03885v2-abstract-full').style.display = 'none'; document.getElementById('2503.03885v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 August, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 5 March, 2025;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2025.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Presented at the 2nd Reinforcement Learning Conference (RLC2025), Edmonton, Canada. To be published in the Proceedings of the Reinforcement Learning Journal 2025</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.09649">arXiv:2501.09649</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.09649">pdf</a>, <a href="https://arxiv.org/format/2501.09649">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bonanni%2C+L">Lorenzo Bonanni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.09649v1-abstract-short" style="display: inline;">
        Online motion planning is a challenging problem for intelligent robots moving in dense environments with dynamic obstacles, e.g., crowds. In this work, we propose a novel approach for optimal and safe online motion planning with minimal information about dynamic obstacles. Specifically, our approach requires only the current position of the obstacles and their maximum speed, but it does not need a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.09649v1-abstract-full').style.display = 'inline'; document.getElementById('2501.09649v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.09649v1-abstract-full" style="display: none;">
        Online motion planning is a challenging problem for intelligent robots moving in dense environments with dynamic obstacles, e.g., crowds. In this work, we propose a novel approach for optimal and safe online motion planning with minimal information about dynamic obstacles. Specifically, our approach requires only the current position of the obstacles and their maximum speed, but it does not need any information about their exact trajectories or dynamic model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for online optimal planning via model simulations, with Velocity Obstacles (VO), for obstacle avoidance. We perform experiments in a cluttered simulated environment with walls, and up to 40 dynamic obstacles moving with random velocities and directions. With an ablation study, we show the key contribution of VO in scaling up the efficiency of MCTS, selecting the safest and most rewarding actions in the tree of simulations. Moreover, we show the superiority of our methodology with respect to state-of-the-art planners, including Non-linear Model Predictive Control (NMPC), in terms of improved collision rate, computational and task performance.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.09649v1-abstract-full').style.display = 'none'; document.getElementById('2501.09649v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2501.07445">arXiv:2501.07445</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2501.07445">pdf</a>, <a href="https://arxiv.org/format/2501.07445">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Online inductive learning from answer sets for efficient reinforcement learning exploration
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Veronese%2C+C">Celeste Veronese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2501.07445v1-abstract-short" style="display: inline;">
        This paper presents a novel approach combining inductive logic programming with reinforcement learning to improve training performance and explainability. We exploit inductive learning of answer set programs from noisy examples to learn a set of logical rules representing an explainable approximation of the agent policy at each batch of experience. We then perform answer set reasoning on the learn&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.07445v1-abstract-full').style.display = 'inline'; document.getElementById('2501.07445v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2501.07445v1-abstract-full" style="display: none;">
        This paper presents a novel approach combining inductive logic programming with reinforcement learning to improve training performance and explainability. We exploit inductive learning of answer set programs from noisy examples to learn a set of logical rules representing an explainable approximation of the agent policy at each batch of experience. We then perform answer set reasoning on the learned rules to guide the exploration of the learning agent at the next batch, without requiring inefficient reward shaping and preserving optimality with soft bias. The entire procedure is conducted during the online execution of the reinforcement learning algorithm. We preliminarily validate the efficacy of our approach by integrating it into the Q-learning algorithm for the Pac-Man scenario in two maps of increasing complexity. Our methodology produces a significant boost in the discounted return achieved by the agent, even in the first batches of training. Moreover, inductive learning does not compromise the computational time required by Q-learning and learned rules quickly converge to an explanation of the agent policy.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2501.07445v1-abstract-full').style.display = 'none'; document.getElementById('2501.07445v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 January, 2025; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2025.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2412.01250">arXiv:2412.01250</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2412.01250">pdf</a>, <a href="https://arxiv.org/format/2412.01250">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Taioli%2C+F">Francesco Taioli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zorzi%2C+E">Edoardo Zorzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Franchi%2C+G">Gianni Franchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2412.01250v3-abstract-short" style="display: inline;">
        Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01250v3-abstract-full').style.display = 'inline'; document.getElementById('2412.01250v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2412.01250v3-abstract-full" style="display: none;">
        Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object Navigation (CoIN), a new task setting where the agent actively resolve uncertainties about the target instance during navigation in natural, template-free, open-ended dialogues with human. We propose a novel training-free method, Agent-user Interaction with UncerTainty Awareness (AIUTA), which operates independently from the navigation policy, and focuses on the human-agent interaction reasoning with Vision-Language Models (VLMs) and Large Language Models (LLMs). First, upon object detection, a Self-Questioner model initiates a self-dialogue within the agent to obtain a complete and accurate observation description with a novel uncertainty estimation technique. Then, an Interaction Trigger module determines whether to ask a question to the human, continue or halt navigation, minimizing user input. For evaluation, we introduce CoIN-Bench, with a curated dataset designed for challenging multi-instance scenarios. CoIN-Bench supports both online evaluation with humans and reproducible experiments with simulated user-agent interactions. On CoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing language-driven instance navigation methods struggle in complex multi-instance scenes. Code and benchmark will be available upon acceptance at https://intelligolabs.github.io/CoIN/
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2412.01250v3-abstract-full').style.display = 'none'; document.getElementById('2412.01250v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 18 March, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 December, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">https://intelligolabs.github.io/CoIN/</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2409.07161">arXiv:2409.07161</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2409.07161">pdf</a>, <a href="https://arxiv.org/format/2409.07161">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Solar and Stellar Astrophysics">astro-ph.SR</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The IXPE View of Neutron Star Low-Mass X-ray Binaries
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Ursini%2C+F">Francesco Ursini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Capitanio%2C+F">Fiamma Capitanio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bobrikova%2C+A">Anna Bobrikova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cocchi%2C+M">Massimo Cocchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fabiani%2C+S">Sergio Fabiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Saade%2C+M+L">Mary Lynne Saade</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2409.07161v1-abstract-short" style="display: inline;">
        Low-mass X-ray binaries hosting weakly magnetized neutron stars (NS-LMXBs) are among the brightest sources in the X-ray sky. Since 2021, the Imaging X-ray Polarimetry Explorer (IXPE) has provided new measurements of the X-ray polarization of these sources. IXPE observations have revealed that most NS-LMXBs are significantly polarized in the X-rays, providing unprecedented insight into the geometry&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.07161v1-abstract-full').style.display = 'inline'; document.getElementById('2409.07161v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2409.07161v1-abstract-full" style="display: none;">
        Low-mass X-ray binaries hosting weakly magnetized neutron stars (NS-LMXBs) are among the brightest sources in the X-ray sky. Since 2021, the Imaging X-ray Polarimetry Explorer (IXPE) has provided new measurements of the X-ray polarization of these sources. IXPE observations have revealed that most NS-LMXBs are significantly polarized in the X-rays, providing unprecedented insight into the geometry of their accretion flow. In this review paper, we summarize the first results obtained by IXPE on NS-LMXBs, the emerging trends within each class of sources (atoll/Z), and possible physical interpretations.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2409.07161v1-abstract-full').style.display = 'none'; document.getElementById('2409.07161v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 11 September, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 3 figures, invited review for the Special Issue X-ray Polarization: A New Era Begins</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2407.07482">arXiv:2407.07482</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2407.07482">pdf</a>, <a href="https://arxiv.org/format/2407.07482">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Leofante%2C+F">Francesco Leofante</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cicalese%2C+F">Ferdinando Cicalese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2407.07482v1-abstract-short" style="display: inline;">
        We study the problem of assessing the robustness of counterfactual explanations for deep learning models. We focus on $\textit{plausible model shifts}$ altering model parameters and propose a novel framework to reason about the robustness property in this setting. To motivate our solution, we begin by showing for the first time that computing the robustness of counterfactuals with respect to plaus&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.07482v1-abstract-full').style.display = 'inline'; document.getElementById('2407.07482v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2407.07482v1-abstract-full" style="display: none;">
        We study the problem of assessing the robustness of counterfactual explanations for deep learning models. We focus on $\textit{plausible model shifts}$ altering model parameters and propose a novel framework to reason about the robustness property in this setting. To motivate our solution, we begin by showing for the first time that computing the robustness of counterfactuals with respect to plausible model shifts is NP-complete. As this (practically) rules out the existence of scalable algorithms for exactly computing robustness, we propose a novel probabilistic approach which is able to provide tight estimates of robustness with strong guarantees while preserving scalability. Remarkably, and differently from existing solutions targeting plausible model shifts, our approach does not impose requirements on the network to be analyzed, thus enabling robustness analysis on a wider range of architectures. Experiments on four binary classification datasets indicate that our method improves the state of the art in generating robust explanations, outperforming existing methods on a range of metrics.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2407.07482v1-abstract-full').style.display = 'none'; document.getElementById('2407.07482v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 July, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 27th European Conference on Artificial Intelligence (ECAI 2024). Marzari and Leofante contributed equally to the paper</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2406.05080">arXiv:2406.05080</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2406.05080">pdf</a>, <a href="https://arxiv.org/format/2406.05080">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        I2EDL: Interactive Instruction Error Detection and Localization
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Taioli%2C+F">Francesco Taioli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rosa%2C+S">Stefano Rosa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natale%2C+L">Lorenzo Natale</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Bue%2C+A">Alessio Del Bue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2406.05080v2-abstract-short" style="display: inline;">
        In the Vision-and-Language Navigation in Continuous Environments (VLN-CE) task, the human user guides an autonomous agent to reach a target goal via a series of low-level actions following a textual instruction in natural language. However, most existing methods do not address the likely case where users may make mistakes when providing such instruction (e.g. &#34;turn left&#34; instead of &#34;turn right&#34;).&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.05080v2-abstract-full').style.display = 'inline'; document.getElementById('2406.05080v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2406.05080v2-abstract-full" style="display: none;">
        In the Vision-and-Language Navigation in Continuous Environments (VLN-CE) task, the human user guides an autonomous agent to reach a target goal via a series of low-level actions following a textual instruction in natural language. However, most existing methods do not address the likely case where users may make mistakes when providing such instruction (e.g. &#34;turn left&#34; instead of &#34;turn right&#34;). In this work, we address a novel task of Interactive VLN in Continuous Environments (IVLN-CE), which allows the agent to interact with the user during the VLN-CE navigation to verify any doubts regarding the instruction errors. We propose an Interactive Instruction Error Detector and Localizer (I2EDL) that triggers the user-agent interaction upon the detection of instruction errors during the navigation. We leverage a pre-trained module to detect instruction errors and pinpoint them in the instruction by cross-referencing the textual input and past observations. In such way, the agent is able to query the user for a timely correction, without demanding the user&#39;s cognitive load, as we locate the probable errors to a precise part of the instruction. We evaluate the proposed I2EDL on a dataset of instructions containing errors, and further devise a novel metric, the Success weighted by Interaction Number (SIN), to reflect both the navigation performance and the interaction effectiveness. We show how the proposed method can ask focused requests for corrections to the user, which in turn increases the navigation success, while minimizing the interactions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2406.05080v2-abstract-full').style.display = 'none'; document.getElementById('2406.05080v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 June, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 7 June, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at IEEE RO-MAN 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2405.20534">arXiv:2405.20534</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2405.20534">pdf</a>, <a href="https://arxiv.org/format/2405.20534">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Aquatic Navigation: A Challenging Benchmark for Deep Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Camponogara%2C+D">Davide Camponogara</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2405.20534v1-abstract-short" style="display: inline;">
        An exciting and promising frontier for Deep Reinforcement Learning (DRL) is its application to real-world robotic systems. While modern DRL approaches achieved remarkable successes in many robotic scenarios (including mobile robotics, surgical assistance, and autonomous driving) unpredictable and non-stationary environments can pose critical challenges to such methods. These features can significa&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.20534v1-abstract-full').style.display = 'inline'; document.getElementById('2405.20534v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2405.20534v1-abstract-full" style="display: none;">
        An exciting and promising frontier for Deep Reinforcement Learning (DRL) is its application to real-world robotic systems. While modern DRL approaches achieved remarkable successes in many robotic scenarios (including mobile robotics, surgical assistance, and autonomous driving) unpredictable and non-stationary environments can pose critical challenges to such methods. These features can significantly undermine fundamental requirements for a successful training process, such as the Markovian properties of the transition model. To address this challenge, we propose a new benchmarking environment for aquatic navigation using recent advances in the integration between game engines and DRL. In more detail, we show that our benchmarking environment is problematic even for state-of-the-art DRL approaches that may struggle to generate reliable policies in terms of generalization power and safety. Specifically, we focus on PPO, one of the most widely accepted algorithms, and we propose advanced training techniques (such as curriculum learning and learnable hyperparameters). Our extensive empirical evaluation shows that a well-designed combination of these ingredients can achieve promising results. Our simulation environment and training baselines are freely available to facilitate further research on this open problem and encourage collaboration in the field.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2405.20534v1-abstract-full').style.display = 'none'; document.getElementById('2405.20534v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 May, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2403.10700">arXiv:2403.10700</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2403.10700">pdf</a>, <a href="https://arxiv.org/format/2403.10700">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computation and Language">cs.CL</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Taioli%2C+F">Francesco Taioli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rosa%2C+S">Stefano Rosa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Natale%2C+L">Lorenzo Natale</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Bue%2C+A">Alessio Del Bue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2403.10700v2-abstract-short" style="display: inline;">
        Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of the most intuitive yet challenging embodied AI tasks. Agents are tasked to navigate towards a target goal by executing a set of low-level actions, following a series of natural language instructions. All VLN-CE methods in the literature assume that language instructions are exact. However, in practice, instructions given&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.10700v2-abstract-full').style.display = 'inline'; document.getElementById('2403.10700v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2403.10700v2-abstract-full" style="display: none;">
        Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of the most intuitive yet challenging embodied AI tasks. Agents are tasked to navigate towards a target goal by executing a set of low-level actions, following a series of natural language instructions. All VLN-CE methods in the literature assume that language instructions are exact. However, in practice, instructions given by humans can contain errors when describing a spatial environment due to inaccurate memory or confusion. Current VLN-CE benchmarks do not address this scenario, making the state-of-the-art methods in VLN-CE fragile in the presence of erroneous instructions from human users. For the first time, we propose a novel benchmark dataset that introduces various types of instruction errors considering potential human causes. This benchmark provides valuable insight into the robustness of VLN systems in continuous environments. We observe a noticeable performance drop (up to -25%) in Success Rate when evaluating the state-of-the-art VLN-CE methods on our benchmark. Moreover, we formally define the task of Instruction Error Detection and Localization, and establish an evaluation protocol on top of our benchmark dataset. We also propose an effective method, based on a cross-modal transformer architecture, that achieves the best performance in error detection and localization, compared to baselines. Surprisingly, our proposed method has revealed errors in the validation set of the two commonly used datasets for VLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in other tasks. Code and dataset available at https://intelligolabs.github.io/R2RIE-CE
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.10700v2-abstract-full').style.display = 'none'; document.getElementById('2403.10700v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 January, 2025; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 15 March, 2024;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">3 figures, 8 pages. Accepted at IROS&#39;24</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2403.05399">arXiv:2403.05399</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2403.05399">pdf</a>, <a href="https://arxiv.org/format/2403.05399">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Planning and Inverse Kinematics of Hyper-Redundant Manipulators with VO-FABRIK
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Morasso%2C+C">Cristian Morasso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Divet%2C+Y">Yann Divet</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sessa%2C+S">Salvatore Sessa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2403.05399v1-abstract-short" style="display: inline;">
        Hyper-redundant Robotic Manipulators (HRMs) offer great dexterity and flexibility of operation, but solving Inverse Kinematics (IK) is challenging. In this work, we introduce VO-FABRIK, an algorithm combining Forward and Backward Reaching Inverse Kinematics (FABRIK) for repeatable deterministic IK computation, and an approach inspired from velocity obstacles to perform path planning under collisio&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.05399v1-abstract-full').style.display = 'inline'; document.getElementById('2403.05399v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2403.05399v1-abstract-full" style="display: none;">
        Hyper-redundant Robotic Manipulators (HRMs) offer great dexterity and flexibility of operation, but solving Inverse Kinematics (IK) is challenging. In this work, we introduce VO-FABRIK, an algorithm combining Forward and Backward Reaching Inverse Kinematics (FABRIK) for repeatable deterministic IK computation, and an approach inspired from velocity obstacles to perform path planning under collision and joint limits constraints. We show preliminary results on an industrial HRM with 19 actuated joints. Our algorithm achieves good performance where a state-of-the-art IK solver fails.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2403.05399v1-abstract-full').style.display = 'none'; document.getElementById('2403.05399v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 8 March, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2024.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">In publication in Springer Proceedings for the European Robotics Forum 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.19265">arXiv:2402.19265</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.19265">pdf</a>, <a href="https://arxiv.org/format/2402.19265">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1613/jair.1.15826">10.1613/jair.1.15826 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.19265v1-abstract-short" style="display: inline;">
        Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planni&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.19265v1-abstract-full').style.display = 'inline'; document.getElementById('2402.19265v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.19265v1-abstract-full" style="display: none;">
        Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristics. We evaluate thoroughly our methodology on two notoriously challenging POMDP problems, involving large action spaces and long planning horizons, namely, rocksample and pocman. Considering different state-of-the-art online POMDP solvers, including POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed in Answer Set Programming (ASP) yield performance superior to neural networks and similar to optimal handcrafted task-specific heuristics within lower computational time. Moreover, they well generalize to more challenging scenarios not experienced in the training phase (e.g., increasing rocks and grid size in rocksample, incrementing the size of the map and the aggressivity of ghosts in pocman).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.19265v1-abstract-full').style.display = 'none'; document.getElementById('2402.19265v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 February, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        Journal of Artificial Intelligence Research, volume 79 (2024), pp. 725-776
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2402.05284">arXiv:2402.05284</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2402.05284">pdf</a>, <a href="https://arxiv.org/format/2402.05284">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Analyzing Adversarial Inputs in Deep Reinforcement Learning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amir%2C+G">Guy Amir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Katz%2C+G">Guy Katz</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2402.05284v1-abstract-short" style="display: inline;">
        In recent years, Deep Reinforcement Learning (DRL) has become a popular paradigm in machine learning due to its successful applications to real-world and complex systems. However, even the state-of-the-art DRL models have been shown to suffer from reliability concerns -- for example, their susceptibility to adversarial inputs, i.e., small and abundant input perturbations that can fool the models i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.05284v1-abstract-full').style.display = 'inline'; document.getElementById('2402.05284v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2402.05284v1-abstract-full" style="display: none;">
        In recent years, Deep Reinforcement Learning (DRL) has become a popular paradigm in machine learning due to its successful applications to real-world and complex systems. However, even the state-of-the-art DRL models have been shown to suffer from reliability concerns -- for example, their susceptibility to adversarial inputs, i.e., small and abundant input perturbations that can fool the models into making unpredictable and potentially dangerous decisions. This drawback limits the deployment of DRL systems in safety-critical contexts, where even a small error cannot be tolerated. In this work, we present a comprehensive analysis of the characterization of adversarial inputs, through the lens of formal verification. Specifically, we introduce a novel metric, the Adversarial Rate, to classify models based on their susceptibility to such perturbations, and present a set of tools and algorithms for its computation. Our analysis empirically demonstrates how adversarial inputs can affect the safety of a given DRL system with respect to such perturbations. Moreover, we analyze the behavior of these configurations to suggest several useful practices and guidelines to help mitigate the vulnerability of trained DRL networks.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2402.05284v1-abstract-full').style.display = 'none'; document.getElementById('2402.05284v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 7 February, 2024; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2024.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2312.05890">arXiv:2312.05890</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2312.05890">pdf</a>, <a href="https://arxiv.org/format/2312.05890">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Scaling #DNN-Verification Tools with Efficient Bound Propagation and Parallel Computing
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Roncolato%2C+G">Gabriele Roncolato</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2312.05890v1-abstract-short" style="display: inline;">
        Deep Neural Networks (DNNs) are powerful tools that have shown extraordinary results in many scenarios, ranging from pattern recognition to complex robotic problems. However, their intricate designs and lack of transparency raise safety concerns when applied in real-world applications. In this context, Formal Verification (FV) of DNNs has emerged as a valuable solution to provide provable guarante&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.05890v1-abstract-full').style.display = 'inline'; document.getElementById('2312.05890v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2312.05890v1-abstract-full" style="display: none;">
        Deep Neural Networks (DNNs) are powerful tools that have shown extraordinary results in many scenarios, ranging from pattern recognition to complex robotic problems. However, their intricate designs and lack of transparency raise safety concerns when applied in real-world applications. In this context, Formal Verification (FV) of DNNs has emerged as a valuable solution to provide provable guarantees on the safety aspect. Nonetheless, the binary answer (i.e., safe or unsafe) could be not informative enough for direct safety interventions such as safety model ranking or selection. To address this limitation, the FV problem has recently been extended to the counting version, called #DNN-Verification, for the computation of the size of the unsafe regions in a given safety property&#39;s domain. Still, due to the complexity of the problem, existing solutions struggle to scale on real-world robotic scenarios, where the DNN can be large and complex. To address this limitation, inspired by advances in FV, in this work, we propose a novel strategy based on reachability analysis combined with Symbolic Linear Relaxation and parallel computing to enhance the efficiency of existing exact and approximate FV for DNN counters. The empirical evaluation on standard FV benchmarks and realistic robotic scenarios shows a remarkable improvement in scalability and efficiency, enabling the use of such techniques even for complex robotic applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2312.05890v1-abstract-full').style.display = 'none'; document.getElementById('2312.05890v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 December, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at AIRO 2023 the 10th Italian Workshop on Artificial Intelligence and Robotics co-located with the 22nd International Conference of the Italian Association for Artificial Intelligence (AI*IA 2023), Rome, Italy</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.06359">arXiv:2311.06359</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.06359">pdf</a>, <a href="https://arxiv.org/format/2311.06359">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3847/2041-8213/ad132d">10.3847/2041-8213/ad132d <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Highly Significant Detection of X-Ray Polarization from the Brightest Accreting Neutron Star Sco X-1
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bachetti%2C+M">Matteo Bachetti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Motta%2C+S+E">Sara E. Motta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Papitto%2C+A">Alessandro Papitto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pilia%2C+M">Maura Pilia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+F">Fei Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+S">Stefano Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bobrikova%2C+A">Anna Bobrikova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Costa%2C+E">Enrico Costa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Deng%2C+W">Wei Deng</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ge%2C+M">Mingyu Ge</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Illiano%2C+G">Giulia Illiano</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Jia%2C+S">Shu-Mei Jia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Krawczynski%2C+H">Henric Krawczynski</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lai%2C+E+V">Eleonora V. Lai</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+K">Kuan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mastroserio%2C+G">Guglielmo Mastroserio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muleri%2C+F">Fabio Muleri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soffitta%2C+P">Paolo Soffitta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Veledina%2C+A">Alexandra Veledina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ambrosino%2C+F">Filippo Ambrosino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Santo%2C+M">Melania Del Santo</a>
      , et al. (94 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.06359v3-abstract-short" style="display: inline;">
        The Imaging X-ray Polarimetry Explorer (IXPE) measured with high significance the X-ray polarization of the brightest Z-source Scorpius X-1, resulting in the nominal 2-8 keV energy band in a polarization degree of 1.0(0.2)% and a polarization angle of 8(6) at 90% of confidence level. This observation was strictly simultaneous with observations performed by NICER, NuSTAR, and Insight-HXMT, which a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.06359v3-abstract-full').style.display = 'inline'; document.getElementById('2311.06359v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.06359v3-abstract-full" style="display: none;">
        The Imaging X-ray Polarimetry Explorer (IXPE) measured with high significance the X-ray polarization of the brightest Z-source Scorpius X-1, resulting in the nominal 2-8 keV energy band in a polarization degree of 1.0(0.2)% and a polarization angle of 8(6) at 90% of confidence level. This observation was strictly simultaneous with observations performed by NICER, NuSTAR, and Insight-HXMT, which allowed for a precise characterization of its broad-band spectrum from soft to hard X-rays. The source has been observed mainly in its soft state, with short periods of flaring. We also observed low-frequency quasi-periodic oscillations. From a spectro-polarimetric analysis, we associate a polarization to the accretion disk at &lt;3.2% at 90% of confidence level, compatible with expectations for an electron-scattering dominated optically thick atmosphere at the Sco X-1 inclination of 44; for the higher-energy Comptonized component, we obtain a polarization of 1.3(0.4)%, in agreement with expectations for a slab of Thomson optical depth of ~7 and an electron temperature of ~3 keV. A polarization rotation with respect to previous observations by OSO-8 and PolarLight, and also with respect to the radio-jet position angle, is observed. This result may indicate a variation of the polarization with the source state that can be related to relativistic precession or to a change in the corona geometry with the accretion flow.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.06359v3-abstract-full').style.display = 'none'; document.getElementById('2311.06359v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 24 January, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 November, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ApJL 960 L11 (2024)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.04632">arXiv:2311.04632</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.04632">pdf</a>, <a href="https://arxiv.org/format/2311.04632">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3847/2041-8213/ad1832">10.3847/2041-8213/ad1832 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        X-Ray Polarized View on the Accretion Geometry in the X-Ray Binary Circinus X-1
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bobrikova%2C+A">Anna Bobrikova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kravtsov%2C+V">Vadim Kravtsov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muleri%2C+F">Fabio Muleri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pilia%2C+M">Maura Pilia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Veledina%2C+A">Alexandra Veledina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fender%2C+R">Rob Fender</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kaaret%2C+P">Philip Kaaret</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kim%2C+D+E">Dawoon E. Kim</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marinucci%2C+A">Andrea Marinucci</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marshall%2C+H+L">Herman L. Marshall</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Papitto%2C+A">Alessandro Papitto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tennant%2C+A+F">Allyn F. Tennant</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Tsygankov%2C+S+S">Sergey S. Tsygankov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weisskopf%2C+M+C">Martin C. Weisskopf</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+K">Kinwah Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zane%2C+S">Silvia Zane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ambrosino%2C+F">Filippo Ambrosino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agudo%2C+I">Ivn Agudo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Antonelli%2C+L+A">Lucio A. Antonelli</a>
      , et al. (79 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.04632v2-abstract-short" style="display: inline;">
        Cir X-1 is a neutron star X-ray binary characterized by strong variations in flux during its eccentric $\sim$16.6 days orbit. There are also strong variations in the spectral state, and historically it has shown both atoll and Z state properties. We observed the source with the Imaging X-ray Polarimetry Explorer during two orbital segments, 6 days apart, for a total of 263~ks. We find an X-ray pol&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.04632v2-abstract-full').style.display = 'inline'; document.getElementById('2311.04632v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.04632v2-abstract-full" style="display: none;">
        Cir X-1 is a neutron star X-ray binary characterized by strong variations in flux during its eccentric $\sim$16.6 days orbit. There are also strong variations in the spectral state, and historically it has shown both atoll and Z state properties. We observed the source with the Imaging X-ray Polarimetry Explorer during two orbital segments, 6 days apart, for a total of 263~ks. We find an X-ray polarization degree in these segments of $1.6\%\pm0.3\%$ and $1.4\%\pm0.3\%$ at polarization angles of $37^\circ\pm5^\circ$ and $-12^\circ\pm7^\circ$, respectively. Thus we observed a rotation of the polarization angle by $49^\circ\pm8^\circ$ along the orbit. Because variations of accretion flow, and then of the hardness ratio, are expected during the orbit, we also studied the polarization binned in hardness ratio, and found the polarization angle differing by $67^\circ\pm11^\circ$ between the lowest and highest values of the hardness ratio. We discuss possible interpretations of this result that could indicate a possible misalignment between the symmetry axes of the accretion disk and the Comptonizing region caused by the misalignment of the neutron star&#39;s angular momentum with respect to the orbital one.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.04632v2-abstract-full').style.display = 'none'; document.getElementById('2311.04632v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 22 December, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 November, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">15 pages, 6 figures, Accepted for publication in ApJL</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ApJL 961 L8 (2024)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2311.01404">arXiv:2311.01404</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2311.01404">pdf</a>, <a href="https://arxiv.org/ps/2311.01404">ps</a>, <a href="https://arxiv.org/format/2311.01404">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Scagliotti%2C+A">Alessandro Scagliotti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+S">Sara Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2311.01404v4-abstract-short" style="display: inline;">
        In this paper, we consider the problem of recovering the $W_2$-optimal transport map T between absolutely continuous measures $,\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural ODE, where the control depends only on the time variable and takes values in a finite-dimensional space. We first show that, under suitable assumptions on $,$ and on the controlled vector fields gove&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.01404v4-abstract-full').style.display = 'inline'; document.getElementById('2311.01404v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2311.01404v4-abstract-full" style="display: none;">
        In this paper, we consider the problem of recovering the $W_2$-optimal transport map T between absolutely continuous measures $,\in\mathcal{P}(\mathbb{R}^n)$ as the flow of a linear-control neural ODE, where the control depends only on the time variable and takes values in a finite-dimensional space. We first show that, under suitable assumptions on $,$ and on the controlled vector fields governing the neural ODE, the optimal transport map is contained in the $C^0_c$-closure of the flows generated by the system. Then, we tackle the problem under the assumption that only discrete approximations of $_N,_N$ of the original measures $,$ are available: we formulate approximated optimal control problems, and we show that their solutions give flows that approximate the original optimal transport map $T$. In the framework of generative models, the approximating flow constructed here can be seen as a `Normalizing Flow&#39;, which usually refers to the task of providing invertible transport maps between probability measures by means of deep neural networks. We propose an iterative numerical scheme based on the Pontryagin Maximum Principle for the resolution of the optimal control problem, resulting in a method for the practical computation of the approximated optimal transport map, and we test it on a two-dimensional example.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2311.01404v4-abstract-full').style.display = 'none'; document.getElementById('2311.01404v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 2 December, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 November, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> November 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Correction of typos and new bibliographical references. 33 pages, 1 figure</span>
    </p>
    

    
      <p class="comments is-size-7">
        

        
          <span class="has-text-black-bis has-text-weight-semibold">MSC Class:</span>
          34H05; 49Q22; 49J45; 49M05
        

        
      </p>
    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2310.06788">arXiv:2310.06788</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2310.06788">pdf</a>, <a href="https://arxiv.org/ps/2310.06788">ps</a>, <a href="https://arxiv.org/format/2310.06788">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Discovery of a variable energy-dependent X-ray polarization in the accreting neutron star GX 5-1
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fabiani%2C+S">Sergio Fabiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Capitanio%2C+F">Fiamma Capitanio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iaria%2C+R">Rosario Iaria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ursini%2C+F">Francesco Ursini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bobrikova%2C+A">Anna Bobrikova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Steiner%2C+J+F">James F. Steiner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Svoboda%2C+J">Jiri Svoboda</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anitra%2C+A">Alessio Anitra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baglio%2C+M+C">Maria C. Baglio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Carotenuto%2C+F">Francesco Carotenuto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Santo%2C+M">Melania Del Santo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrigno%2C+C">Carlo Ferrigno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lewis%2C+F">Fraser Lewis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Russell%2C+D+M">David M. Russell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Russell%2C+T+D">Thomas D. Russell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eijnden%2C+J+v+d">Jakob van den Eijnden</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cocchi%2C+M">Massimo Cocchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+K">Kuan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Weisskopf%2C+M+C">Martin C. Weisskopf</a>
      , et al. (94 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2310.06788v2-abstract-short" style="display: inline;">
        We report on the coordinated observations of the neutron star low-mass X-ray binary (NS-LMXB) \gx in X-rays (IXPE, NICER, Nustar and INTEGRAL), optical (REM and LCO), near-infrared (REM), mid-infrared (VLT VISIR), and radio (ATCA). This Z-source was observed by \IXPE twice in March-April 2023 (Obs. 1 and 2). In the radio band, the source was detected, but only upper-limits to the linear polarizati&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.06788v2-abstract-full').style.display = 'inline'; document.getElementById('2310.06788v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2310.06788v2-abstract-full" style="display: none;">
        We report on the coordinated observations of the neutron star low-mass X-ray binary (NS-LMXB) \gx in X-rays (IXPE, NICER, Nustar and INTEGRAL), optical (REM and LCO), near-infrared (REM), mid-infrared (VLT VISIR), and radio (ATCA). This Z-source was observed by \IXPE twice in March-April 2023 (Obs. 1 and 2). In the radio band, the source was detected, but only upper-limits to the linear polarization were obtained at a $3$ level of $6.1\%$ at 5.5 GHz and $5.9\%$ at 9 GHz in Obs.~1 and $12.5\%$ at 5.5~GHz and $20\%$ at 9~GHz in Obs.~2. The mid-IR, near-IR and optical observations suggest the presence of a compact jet which peaks in the mid- or far-IR. The X-ray polarization degree was found to be $3.7\% \pm 0.4 \%$ (at $90\%$ confidence level) during Obs.~1 when the source was in the horizontal branch of the Z-track and $1.8\% \pm 0.4 \%$ during Obs.~2 when the source was in the normal-flaring branch. These results confirm the variation of polarization degree as a function of the position of the source in the color-color diagram as for previously observed Z-track sources (Cyg~X-2 and XTE~1701$-$462). Evidence for a variation of the polarization angle $\sim 20^\circ$ with energy is found in both observations, likely related to the different, non-orthogonal polarization angles of the disk and Comptonization components which peak at different energies.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2310.06788v2-abstract-full').style.display = 'none'; document.getElementById('2310.06788v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 9 December, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 10 October, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Submitted to Astronomy and Astrophysics on 06 July 2023. Accepted on 21 November 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.09842">arXiv:2308.09842</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.09842">pdf</a>, <a href="https://arxiv.org/format/2308.09842">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cicalese%2C+F">Ferdinando Cicalese</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.09842v2-abstract-short" style="display: inline;">
        Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approxima&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.09842v2-abstract-full').style.display = 'inline'; document.getElementById('2308.09842v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.09842v2-abstract-full" style="display: none;">
        Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.09842v2-abstract-full').style.display = 'none'; document.getElementById('2308.09842v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 February, 2024; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 18 August, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 38th Annual AAAI Conference on Artificial Intelligence 2024</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2308.08854">arXiv:2308.08854</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2308.08854">pdf</a>, <a href="https://arxiv.org/format/2308.08854">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Language-enhanced RNR-Map: Querying Renderable Neural Radiance Field maps with natural language
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Taioli%2C+F">Francesco Taioli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cunico%2C+F">Federico Cunico</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Girella%2C+F">Federico Girella</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bologna%2C+R">Riccardo Bologna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2308.08854v1-abstract-short" style="display: inline;">
        We present Le-RNR-Map, a Language-enhanced Renderable Neural Radiance map for Visual Navigation with natural language query prompts. The recently proposed RNR-Map employs a grid structure comprising latent codes positioned at each pixel. These latent codes, which are derived from image observation, enable: i) image rendering given a camera pose, since they are converted to Neural Radiance Field; i&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.08854v1-abstract-full').style.display = 'inline'; document.getElementById('2308.08854v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2308.08854v1-abstract-full" style="display: none;">
        We present Le-RNR-Map, a Language-enhanced Renderable Neural Radiance map for Visual Navigation with natural language query prompts. The recently proposed RNR-Map employs a grid structure comprising latent codes positioned at each pixel. These latent codes, which are derived from image observation, enable: i) image rendering given a camera pose, since they are converted to Neural Radiance Field; ii) image navigation and localization with astonishing accuracy. On top of this, we enhance RNR-Map with CLIP-based embedding latent codes, allowing natural language search without additional label data. We evaluate the effectiveness of this map in single and multi-object searches. We also investigate its compatibility with a Large Language Model as an &#34;affordance query resolver&#34;. Code and videos are available at https://intelligolabs.github.io/Le-RNR-Map/
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2308.08854v1-abstract-full').style.display = 'none'; document.getElementById('2308.08854v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 August, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> August 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at ICCVW23 VLAR</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.10965">arXiv:2306.10965</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.10965">pdf</a>, <a href="https://arxiv.org/format/2306.10965">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Solar and Stellar Astrophysics">astro-ph.SR</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1051/0004-6361/202346275">10.1051/0004-6361/202346275 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Discovery of strongly variable X-ray polarization in the neutron star low-mass X-ray binary transient XTE J1701$-$462
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Cocchi%2C+M">Massimo Cocchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fabiani%2C+S">Sergio Fabiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ursini%2C+F">Francesco Ursini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Capitanio%2C+F">Fiamma Capitanio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bobrikova%2C+A">Anna Bobrikova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Paizis%2C+A">Adamantia Paizis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sidoli%2C+L">Lara Sidoli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Veledina%2C+A">Alexandra Veledina</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+S">Stefano Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ingram%2C+A">Adam Ingram</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kajava%2C+J+J+E">Jari J. E. Kajava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matt%2C+G">Giorgio Matt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Malacaria%2C+C">Christian Malacaria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Miku%C5%A1incov%C3%A1%2C+R">Romana Mikuincov</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Zane%2C+S">Silvia Zane</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agudo%2C+I">Ivn Agudo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Antonelli%2C+L+A">Lucio A. Antonelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bachetti%2C+M">Matteo Bachetti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baldini%2C+L">Luca Baldini</a>
      , et al. (83 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.10965v1-abstract-short" style="display: inline;">
        After about 16 years since its first outburst, the transient neutron star low-mass X-ray binary XTE J1701$-$462 turned on again in September 2022, allowing for the first study of its X-ray polarimetric characteristics by a dedicated observing program with the Imaging X-ray Polarimeter Explorer (IXPE). Polarimetric studies of XTE J1701$-$462 have been expected to improve our understanding of accret&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.10965v1-abstract-full').style.display = 'inline'; document.getElementById('2306.10965v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.10965v1-abstract-full" style="display: none;">
        After about 16 years since its first outburst, the transient neutron star low-mass X-ray binary XTE J1701$-$462 turned on again in September 2022, allowing for the first study of its X-ray polarimetric characteristics by a dedicated observing program with the Imaging X-ray Polarimeter Explorer (IXPE). Polarimetric studies of XTE J1701$-$462 have been expected to improve our understanding of accreting weakly magnetized neutron stars, in particular, the physics and the geometry of the hot inner regions close to the compact object. The IXPE data of two triggered observations were analyzed using time-resolved spectroscopic and polarimetric techniques, following the source along its Z-track of the color-color diagram. During the first pointing on 2022 September 29, an average 2-8 keV polarization degree of 4.6$\pm$ 0.4\% was measured, the highest value found up to now for this class of sources. Conversely, only a $\sim$0.6\% average degree was obtained during the second pointing ten days later. The polarimetric signal appears to be strictly related to the higher energy blackbody component associated with the boundary layer (BL) emission and its reflection from the inner accretion disk, and it is as strong as 6.1\% and 1.2\% ($&gt;95\%$ significant) above 3-4 keV for the two measurements, respectively. The variable polarimetric signal is apparently related to the spectral characteristics of XTE J1701$-$462, which is the strongest when the source was in the horizontal branch of its Z-track and the weakest in the normal branch. These IXPE results provide new important observational constraints on the physical models and geometry of the Z-sources. Here, we discuss the possible reasons for the presence of strong and variable polarization among these sources.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.10965v1-abstract-full').style.display = 'none'; document.getElementById('2306.10965v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 8 figures; published in A&amp;A 674, L10 (2023)</span>
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        A&amp;A 674, L10 (2023)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2306.08476">arXiv:2306.08476</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2306.08476">pdf</a>, <a href="https://arxiv.org/format/2306.08476">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3847/2041-8213/acec6e">10.3847/2041-8213/acec6e <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        First detection of X-ray polarization from the accreting neutron star 4U 1820-303
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Di+Marco%2C+A">Alessandro Di Marco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=La+Monaca%2C+F">Fabio La Monaca</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Russell%2C+T+D">Thomas D. Russell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Anitra%2C+A">Alessio Anitra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mastroserio%2C+G">Guglielmo Mastroserio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muleri%2C+F">Fabio Muleri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Xie%2C+F">Fei Xie</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bachetti%2C+M">Matteo Bachetti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Burderi%2C+L">Luciano Burderi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Carotenuto%2C+F">Francesco Carotenuto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Santo%2C+M">Melania Del Santo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Di+Salvo%2C+T">Tiziana Di Salvo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dovciak%2C+M">Michal Dovciak</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Iaria%2C+R">Rosario Iaria</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kajava%2C+J+J+E">Jari J. E. Kajava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Liu%2C+K">Kuan Liu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Middei%2C+R">Riccardo Middei</a>, 
      
      <a href="/search/?searchtype=author&amp;query=O%27Dell%2C+S+L">Stephen L. O&#39;Dell</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pilia%2C+M">Maura Pilia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rankin%2C+J">John Rankin</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sanna%2C+A">Andrea Sanna</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Eijnden%2C+J+v+d">Jakob van den Eijnden</a>
      , et al. (94 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2306.08476v4-abstract-short" style="display: inline;">
        This paper reports the first detection of polarization in the X-rays for atoll-source 4U 1820-303, obtained with the Imaging X-ray Polarimetry Explorer (IXPE) at 99.999% confidence level (CL). Simultaneous polarimetric measurements were also performed in the radio with the Australia Telescope Compact Array (ATCA). The IXPE observations of 4U 1820-303 were coordinated with Swift-XRT, NICER, and NuS&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.08476v4-abstract-full').style.display = 'inline'; document.getElementById('2306.08476v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2306.08476v4-abstract-full" style="display: none;">
        This paper reports the first detection of polarization in the X-rays for atoll-source 4U 1820-303, obtained with the Imaging X-ray Polarimetry Explorer (IXPE) at 99.999% confidence level (CL). Simultaneous polarimetric measurements were also performed in the radio with the Australia Telescope Compact Array (ATCA). The IXPE observations of 4U 1820-303 were coordinated with Swift-XRT, NICER, and NuSTAR aiming to obtain an accurate X-ray spectral model covering a broad energy interval. The source shows a significant polarization above 4 keV, with a polarization degree of 2.0(0.5)% and a polarization angle of -55(7) deg in the 4-7 keV energy range, and a polarization degree of 10(2)% and a polarization angle of -67(7) deg in the 7-8 keV energy bin. This polarization also shows a clear energy trend with polarization degree increasing with energy and a hint for a position-angle change of about 90 deg at 96% CL around 4 keV. The spectro-polarimetric fit indicates that the accretion disk is polarized orthogonally to the hard spectral component, which is presumably produced in the boundary/spreading layer. We do not detect linear polarization from the radio counterpart, with a 99.97% upper limit of 50% at 7.25 GHz.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2306.08476v4-abstract-full').style.display = 'none'; document.getElementById('2306.08476v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 21 August, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 14 June, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2023.
      
    </p>
    

    

    
      <p class="comments is-size-7">
        <span class="has-text-black-bis has-text-weight-semibold">Journal ref:</span>
        ApJL 953 L22 (2023)
      </p>
    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.09172">arXiv:2303.09172</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.09172">pdf</a>, <a href="https://arxiv.org/format/2303.09172">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Logic in Computer Science">cs.LO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Learning Logic Specifications for Soft Policy Guidance in POMCP
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mazzi%2C+G">Giulio Mazzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Meli%2C+D">Daniele Meli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.09172v1-abstract-short" style="display: inline;">
        Partially Observable Monte Carlo Planning (POMCP) is an efficient solver for Partially Observable Markov Decision Processes (POMDPs). It allows scaling to large state spaces by computing an approximation of the optimal policy locally and online, using a Monte Carlo Tree Search based strategy. However, POMCP suffers from sparse reward function, namely, rewards achieved only when the final goal is r&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.09172v1-abstract-full').style.display = 'inline'; document.getElementById('2303.09172v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.09172v1-abstract-full" style="display: none;">
        Partially Observable Monte Carlo Planning (POMCP) is an efficient solver for Partially Observable Markov Decision Processes (POMDPs). It allows scaling to large state spaces by computing an approximation of the optimal policy locally and online, using a Monte Carlo Tree Search based strategy. However, POMCP suffers from sparse reward function, namely, rewards achieved only when the final goal is reached, particularly in environments with large state spaces and long horizons. Recently, logic specifications have been integrated into POMCP to guide exploration and to satisfy safety requirements. However, such policy-related rules require manual definition by domain experts, especially in real-world scenarios. In this paper, we use inductive logic programming to learn logic specifications from traces of POMCP executions, i.e., sets of belief-action pairs generated by the planner. Specifically, we learn rules expressed in the paradigm of answer set programming. We then integrate them inside POMCP to provide soft policy bias toward promising actions. In the context of two benchmark scenarios, rocksample and battery, we show that the integration of learned rules from small task instances can improve performance with fewer Monte Carlo simulations and in larger task instances. We make our modified version of POMCP publicly available at https://github.com/GiuMaz/pomcp_clingo.git.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.09172v1-abstract-full').style.display = 'none'; document.getElementById('2303.09172v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in the Proceedings of 22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS) 2023</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.03207">arXiv:2303.03207</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.03207">pdf</a>, <a href="https://arxiv.org/format/2303.03207">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Constrained Reinforcement Learning and Formal Verification for Safe Colonoscopy Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pore%2C+A">Ameya Pore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casals%2C+A">Alicia Casals</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fiorini%2C+P">Paolo Fiorini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dall%27Alba%2C+D">Diego Dall&#39;Alba</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.03207v3-abstract-short" style="display: inline;">
        The field of robotic Flexible Endoscopes (FEs) has progressed significantly, offering a promising solution to reduce patient discomfort. However, the limited autonomy of most robotic FEs results in non-intuitive and challenging manoeuvres, constraining their application in clinical settings. While previous studies have employed lumen tracking for autonomous navigation, they fail to adapt to the pr&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.03207v3-abstract-full').style.display = 'inline'; document.getElementById('2303.03207v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.03207v3-abstract-full" style="display: none;">
        The field of robotic Flexible Endoscopes (FEs) has progressed significantly, offering a promising solution to reduce patient discomfort. However, the limited autonomy of most robotic FEs results in non-intuitive and challenging manoeuvres, constraining their application in clinical settings. While previous studies have employed lumen tracking for autonomous navigation, they fail to adapt to the presence of obstructions and sharp turns when the endoscope faces the colon wall. In this work, we propose a Deep Reinforcement Learning (DRL)-based navigation strategy that eliminates the need for lumen tracking. However, the use of DRL methods poses safety risks as they do not account for potential hazards associated with the actions taken. To ensure safety, we exploit a Constrained Reinforcement Learning (CRL) method to restrict the policy in a predefined safety regime. Moreover, we present a model selection strategy that utilises Formal Verification (FV) to choose a policy that is entirely safe before deployment. We validate our approach in a virtual colonoscopy environment and report that out of the 300 trained policies, we could identify three policies that are entirely safe. Our work demonstrates that CRL, combined with model selection through FV, can improve the robustness and safety of robotic behaviour in surgical applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.03207v3-abstract-full').style.display = 'none'; document.getElementById('2303.03207v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 August, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 6 March, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in the IEEE International Conference on Intelligent Robots and Systems (IROS), 2023. [Corsi, Marzari and Pore contributed equally]</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2303.03155">arXiv:2303.03155</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2303.03155">pdf</a>, <a href="https://arxiv.org/format/2303.03155">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1109/TPAMI.2024.3451994">10.1109/TPAMI.2024.3451994 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Unsupervised Active Visual Search with Monte Carlo planning under Uncertain Detections
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Taioli%2C+F">Francesco Taioli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giuliari%2C+F">Francesco Giuliari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berra%2C+R">Riccardo Berra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Bue%2C+A">Alessio Del Bue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Setti%2C+F">Francesco Setti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2303.03155v1-abstract-short" style="display: inline;">
        We propose a solution for Active Visual Search of objects in an environment, whose 2D floor map is the only known information. Our solution has three key features that make it more plausible and robust to detector failures compared to state-of-the-art methods: (i) it is unsupervised as it does not need any training sessions. (ii) During the exploration, a probability distribution on the 2D floor m&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.03155v1-abstract-full').style.display = 'inline'; document.getElementById('2303.03155v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2303.03155v1-abstract-full" style="display: none;">
        We propose a solution for Active Visual Search of objects in an environment, whose 2D floor map is the only known information. Our solution has three key features that make it more plausible and robust to detector failures compared to state-of-the-art methods: (i) it is unsupervised as it does not need any training sessions. (ii) During the exploration, a probability distribution on the 2D floor map is updated according to an intuitive mechanism, while an improved belief update increases the effectiveness of the agent&#39;s exploration. (iii) We incorporate the awareness that an object detector may fail into the aforementioned probability modelling by exploiting the success statistics of a specific detector. Our solution is dubbed POMP-BE-PD (Pomcp-based Online Motion Planning with Belief by Exploration and Probabilistic Detection). It uses the current pose of an agent and an RGB-D observation to learn an optimal search policy, exploiting a POMDP solved by a Monte-Carlo planning approach. On the Active Vision Database benchmark, we increase the average success rate over all the environments by a significant 35% while decreasing the average path length by 4% with respect to competing methods. Thus, our results are state-of-the-art, even without using any training procedure.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2303.03155v1-abstract-full').style.display = 'none'; document.getElementById('2303.03155v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 March, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> March 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">12 pages,8 figures. Submitted for review at IEEE Transactions on Pattern Analysis and Machine Intelligence. arXiv admin note: text overlap with arXiv:2009.08140</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2302.10030">arXiv:2302.10030</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2302.10030">pdf</a>, <a href="https://arxiv.org/format/2302.10030">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Safe Deep Reinforcement Learning by Verifying Task-Level Properties
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amato%2C+C">Christopher Amato</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2302.10030v1-abstract-short" style="display: inline;">
        Cost functions are commonly employed in Safe Deep Reinforcement Learning (DRL). However, the cost is typically encoded as an indicator function due to the difficulty of quantifying the risk of policy decisions in the state space. Such an encoding requires the agent to visit numerous unsafe states to learn a cost-value function to drive the learning process toward safety. Hence, increasing the numb&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.10030v1-abstract-full').style.display = 'inline'; document.getElementById('2302.10030v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2302.10030v1-abstract-full" style="display: none;">
        Cost functions are commonly employed in Safe Deep Reinforcement Learning (DRL). However, the cost is typically encoded as an indicator function due to the difficulty of quantifying the risk of policy decisions in the state space. Such an encoding requires the agent to visit numerous unsafe states to learn a cost-value function to drive the learning process toward safety. Hence, increasing the number of unsafe interactions and decreasing sample efficiency. In this paper, we investigate an alternative approach that uses domain knowledge to quantify the risk in the proximity of such states by defining a violation metric. This metric is computed by verifying task-level properties, shaped as input-output conditions, and it is used as a penalty to bias the policy away from unsafe states without learning an additional value function. We investigate the benefits of using the violation metric in standard Safe DRL benchmarks and robotic mapless navigation tasks. The navigation experiments bridge the gap between Safe DRL and robotics, introducing a framework that allows rapid testing on real robots. Our experiments show that policies trained with the violation penalty achieve higher performance over Safe DRL baselines and significantly reduce the number of visited unsafe states.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.10030v1-abstract-full').style.display = 'none'; document.getElementById('2302.10030v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 February, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 22nd International Conference on Autonomous Agents and Multiagent Systems (AAMAS). Marchesini and Marzari contributed equally</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2302.06695">arXiv:2302.06695</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2302.06695">pdf</a>, <a href="https://arxiv.org/format/2302.06695">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Online Safety Property Collection and Refinement for Safe Deep Reinforcement Learning in Mapless Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2302.06695v1-abstract-short" style="display: inline;">
        Safety is essential for deploying Deep Reinforcement Learning (DRL) algorithms in real-world scenarios. Recently, verification approaches have been proposed to allow quantifying the number of violations of a DRL policy over input-output relationships, called properties. However, such properties are hard-coded and require task-level knowledge, making their application intractable in challenging saf&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.06695v1-abstract-full').style.display = 'inline'; document.getElementById('2302.06695v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2302.06695v1-abstract-full" style="display: none;">
        Safety is essential for deploying Deep Reinforcement Learning (DRL) algorithms in real-world scenarios. Recently, verification approaches have been proposed to allow quantifying the number of violations of a DRL policy over input-output relationships, called properties. However, such properties are hard-coded and require task-level knowledge, making their application intractable in challenging safety-critical tasks. To this end, we introduce the Collection and Refinement of Online Properties (CROP) framework to design properties at training time. CROP employs a cost signal to identify unsafe interactions and use them to shape safety properties. Hence, we propose a refinement strategy to combine properties that model similar unsafe interactions. Our evaluation compares the benefits of computing the number of violations using standard hard-coded properties and the ones generated with CROP. We evaluate our approach in several robotic mapless navigation tasks and demonstrate that the violation metric computed with CROP allows higher returns and lower violations over previous Safe DRL approaches.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2302.06695v1-abstract-full').style.display = 'none'; document.getElementById('2302.06695v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 13 February, 2023; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at the 2023 IEEE International Conference on Robotics and Automation (ICRA). Marzari and Marchesini contributed equally</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2301.07068">arXiv:2301.07068</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2301.07068">pdf</a>, <a href="https://arxiv.org/format/2301.07068">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        The #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural Networks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cicalese%2C+F">Ferdinando Cicalese</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2301.07068v4-abstract-short" style="display: inline;">
        Deep Neural Networks are increasingly adopted in critical tasks that require a high level of safety, e.g., autonomous driving. While state-of-the-art verifiers can be employed to check whether a DNN is unsafe w.r.t. some given property (i.e., whether there is at least one unsafe input configuration), their yes/no output is not informative enough for other purposes, such as shielding, model selecti&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.07068v4-abstract-full').style.display = 'inline'; document.getElementById('2301.07068v4-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2301.07068v4-abstract-full" style="display: none;">
        Deep Neural Networks are increasingly adopted in critical tasks that require a high level of safety, e.g., autonomous driving. While state-of-the-art verifiers can be employed to check whether a DNN is unsafe w.r.t. some given property (i.e., whether there is at least one unsafe input configuration), their yes/no output is not informative enough for other purposes, such as shielding, model selection, or training improvements. In this paper, we introduce the #DNN-Verification problem, which involves counting the number of input configurations of a DNN that result in a violation of a particular safety property. We analyze the complexity of this problem and propose a novel approach that returns the exact count of violations. Due to the #P-completeness of the problem, we also propose a randomized, approximate method that provides a provable probabilistic bound of the correct count while significantly reducing computational requirements. We present experimental results on a set of safety-critical benchmarks that demonstrate the effectiveness of our approximate method and evaluate the tightness of the bound.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2301.07068v4-abstract-full').style.display = 'none'; document.getElementById('2301.07068v4-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 June, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 17 January, 2023;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2023.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted in the International Joint Conference on Artificial Intelligence (IJCAI), 2023. [Marzari and Corsi contributed equally]</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2212.12472">arXiv:2212.12472</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2212.12472">pdf</a>, <a href="https://arxiv.org/format/2212.12472">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Astrophysical Phenomena">astro-ph.HE</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Solar and Stellar Astrophysics">astro-ph.SR</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.3847/1538-4357/acae88">10.3847/1538-4357/acae88 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Polarization properties of the weakly magnetized neutron star X-ray binary GS 1826-238 in the high soft state
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Capitanio%2C+F">Fiamma Capitanio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fabiani%2C+S">Sergio Fabiani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gnarini%2C+A">Andrea Gnarini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ursini%2C+F">Francesco Ursini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferrigno%2C+C">Carlo Ferrigno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Matt%2C+G">Giorgio Matt</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Poutanen%2C+J">Juri Poutanen</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cocchi%2C+M">Massimo Cocchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mikusincova%2C+R">Romana Mikusincova</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Ruben Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+S">Stefano Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Kajava%2C+J+J+E">Jari J. E. Kajava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Muleri%2C+F">Fabio Muleri</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Sanchez-Fernandez%2C+C">Celia Sanchez-Fernandez</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Soffitta%2C+P">Paolo Soffitta</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wu%2C+K">Kinwah Wu</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Agudo%2C+I">Ivan Agudo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Antonelli%2C+L+A">Lucio A. Antonelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bachetti%2C+M">Matteo Bachetti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baldini%2C+L">Luca Baldini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Baumgartner%2C+W+H">Wayne H. Baumgartner</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bellazzini%2C+R">Ronaldo Bellazzini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bongiorno%2C+S+D">Stephen D. Bongiorno</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bonino%2C+R">Raffaella Bonino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Brez%2C+A">Alessandro Brez</a>
      , et al. (72 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2212.12472v1-abstract-short" style="display: inline;">
        The launch of the Imaging X-ray Polarimetry Explorer (IXPE) on 2021 December 9 has opened a new window in X-ray astronomy. We report here the results of the first IXPE observation of a weakly magnetized neutron star, GS 1826-238, performed on 2022 March 29-31 when the source was in a high soft state. An upper limit (99.73% confidence level) of 1.3% for the linear polarization degree is obtained ov&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.12472v1-abstract-full').style.display = 'inline'; document.getElementById('2212.12472v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2212.12472v1-abstract-full" style="display: none;">
        The launch of the Imaging X-ray Polarimetry Explorer (IXPE) on 2021 December 9 has opened a new window in X-ray astronomy. We report here the results of the first IXPE observation of a weakly magnetized neutron star, GS 1826-238, performed on 2022 March 29-31 when the source was in a high soft state. An upper limit (99.73% confidence level) of 1.3% for the linear polarization degree is obtained over the IXPE 2-8 keV energy range. Coordinated INTEGRAL and NICER observations were carried out simultaneously with IXPE. The spectral parameters obtained from the fits to the broad-band spectrum were used as inputs for Monte Carlo simulations considering different possible geometries of the X-ray emitting region. Comparing the IXPE upper limit with these simulations, we can put constraints on the geometry and inclination angle of GS 1826-238.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2212.12472v1-abstract-full').style.display = 'none'; document.getElementById('2212.12472v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 23 December, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accpted for publication in ApJ</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2206.09603">arXiv:2206.09603</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2206.09603">pdf</a>, <a href="https://arxiv.org/format/2206.09603">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Constrained Reinforcement Learning for Robotics via Scenario-Based Programming
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yerushalmi%2C+R">Raz Yerushalmi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Amir%2C+G">Guy Amir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harel%2C+D">David Harel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Katz%2C+G">Guy Katz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2206.09603v1-abstract-short" style="display: inline;">
        Deep reinforcement learning (DRL) has achieved groundbreaking successes in a wide variety of robotic applications. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper prese&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.09603v1-abstract-full').style.display = 'inline'; document.getElementById('2206.09603v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2206.09603v1-abstract-full" style="display: none;">
        Deep reinforcement learning (DRL) has achieved groundbreaking successes in a wide variety of robotic applications. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper presents a novel technique for incorporating domain-expert knowledge into a constrained DRL training loop. Our technique exploits the scenario-based programming paradigm, which is designed to allow specifying such knowledge in a simple and intuitive way. We validated our method on the popular robotic mapless navigation problem, in simulation, and on the actual platform. Our experiments demonstrate that using our approach to leverage expert knowledge dramatically improves the safety and the performance of the agent.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2206.09603v1-abstract-full').style.display = 'none'; document.getElementById('2206.09603v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 20 June, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> June 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.13536">arXiv:2205.13536</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.13536">pdf</a>, <a href="https://arxiv.org/format/2205.13536">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Optimization and Control">math.OC</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Verifying Learning-Based Robotic Navigation Systems
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Amir%2C+G">Guy Amir</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Yerushalmi%2C+R">Raz Yerushalmi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Harel%2C+D">David Harel</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Katz%2C+G">Guy Katz</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.13536v3-abstract-short" style="display: inline;">
        Deep reinforcement learning (DRL) has become a dominant deep-learning paradigm for tasks where complex policies are learned within reactive systems. Unfortunately, these policies are known to be susceptible to bugs. Despite significant progress in DNN verification, there has been little work demonstrating the use of modern verification tools on real-world, DRL-controlled systems. In this case stud&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.13536v3-abstract-full').style.display = 'inline'; document.getElementById('2205.13536v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.13536v3-abstract-full" style="display: none;">
        Deep reinforcement learning (DRL) has become a dominant deep-learning paradigm for tasks where complex policies are learned within reactive systems. Unfortunately, these policies are known to be susceptible to bugs. Despite significant progress in DNN verification, there has been little work demonstrating the use of modern verification tools on real-world, DRL-controlled systems. In this case study, we attempt to begin bridging this gap, and focus on the important task of mapless robotic navigation -- a classic robotics problem, in which a robot, usually controlled by a DRL agent, needs to efficiently and safely navigate through an unknown arena towards a target. We demonstrate how modern verification engines can be used for effective model selection, i.e., selecting the best available policy for the robot in question from a pool of candidate policies. Specifically, we use verification to detect and rule out policies that may demonstrate suboptimal behavior, such as collisions and infinite loops. We also apply verification to identify models with overly conservative behavior, thus allowing users to choose superior policies, which might be better at finding shorter paths to a target. To validate our work, we conducted extensive experiments on an actual robot, and confirmed that the suboptimal policies detected by our method were indeed flawed. We also demonstrate the superiority of our verification-driven approach over state-of-the-art, gradient attacks. Our work is the first to establish the usefulness of DNN verification in identifying and filtering out suboptimal DRL policies in real-world robots, and we believe that the methods presented here are applicable to a wide range of systems that incorporate deep-learning-based agents.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.13536v3-abstract-full').style.display = 'none'; document.getElementById('2205.13536v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 10 January, 2023; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 26 May, 2022;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">To appear in Proc. 29th Int. Conf. on Tools and Algorithms for the Construction and Analysis of Systems (TACAS)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2205.00215">arXiv:2205.00215</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2205.00215">pdf</a>, <a href="https://arxiv.org/format/2205.00215">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        An attention model for the formation of collectives in real-world domains
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Fenoy%2C+A">Adri Fenoy</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bistaffa%2C+F">Filippo Bistaffa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2205.00215v1-abstract-short" style="display: inline;">
        We consider the problem of forming collectives of agents for real-world applications aligned with Sustainable Development Goals (e.g., shared mobility, cooperative learning). We propose a general approach for the formation of collectives based on a novel combination of an attention model and an integer linear program (ILP). In more detail, we propose an attention encoder-decoder model that transfo&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.00215v1-abstract-full').style.display = 'inline'; document.getElementById('2205.00215v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2205.00215v1-abstract-full" style="display: none;">
        We consider the problem of forming collectives of agents for real-world applications aligned with Sustainable Development Goals (e.g., shared mobility, cooperative learning). We propose a general approach for the formation of collectives based on a novel combination of an attention model and an integer linear program (ILP). In more detail, we propose an attention encoder-decoder model that transforms a collective formation instance to a weighted set packing problem, which is then solved by an ILP. Results on two real-world domains (i.e., ridesharing and team formation for cooperative learning) show that our approach provides solutions that are comparable (in terms of quality) to the ones produced by state-of-the-art approaches specific to each domain. Moreover, our solution outperforms the most recent general approach for forming collectives based on Monte Carlo tree search.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2205.00215v1-abstract-full').style.display = 'none'; document.getElementById('2205.00215v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 April, 2022; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2022.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.12490">arXiv:2112.12490</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.12490">pdf</a>, <a href="https://arxiv.org/format/2112.12490">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
        
          <div class="is-inline-block" style="margin-left: 0.5rem">
            <div class="tags has-addons">
              <span class="tag is-dark is-size-7">doi</span>
              <span class="tag is-light is-size-7"><a class="" href="https://doi.org/10.1145/3477314.3507182">10.1145/3477314.3507182 <i class="fa fa-external-link" aria-hidden="true"></i></a></span>
            </div>
          </div>
        
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Curriculum Learning for Safe Mapless Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.12490v2-abstract-short" style="display: inline;">
        This work investigates the effects of Curriculum Learning (CL)-based approaches on the agent&#39;s performance. In particular, we focus on the safety aspect of robotic mapless navigation, comparing over a standard end-to-end (E2E) training strategy. To this end, we present a CL approach that leverages Transfer of Learning (ToL) and fine-tuning in a Unity-based simulation with the Robotnik Kairos as a&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.12490v2-abstract-full').style.display = 'inline'; document.getElementById('2112.12490v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.12490v2-abstract-full" style="display: none;">
        This work investigates the effects of Curriculum Learning (CL)-based approaches on the agent&#39;s performance. In particular, we focus on the safety aspect of robotic mapless navigation, comparing over a standard end-to-end (E2E) training strategy. To this end, we present a CL approach that leverages Transfer of Learning (ToL) and fine-tuning in a Unity-based simulation with the Robotnik Kairos as a robotic agent. For a fair comparison, our evaluation considers an equal computational demand for every learning approach (i.e., the same number of interactions and difficulty of the environments) and confirms that our CL-based method that uses ToL outperforms the E2E methodology. In particular, we improve the average success rate and the safety of the trained policy, resulting in 10% fewer collisions in unseen testing scenarios. To further confirm these results, we employ a formal verification tool to quantify the number of correct behaviors of Reinforcement Learning policies over desired specifications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.12490v2-abstract-full').style.display = 'none'; document.getElementById('2112.12490v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 29 December, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 December, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">8 pages, 5 figures. The poster version of this paper has been accepted by The 37th ACM/SIGAPP Symposium on Applied Computing Proceedings (SAC IRMAS 2022)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.10593">arXiv:2112.10593</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.10593">pdf</a>, <a href="https://arxiv.org/format/2112.10593">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Benchmarking Safe Deep Reinforcement Learning in Aquatic Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.10593v1-abstract-short" style="display: inline;">
        We propose a novel benchmark environment for Safe Reinforcement Learning focusing on aquatic navigation. Aquatic navigation is an extremely challenging task due to the non-stationary environment and the uncertainties of the robotic platform, hence it is crucial to consider the safety aspect of the problem, by analyzing the behavior of the trained network to avoid dangerous situations (e.g., collis&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.10593v1-abstract-full').style.display = 'inline'; document.getElementById('2112.10593v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.10593v1-abstract-full" style="display: none;">
        We propose a novel benchmark environment for Safe Reinforcement Learning focusing on aquatic navigation. Aquatic navigation is an extremely challenging task due to the non-stationary environment and the uncertainties of the robotic platform, hence it is crucial to consider the safety aspect of the problem, by analyzing the behavior of the trained network to avoid dangerous situations (e.g., collisions). To this end, we consider a value-based and policy-gradient Deep Reinforcement Learning (DRL) and we propose a crossover-based strategy that combines gradient-based and gradient-free DRL to improve sample-efficiency. Moreover, we propose a verification strategy based on interval analysis that checks the behavior of the trained models over a set of desired properties. Our results show that the crossover-based training outperforms prior DRL approaches, while our verification allows us to quantify the number of configurations that violate the behaviors that are described by the properties. Crucially, this will serve as a benchmark for future research in this domain of applications.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.10593v1-abstract-full').style.display = 'none'; document.getElementById('2112.10593v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 5 figures, 1 table. Accepted at IROS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2112.09012">arXiv:2112.09012</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2112.09012">pdf</a>, <a href="https://arxiv.org/format/2112.09012">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Multiagent Systems">cs.MA</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Machine Learning">cs.LG</span>
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Centralizing State-Values in Dueling Networks for Multi-Robot Reinforcement Learning Mapless Navigation
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2112.09012v1-abstract-short" style="display: inline;">
        We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep Reinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint action-value functi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.09012v1-abstract-full').style.display = 'inline'; document.getElementById('2112.09012v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2112.09012v1-abstract-full" style="display: none;">
        We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep Reinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint action-value function into individual ones, to favor cooperation and achieve decentralized execution. Such factorization involves constraints (e.g., monotonicity) that limit the emergence of novel behaviors in an individual as each agent is trained starting from a joint action-value. In contrast, we propose a novel architecture for CTDE that uses a centralized state-value network to compute a joint state-value, which is used to inject global state information in the value-based updates of the agents. Consequently, each model computes its gradient update for the weights, considering the overall state of the environment. Our idea follows the insights of Dueling Networks as a separate estimation of the joint state-value has both the advantage of improving sample efficiency, while providing each robot information whether the global state is (or is not) valuable. Experiments in a robotic navigation task with 2 4, and 8 robots, confirm the superior performance of our approach over prior CTDE methods (e.g., VDN, QMIX).
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2112.09012v1-abstract-full').style.display = 'none'; document.getElementById('2112.09012v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 16 December, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">6 pages, 5 figures, 1 table. Accepted at IROS 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2109.02323">arXiv:2109.02323</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2109.02323">pdf</a>, <a href="https://arxiv.org/format/2109.02323">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Safe Reinforcement Learning using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Pore%2C+A">Ameya Pore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dall%27Alba%2C+D">Diego Dall&#39;Alba</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Casals%2C+A">Alicia Casals</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fiorini%2C+P">Paolo Fiorini</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2109.02323v1-abstract-short" style="display: inline;">
        Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon&#39;s cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety c&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.02323v1-abstract-full').style.display = 'inline'; document.getElementById('2109.02323v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2109.02323v1-abstract-full" style="display: none;">
        Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon&#39;s cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety criteria as they maximise cumulative rewards without considering the risks associated with the actions performed. Due to this limitation, the application of DRL in the safety-critical paradigm of robot-assisted Minimally Invasive Surgery (MIS) has been constrained. In this work, we introduce a Safe-DRL framework that incorporates safety constraints for the automation of surgical subtasks via DRL training. We validate our approach in a virtual scene that replicates a tissue retraction task commonly occurring in multiple phases of an MIS. Furthermore, to evaluate the safe behaviour of the robotic arms, we formulate a formal verification tool for DRL methods that provides the probability of unsafe configurations. Our results indicate that a formal analysis guarantees safety with high confidence such that the robotic instruments operate within the safe workspace and avoid hazardous interaction with other anatomical structures.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2109.02323v1-abstract-full').style.display = 'none'; document.getElementById('2109.02323v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 6 September, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">7 pages, 6 figures</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2107.00914">arXiv:2107.00914</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2107.00914">pdf</a>, <a href="https://arxiv.org/format/2107.00914">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        POMP++: Pomcp-based Active Visual Search in unknown indoor environments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Giuliari%2C+F">Francesco Giuliari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berra%2C+R">Riccardo Berra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Bue%2C+A">Alessio Del Bue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Setti%2C+F">Francesco Setti</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2107.00914v2-abstract-short" style="display: inline;">
        In this paper we focus on the problem of learning online an optimal policy for Active Visual Search (AVS) of objects in unknown indoor environments. We propose POMP++, a planning strategy that introduces a novel formulation on top of the classic Partially Observable Monte Carlo Planning (POMCP) framework, to allow training-free online policy learning in unknown environments. We present a new belie&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00914v2-abstract-full').style.display = 'inline'; document.getElementById('2107.00914v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2107.00914v2-abstract-full" style="display: none;">
        In this paper we focus on the problem of learning online an optimal policy for Active Visual Search (AVS) of objects in unknown indoor environments. We propose POMP++, a planning strategy that introduces a novel formulation on top of the classic Partially Observable Monte Carlo Planning (POMCP) framework, to allow training-free online policy learning in unknown environments. We present a new belief reinvigoration strategy which allows to use POMCP with a dynamically growing state space to address the online generation of the floor map. We evaluate our method on two public benchmark datasets, AVD that is acquired by real robotic platforms and Habitat ObjectNav that is rendered from real 3D scene scans, achieving the best success rate with an improvement of &gt;10% over the state-of-the-art methods.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2107.00914v2-abstract-full').style.display = 'none'; document.getElementById('2107.00914v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 5 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 2 July, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> July 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2104.13791">arXiv:2104.13791</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2104.13791">pdf</a>, <a href="https://arxiv.org/format/2104.13791">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Rule-based Shielding for Partially Observable Monte-Carlo Planning
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mazzi%2C+G">Giulio Mazzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2104.13791v1-abstract-short" style="display: inline;">
        Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders policy interpretability and makes policy verification very complex. In&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.13791v1-abstract-full').style.display = 'inline'; document.getElementById('2104.13791v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2104.13791v1-abstract-full" style="display: none;">
        Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders policy interpretability and makes policy verification very complex. In this work, we propose two contributions. The first is a method for identifying unexpected actions selected by POMCP with respect to expert prior knowledge of the task. The second is a shielding approach that prevents POMCP from selecting unexpected actions. The first method is based on Satisfiability Modulo Theory (SMT). It inspects traces (i.e., sequences of belief-action-observation triplets) generated by POMCP to compute the parameters of logical formulas about policy properties defined by the expert. The second contribution is a module that uses online the logical formulas to identify anomalous actions selected by POMCP and substitutes those actions with actions that satisfy the logical formulas fulfilling expert knowledge. We evaluate our approach on Tiger, a standard benchmark for POMDPs, and a real-world problem related to velocity regulation in mobile robot navigation. Results show that the shielded POMCP outperforms the standard POMCP in a case study in which a wrong parameter of POMCP makes it select wrong actions from time to time. Moreover, we show that the approach keeps good performance also if the parameters of the logical formula are optimized using trajectories containing some wrong actions.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2104.13791v1-abstract-full').style.display = 'none'; document.getElementById('2104.13791v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2021; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> April 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">arXiv admin note: substantial text overlap with arXiv:2012.12732</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2102.04022">arXiv:2102.04022</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2102.04022">pdf</a>, <a href="https://arxiv.org/format/2102.04022">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Towards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasks
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Marzari%2C+L">Luca Marzari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Pore%2C+A">Ameya Pore</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Dall%27Alba%2C+D">Diego Dall&#39;Alba</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Aragon-Camarasa%2C+G">Gerardo Aragon-Camarasa</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fiorini%2C+P">Paolo Fiorini</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2102.04022v3-abstract-short" style="display: inline;">
        Deep Reinforcement Learning (DRL) is emerging as a promising approach to generate adaptive behaviors for robotic platforms. However, a major drawback of using DRL is the data-hungry training regime that requires millions of trial and error attempts, which is impractical when running experiments on robotic systems. Learning from Demonstrations (LfD) has been introduced to solve this issue by clonin&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04022v3-abstract-full').style.display = 'inline'; document.getElementById('2102.04022v3-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2102.04022v3-abstract-full" style="display: none;">
        Deep Reinforcement Learning (DRL) is emerging as a promising approach to generate adaptive behaviors for robotic platforms. However, a major drawback of using DRL is the data-hungry training regime that requires millions of trial and error attempts, which is impractical when running experiments on robotic systems. Learning from Demonstrations (LfD) has been introduced to solve this issue by cloning the behavior of expert demonstrations. However, LfD requires a large number of demonstrations that are difficult to be acquired since dedicated complex setups are required. To overcome these limitations, we propose a multi-subtask reinforcement learning methodology where complex pick and place tasks can be decomposed into low-level subtasks. These subtasks are parametrized as expert networks and learned via DRL methods. Trained subtasks are then combined by a high-level choreographer to accomplish the intended pick and place task considering different initial configurations. As a testbed, we use a pick and place robotic simulator to demonstrate our methodology and show that our method outperforms a benchmark methodology based on LfD in terms of sample-efficiency. We transfer the learned policy to the real robotic system and demonstrate robust grasping using various geometric-shaped objects.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2102.04022v3-abstract-full').style.display = 'none'; document.getElementById('2102.04022v3-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 October, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 8 February, 2021;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> February 2021.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">This work has been accepted to the IEEE International Conference on Advanced Robotics (ICAR) 2021</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2012.12732">arXiv:2012.12732</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2012.12732">pdf</a>, <a href="https://arxiv.org/format/2012.12732">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Identification of Unexpected Decisions in Partially Observable Monte-Carlo Planning: a Rule-Based Approach
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Mazzi%2C+G">Giulio Mazzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2012.12732v2-abstract-short" style="display: inline;">
        Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders interpretability. In this work, we propose a methodology based on Sati&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.12732v2-abstract-full').style.display = 'inline'; document.getElementById('2012.12732v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2012.12732v2-abstract-full" style="display: none;">
        Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders interpretability. In this work, we propose a methodology based on Satisfiability Modulo Theory (SMT) for analyzing POMCP policies by inspecting their traces, namely sequences of belief-action-observation triplets generated by the algorithm. The proposed method explores local properties of policy behavior to identify unexpected decisions. We propose an iterative process of trace analysis consisting of three main steps, i) the definition of a question by means of a parametric logical formula describing (probabilistic) relationships between beliefs and actions, ii) the generation of an answer by computing the parameters of the logical formula that maximize the number of satisfied clauses (solving a MAX-SMT problem), iii) the analysis of the generated logical formula and the related decision boundaries for identifying unexpected decisions made by POMCP with respect to the original question. We evaluate our approach on Tiger, a standard benchmark for POMDPs, and a real-world problem related to mobile robot navigation. Results show that the approach can exploit human knowledge on the domain, outperforming state-of-the-art anomaly detection methods in identifying unexpected decisions. An improvement of the Area Under Curve up to 47\% has been achieved in our tests.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2012.12732v2-abstract-full').style.display = 'none'; document.getElementById('2012.12732v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 28 April, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 23 December, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> December 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">AAMAS 2021, 3-7 May 2021, London-UK (Virtual)</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2010.09387">arXiv:2010.09387</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2010.09387">pdf</a>, <a href="https://arxiv.org/format/2010.09387">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Artificial Intelligence">cs.AI</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        Evaluating the Safety of Deep Reinforcement Learning Models using Semi-Formal Verification
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Corsi%2C+D">Davide Corsi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marchesini%2C+E">Enrico Marchesini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2010.09387v1-abstract-short" style="display: inline;">
        Groundbreaking successes have been achieved by Deep Reinforcement Learning (DRL) in solving practical decision-making problems. Robotics, in particular, can involve high-cost hardware and human interactions. Hence, scrupulous evaluations of trained models are required to avoid unsafe behaviours in the operational environment. However, designing metrics to measure the safety of a neural network is&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09387v1-abstract-full').style.display = 'inline'; document.getElementById('2010.09387v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2010.09387v1-abstract-full" style="display: none;">
        Groundbreaking successes have been achieved by Deep Reinforcement Learning (DRL) in solving practical decision-making problems. Robotics, in particular, can involve high-cost hardware and human interactions. Hence, scrupulous evaluations of trained models are required to avoid unsafe behaviours in the operational environment. However, designing metrics to measure the safety of a neural network is an open problem, since standard evaluation parameters (e.g., total reward) are not informative enough. In this paper, we present a semi-formal verification approach for decision-making tasks, based on interval analysis, that addresses the computational demanding of previous verification frameworks and design metrics to measure the safety of the models. Our method obtains comparable results over standard benchmarks with respect to formal verifiers, while drastically reducing the computation time. Moreover, our approach allows to efficiently evaluate safety properties for decision-making models in practical applications such as mapless navigation for mobile robots and trajectory generation for manipulators.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2010.09387v1-abstract-full').style.display = 'none'; document.getElementById('2010.09387v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 19 October, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> October 2020.
      
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2009.08140">arXiv:2009.08140</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/2009.08140">pdf</a>, <a href="https://arxiv.org/format/2009.08140">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Robotics">cs.RO</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Computer Vision and Pattern Recognition">cs.CV</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        POMP: Pomcp-based Online Motion Planning for active visual search in indoor environments
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Wang%2C+Y">Yiming Wang</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Giuliari%2C+F">Francesco Giuliari</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Berra%2C+R">Riccardo Berra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Castellini%2C+A">Alberto Castellini</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Del+Bue%2C+A">Alessio Del Bue</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cristani%2C+M">Marco Cristani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Setti%2C+F">Francesco Setti</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2009.08140v1-abstract-short" style="display: inline;">
        In this paper we focus on the problem of learning an optimal policy for Active Visual Search (AVS) of objects in known indoor environments with an online setup. Our POMP method uses as input the current pose of an agent (e.g. a robot) and a RGB-D frame. The task is to plan the next move that brings the agent closer to the target object. We model this problem as a Partially Observable Markov Decisi&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.08140v1-abstract-full').style.display = 'inline'; document.getElementById('2009.08140v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2009.08140v1-abstract-full" style="display: none;">
        In this paper we focus on the problem of learning an optimal policy for Active Visual Search (AVS) of objects in known indoor environments with an online setup. Our POMP method uses as input the current pose of an agent (e.g. a robot) and a RGB-D frame. The task is to plan the next move that brings the agent closer to the target object. We model this problem as a Partially Observable Markov Decision Process solved by a Monte-Carlo planning approach. This allows us to make decisions on the next moves by iterating over the known scenario at hand, exploring the environment and searching for the object at the same time. Differently from the current state of the art in Reinforcement Learning, POMP does not require extensive and expensive (in time and computation) labelled data so being very agile in solving AVS in small and medium real scenarios. We only require the information of the floormap of the environment, an information usually available or that can be easily extracted from an a priori single exploration run. We validate our method on the publicly available AVD benchmark, achieving an average success rate of 0.76 with an average path length of 17.1, performing close to the state of the art but without any training needed. Additionally, we show experimentally the robustness of our method when the quality of the object detection goes from ideal to faulty.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2009.08140v1-abstract-full').style.display = 'none'; document.getElementById('2009.08140v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 17 September, 2020; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> September 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Accepted at BMVC2020</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/2005.06306">arXiv:2005.06306</a>
        <span>&nbsp;&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="High Energy Physics - Phenomenology">hep-ph</span>
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A possible simultaneous fit to the available $e^+e^- \rightarrow ^+_c \bar^-_c$ cross section data nearby $(4660)$ by means of a strong correction to the Coulomb enhancement factor
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Amoroso%2C+A">Antonio Amoroso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bagnasco%2C+S">Stefano Bagnasco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Ferroli%2C+R+B">Rinaldo Baldini Ferroli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Balossino%2C+I">Ilaria Balossino</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bertani%2C+M">Monica Bertani</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bettoni%2C+D">Diego Bettoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bianchi%2C+F">Fabrizio Bianchi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Bortone%2C+A">Alberto Bortone</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Calcaterra%2C+A">Alessandro Calcaterra</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cibinetto%2C+G">Gianluigi Cibinetto</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Cossio%2C+F">Fabio Cossio</a>, 
      
      <a href="/search/?searchtype=author&amp;query=De+Mori%2C+F">Francesca De Mori</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Rolo%2C+M+D+D+R">Manuel Dioniso Da Rocha Rolo</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Destefanis%2C+M">Marco Destefanis</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+R">Riccardo Farinelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Fava%2C+L">Luciano Fava</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Felici%2C+G">Giulietto Felici</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Gaido%2C+L">Luciano Gaido</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Garzia%2C+I">Isabella Garzia</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Greco%2C+M">Michela Greco</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lavezzi%2C+L">Lia Lavezzi</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Lusso%2C+S">Stefano Lusso</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Maggiora%2C+M">Marco Maggiora</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Mangoni%2C+A">Alessio Mangoni</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Marcello%2C+S">Simonetta Marcello</a>
      , et al. (8 additional authors not shown)
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="2005.06306v2-abstract-short" style="display: inline;">
        There are two available set of data on the $e^+e^- \rightarrow ^+_c \bar_c^-$ cross section above threshold. The BELLE measurement, with ISR return, is compatible with the presence of a resonant state, called $(4660)$ (formerly known as $Y(4660)$), observed also in other final states. The BESIII dataset has shown a different trend, with a flat cross section. We propose a new solution to fit bot&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.06306v2-abstract-full').style.display = 'inline'; document.getElementById('2005.06306v2-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="2005.06306v2-abstract-full" style="display: none;">
        There are two available set of data on the $e^+e^- \rightarrow ^+_c \bar_c^-$ cross section above threshold. The BELLE measurement, with ISR return, is compatible with the presence of a resonant state, called $(4660)$ (formerly known as $Y(4660)$), observed also in other final states. The BESIII dataset has shown a different trend, with a flat cross section. We propose a new solution to fit both datasets by means of a strong correction to the Coulomb enhancement factor. Mass and width of the resonant state is extracted.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('2005.06306v2-abstract-full').style.display = 'none'; document.getElementById('2005.06306v2-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 15 November, 2021; <span class="has-text-black-bis has-text-weight-semibold">v1</span> submitted 13 May, 2020;
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> May 2020.
      
    </p>
    
    <p class="comments is-size-7">
      <span class="has-text-black-bis has-text-weight-semibold">Comments:</span>
      <span class="has-text-grey-dark mathjax">Found a bug in the present version of the work that lead to drawing incorrect conclusions in the discussion of the results</span>
    </p>
    

    

    
  </li>

  <li class="arxiv-result">
    <div class="is-marginless">
      <p class="list-title is-inline-block"><a href="https://arxiv.org/abs/1901.10982">arXiv:1901.10982</a>
        <span>&nbsp;[<a href="https://arxiv.org/pdf/1901.10982">pdf</a>, <a href="https://arxiv.org/format/1901.10982">other</a>]&nbsp;</span>
      </p>
      <div class="tags is-inline-block">
        <span class="tag is-small is-link tooltip is-tooltip-top" data-tooltip="Emerging Technologies">cs.ET</span>
        
          
            <span class="tag is-small is-grey tooltip is-tooltip-top" data-tooltip="Quantum Physics">quant-ph</span>
          
        </div>
      
    </div>
    
    <p class="title is-5 mathjax">
      
        A QUBO Model for Gaussian Process Variance Reduction
      
    </p>
    <p class="authors">
      <span class="search-hit">Authors:</span>
      
      <a href="/search/?searchtype=author&amp;query=Bottarelli%2C+L">Lorenzo Bottarelli</a>, 
      
      <a href="/search/?searchtype=author&amp;query=Farinelli%2C+A">Alessandro Farinelli</a>
      
    </p>
    
    <p class="abstract mathjax">
      <span class="has-text-black-bis has-text-weight-semibold">Abstract</span>:
      <span class="abstract-short has-text-grey-dark mathjax" id="1901.10982v1-abstract-short" style="display: inline;">
        Gaussian Processes are used in many applications to model spatial phenomena. Within this context, a key issue is to decide the set of locations where to take measurements so as to obtain a better approximation of the underlying function. Current state of the art techniques select such set to minimize the posterior variance of the Gaussian process. We explore the feasibility of solving this problem&hellip;
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1901.10982v1-abstract-full').style.display = 'inline'; document.getElementById('1901.10982v1-abstract-short').style.display = 'none';">&#9661; More</a>
      </span>
      <span class="abstract-full has-text-grey-dark mathjax" id="1901.10982v1-abstract-full" style="display: none;">
        Gaussian Processes are used in many applications to model spatial phenomena. Within this context, a key issue is to decide the set of locations where to take measurements so as to obtain a better approximation of the underlying function. Current state of the art techniques select such set to minimize the posterior variance of the Gaussian process. We explore the feasibility of solving this problem by proposing a novel Quadratic Unconstrained Binary Optimization (QUBO) model. In recent years this QUBO formulation has gained increasing attention since it represents the input for the specialized quantum annealer D-Wave machines. Hence, our contribution takes an important first step towards the sampling optimization of Gaussian processes in the context of quantum computation. Results of our empirical evaluation shows that the optimum of the QUBO objective function we derived represents a good solution for the above mentioned problem. In fact we are able to obtain comparable and in some cases better results than the widely used submodular technique.
        <a class="is-size-7" style="white-space: nowrap;" onclick="document.getElementById('1901.10982v1-abstract-full').style.display = 'none'; document.getElementById('1901.10982v1-abstract-short').style.display = 'inline';">&#9651; Less</a>
      </span>
    </p>
    

    <p class="is-size-7"><span class="has-text-black-bis has-text-weight-semibold">Submitted</span> 30 January, 2019; 
      <span class="has-text-black-bis has-text-weight-semibold">originally announced</span> January 2019.
      
    </p>
    

    

    
  </li>

</ol>


  <nav class="pagination is-small is-centered breathe-horizontal" role="navigation" aria-label="pagination">
    
    <a href=""
      class="pagination-previous is-invisible">Previous
    </a>
    
    
      <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
        class="pagination-next" >Next
      </a>
    
    <ul class="pagination-list">

      <li>
        <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=0"
          class="pagination-link is-current"
          aria-label="Goto page 1">1
        </a>
      </li>

      
        
        <li>
          <a href="/search/?query=Alessandro+Farinelli&amp;searchtype=author&amp;abstracts=show&amp;order=-announced_date_first&amp;size=50&amp;start=50"
            class="pagination-link "
            aria-label="Page 2"
            aria-current="page">2
          </a>
        </li>
        
      
    </ul>
  </nav>
  

  


      <div class="is-hidden-tablet">
        <!-- feedback for mobile only -->
        <span class="help" style="display: inline-block;"><a href="https://github.com/arXiv/arxiv-search/releases">Search v0.5.6 released 2020-02-24</a>&nbsp;&nbsp;</span>
      </div>
    </div>

  </main>
  <footer>
    
    <div class="columns is-desktop" role="navigation" aria-label="Secondary">
  <!-- MetaColumn 1 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/about">About</a></li>
          <li><a href="https://info.arxiv.org/help">Help</a></li>
        </ul>
      </div>
      <div class="column">
        <ul class="nav-spaced">
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>contact arXiv</title><desc>Click here to contact arXiv</desc><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>
            <a href="https://info.arxiv.org/help/contact.html"> Contact</a>
          </li>
          <li>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><title>subscribe to arXiv mailings</title><desc>Click here to subscribe</desc><path d="M476 3.2L12.5 270.6c-18.1 10.4-15.8 35.6 2.2 43.2L121 358.4l287.3-253.2c5.5-4.9 13.3 2.6 8.6 8.3L176 407v80.5c0 23.6 28.5 32.9 42.5 15.8L282 426l124.6 52.2c14.2 6 30.4-2.9 33-18.2l72-432C515 7.8 493.3-6.8 476 3.2z"/></svg>
            <a href="https://info.arxiv.org/help/subscribe"> Subscribe</a>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 1 -->
  <!-- MetaColumn 2 -->
  <div class="column">
    <div class="columns">
      <div class="column">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/license/index.html">Copyright</a></li>
          <li><a href="https://info.arxiv.org/help/policies/privacy_policy.html">Privacy Policy</a></li>
        </ul>
      </div>
      <div class="column sorry-app-links">
        <ul class="nav-spaced">
          <li><a href="https://info.arxiv.org/help/web_accessibility.html">Web Accessibility Assistance</a></li>
          <li>
            <p class="help">
              <a class="a11y-main-link" href="https://status.arxiv.org" target="_blank">arXiv Operational Status <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 512" class="icon filter-dark_grey" role="presentation"><path d="M224.3 273l-136 136c-9.4 9.4-24.6 9.4-33.9 0l-22.6-22.6c-9.4-9.4-9.4-24.6 0-33.9l96.4-96.4-96.4-96.4c-9.4-9.4-9.4-24.6 0-33.9L54.3 103c9.4-9.4 24.6-9.4 33.9 0l136 136c9.5 9.4 9.5 24.6.1 34z"/></svg></a><br>
              Get status notifications via
              <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/email/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" class="icon filter-black" role="presentation"><path d="M502.3 190.8c3.9-3.1 9.7-.2 9.7 4.7V400c0 26.5-21.5 48-48 48H48c-26.5 0-48-21.5-48-48V195.6c0-5 5.7-7.8 9.7-4.7 22.4 17.4 52.1 39.5 154.1 113.6 21.1 15.4 56.7 47.8 92.2 47.6 35.7.3 72-32.8 92.3-47.6 102-74.1 131.6-96.3 154-113.7zM256 320c23.2.4 56.6-29.2 73.4-41.4 132.7-96.3 142.8-104.7 173.4-128.7 5.8-4.5 9.2-11.5 9.2-18.9v-19c0-26.5-21.5-48-48-48H48C21.5 64 0 85.5 0 112v19c0 7.4 3.4 14.3 9.2 18.9 30.6 23.9 40.7 32.4 173.4 128.7 16.8 12.2 50.2 41.8 73.4 41.4z"/></svg>email</a>
              or <a class="is-link" href="https://subscribe.sorryapp.com/24846f03/slack/new" target="_blank"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" class="icon filter-black" role="presentation"><path d="M94.12 315.1c0 25.9-21.16 47.06-47.06 47.06S0 341 0 315.1c0-25.9 21.16-47.06 47.06-47.06h47.06v47.06zm23.72 0c0-25.9 21.16-47.06 47.06-47.06s47.06 21.16 47.06 47.06v117.84c0 25.9-21.16 47.06-47.06 47.06s-47.06-21.16-47.06-47.06V315.1zm47.06-188.98c-25.9 0-47.06-21.16-47.06-47.06S139 32 164.9 32s47.06 21.16 47.06 47.06v47.06H164.9zm0 23.72c25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06H47.06C21.16 243.96 0 222.8 0 196.9s21.16-47.06 47.06-47.06H164.9zm188.98 47.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06s-21.16 47.06-47.06 47.06h-47.06V196.9zm-23.72 0c0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06V79.06c0-25.9 21.16-47.06 47.06-47.06 25.9 0 47.06 21.16 47.06 47.06V196.9zM283.1 385.88c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06-25.9 0-47.06-21.16-47.06-47.06v-47.06h47.06zm0-23.72c-25.9 0-47.06-21.16-47.06-47.06 0-25.9 21.16-47.06 47.06-47.06h117.84c25.9 0 47.06 21.16 47.06 47.06 0 25.9-21.16 47.06-47.06 47.06H283.1z"/></svg>slack</a>
            </p>
          </li>
        </ul>
      </div>
    </div>
  </div> <!-- end MetaColumn 2 -->
</div>
    
  </footer>
  <script src="https://static.arxiv.org/static/base/1.0.0a5/js/member_acknowledgement.js"></script>
  </body>
</html>