{
  "author": "Renate Schmidt",
  "results": [
    {
      "title": "GenOM: Ontology Matching with Description Generation and Large Language Model",
      "abstract": "Ontology matching (OM) plays an essential role in enabling semantic interoperability and integration across heterogeneous knowledge sources, particularly in the biomedical domain which contains numerous complex concepts related to diseases and pharmaceuticals. This paper introduces GenOM, a large language model (LLM)-based ontology alignment framework, which enriches the semantic representations of ontology concepts via generating textual definitions, retrieves alignment candidates with an embedding model, and incorporates exact matching-based tools to improve precision. Extensive experiments conducted on the OAEI Bio-ML track demonstrate that GenOM can often achieve competitive performance, surpassing many baselines including traditional OM systems and recent LLM-based methods. Further ablation studies confirm the effectiveness of semantic enrichment and few-shot prompting, highlighting the framework's robustness and adaptability. △ Less",
      "url": "https://arxiv.org/abs/2508.10703"
    },
    {
      "title": "Computing Witnesses Using the SCAN Algorithm (Extended Preprint)",
      "abstract": "Second-order quantifier-elimination is the problem of finding, given a formula with second-order quantifiers, a logically equivalent first-order formula. While such formulas are not computable in general, there are practical algorithms and subclasses with applications throughout computational logic. One of the most prominent algorithms for second-order quantifier elimination is the SCAN algorithm which is based on saturation theorem proving. In this paper we show how the SCAN algorithm on clause sets can be extended to solve a more general problem: namely, finding an instance of the second-order quantifiers that results in a logically equivalent first-order formula. In addition we provide a prototype implementation of the proposed method. This work paves the way for applying the SCAN algorithm to new problems in application domains such as modal correspondence theory, knowledge representation, and verification. △ Less",
      "url": "https://arxiv.org/abs/2506.00163"
    },
    {
      "title": "Saturation-based Boolean conjunctive query answering and rewriting for the guarded quantification fragments",
      "abstract": "Query answering is an important problem in AI, database and knowledge representation. In this paper, we develop saturation-based Boolean conjunctive query answering and rewriting procedures for the guarded, the loosely guarded and the clique-guarded fragments. Our query answering procedure improves existing resolution-based decision procedures for the guarded and the loosely guarded fragments and this procedure solves Boolean conjunctive query answering problems for the guarded, the loosely guarded and the clique-guarded fragments. Based on this query answering procedure, we also introduce a novel saturation-based query rewriting procedure for these guarded fragments. Unlike mainstream query answering and rewriting methods, our procedures derive a compact and reusable saturation, namely a closure of formulas, to handle the challenge of querying for distributed datasets. This paper lays the theoretical foundations for the first automated deduction decision procedures for Boolean conjunctive query answering and the first saturation-based Boolean conjunctive query rewriting in the guarded, the loosely guarded and the clique-guarded fragments. △ Less",
      "url": "https://arxiv.org/abs/2208.05365"
    },
    {
      "title": "Signature-Based Abduction for Expressive Description Logics -- Technical Report",
      "abstract": "Signature-based abduction aims at building hypotheses over a specified set of names, the signature, that explain an observation relative to some background knowledge. This type of abduction is useful for tasks such as diagnosis, where the vocabulary used for observed symptoms differs from the vocabulary expected to explain those symptoms. We present the first complete method solving signature-based abduction for observations expressed in the expressive description logic ALC, which can include TBox and ABox axioms, thereby solving the knowledge base abduction problem. The method is guaranteed to compute a finite and complete set of hypotheses, and is evaluated on a set of realistic knowledge bases. △ Less",
      "url": "https://arxiv.org/abs/2007.00757"
    },
    {
      "title": "Querying Guarded Fragments via Resolution",
      "abstract": "Answering Boolean conjunctive queries over the guarded fragment is decidable, however, as yet no practical decision procedure exists. Meanwhile, ordered resolution, as a practically oriented algorithm, is widely used in state-of-art modern theorem provers. In this paper, we devise a resolution decision procedure, which not only proves decidability of querying of the guarded fragment, but is implementable in any `off-the-shelf' resolution theorem prover with modest effort. Further, we extend the procedure to querying the loosely guarded fragment. The difficulty in querying a knowledge base of (loosely) guarded clauses is that query clauses are not guarded. We show however there are ways to reformulate query clauses into (loosely) guarded clauses either directly via the separation and splitting rules, or via performing inferences using our top-variable inference system combining with a form of dynamic renaming. Therefore, the problem of querying the (loosely) guarded fragment can be reduced to deciding the (loosely) guarded fragment and possibly irreducible query clauses, i.e., a clause that cannot derive any new conclusion. Meanwhile, our procedure yields a goal-oriented query rewriting algorithm: Before introducing datasets, one can produce a saturated clausal set $\\mathcal{S}$ using given BCQs and (loosely) guarded theories. Clauses in $\\mathcal{S}$ can be easily transformed first-order queries, therefore query answering over the (loosely) guarded fragment is reduced to evaluating a union of first-order queries over datasets. As far as we know, this is the first practical decision procedure for answering and rewriting Boolean conjunctive queries over the guarded fragment and the loosely guarded fragment. △ Less",
      "url": "https://arxiv.org/abs/2002.02228"
    },
    {
      "title": "Deciding the Loosely Guarded Fragment and Querying Its Horn Fragment Using Resolution",
      "abstract": "We consider the following query answering problem: Given a Boolean conjunctive query and a theory in the Horn loosely guarded fragment, the aim is to determine whether the query is entailed by the theory. In this paper, we present a resolution decision procedure for the loosely guarded fragment, and use such a procedure to answer Boolean conjunctive queries against the Horn loosely guarded fragment. The Horn loosely guarded fragment subsumes classes of rules that are prevalent in ontology-based query answering, such as Horn ALCHOI and guarded existential rules. Additionally, we identify star queries and cloud queries, which using our procedure, can be answered against the loosely guarded fragment. △ Less",
      "url": "https://arxiv.org/abs/2001.03829"
    },
    {
      "title": "ABox Abduction via Forgetting in ALC (Long Version)",
      "abstract": "Abductive reasoning generates explanatory hypotheses for new observations using prior knowledge. This paper investigates the use of forgetting, also known as uniform interpolation, to perform ABox abduction in description logic (ALC) ontologies. Non-abducibles are specified by a forgetting signature which can contain concept, but not role, symbols. The resulting hypotheses are semantically minimal and each consist of a set of disjuncts. These disjuncts are each independent explanations, and are not redundant with respect to the background ontology or the other disjuncts, representing a form of hypothesis space. The observations and hypotheses handled by the method can contain both atomic or complex ALC concepts, excluding role assertions, and are not restricted to Horn clauses. Two approaches to redundancy elimination are explored for practical use: full and approximate. Using a prototype implementation, experiments were performed over a corpus of real world ontologies to investigate the practicality of both approaches across several settings. △ Less",
      "url": "https://arxiv.org/abs/1811.05420"
    },
    {
      "title": "Blocking and Other Enhancements for Bottom-Up Model Generation Methods",
      "abstract": "Model generation is a problem complementary to theorem proving and is important for fault analysis and debugging of formal specifications of security protocols, programs and terminological definitions. This paper discusses several ways of enhancing the paradigm of bottom-up model generation. The two main contributions are new, generalized blocking techniques and a new range-restriction transformation. The blocking techniques are based on simple transformations of the input set together with standard equality reasoning and redundancy elimination techniques. These provide general methods for finding small, finite models. The range-restriction transformation refines existing transformations to range-restricted clauses by carefully limiting the creation of domain terms. All possible combinations of the introduced techniques and classical range-restriction were tested on the clausal problems of the TPTP Version 6.0.0 with an implementation based on the SPASS theorem prover using a hyperresolution-like refinement. Unrestricted domain blocking gave best results for satisfiable problems showing it is a powerful technique indispensable for bottom-up model generation methods. Both in combination with the new range-restricting transformation, and the classical range-restricting transformation, good results have been obtained. Limiting the creation of terms during the inference process by using the new range restricting transformation has paid off, especially when using it together with a shifting transformation. The experimental results also show that classical range restriction with unrestricted blocking provides a useful complementary method. Overall, the results showed bottom-up model generation methods were good for disproving theorems and generating models for satisfiable problems, but less efficient than SPASS in auto mode for unsatisfiable problems. △ Less",
      "url": "https://arxiv.org/abs/1611.09014"
    },
    {
      "title": "Lifting QBF Resolution Calculi to DQBF",
      "abstract": "We examine the existing Resolution systems for quantified Boolean formulas (QBF) and answer the question which of these calculi can be lifted to the more powerful Dependency QBFs (DQBF). An interesting picture emerges: While for QBF we have the strict chain of proof systems Q-Resolution < IR-calc < IRM-calc, the situation is quite different in DQBF. Q-Resolution and likewise universal Resolution are too weak: they are not complete. IR-calc has the right strength: it is sound and complete. IRM-calc is too strong: it is not sound any more, and the same applies to long-distance Resolution. Conceptually, we use the relation of DQBF to EPR and explain our new DQBF calculus based on IR-calc as a subsystem of FO-Resolution. △ Less",
      "url": "https://arxiv.org/abs/1604.08058"
    },
    {
      "title": "Refinement in the Tableau Synthesis Framework",
      "abstract": "This paper is concerned with the possibilities of refining and improving calculi generated in the tableau synthesis framework. A general method in the tableau synthesis framework allows to reduce the branching factor of tableau rules and preserves completeness if a general rule refinement condition holds. In this paper we consider two approaches to satisfy this general rule refinement condition. △ Less",
      "url": "https://arxiv.org/abs/1305.3131"
    },
    {
      "title": "Using Tableau to Decide Description Logics with Full Role Negation and Identity",
      "abstract": "This paper presents a tableau approach for deciding expressive description logics with full role negation and role identity. We consider the description logic ALBOid, which is the extension of ALC with the Boolean role operators, inverse of roles, the identity role, and includes full support for individuals and singleton concepts. ALBOid is expressively equivalent to the two-variable fragment of first-order logic with equality and subsumes Boolean modal logic. In this paper we define a sound and complete tableau calculus for the ALBOid that provides a basis for decision procedures for this logic and all its sublogics. An important novelty of our approach is the use of a generic unrestricted blocking mechanism. Being based on a conceptually simple rule, unrestricted blocking performs case distinctions over whether two individuals are equal or not and equality reasoning to find finite models. The blocking mechanism ties the proof of termination of tableau derivations to the finite model property of ALBOid. △ Less",
      "url": "https://arxiv.org/abs/1208.1476"
    },
    {
      "title": "Automated Synthesis of Tableau Calculi",
      "abstract": "This paper presents a method for synthesising sound and complete tableau calculi. Given a specification of the formal semantics of a logic, the method generates a set of tableau inference rules that can then be used to reason within the logic. The method guarantees that the generated rules form a calculus which is sound and constructively complete. If the logic can be shown to admit finite filtration with respect to a well-defined first-order semantics then adding a general blocking mechanism provides a terminating tableau calculus. The process of generating tableau rules can be completely automated and produces, together with the blocking mechanism, an automated procedure for generating tableau decision procedures. For illustration we show the workability of the approach for a description logic with transitive roles and propositional intuitionistic logic. △ Less",
      "url": "https://arxiv.org/abs/1104.4131"
    }
  ]
}