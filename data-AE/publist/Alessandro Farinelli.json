{
  "author": "Alessandro Farinelli",
  "results": [
    {
      "title": "Probabilistically Tightened Linear Relaxation-based Perturbation Analysis for Neural Network Verification",
      "abstract": "We present $\\textbf{P}$robabilistically $\\textbf{T}$ightened $\\textbf{Li}$near $\\textbf{R}$elaxation-based $\\textbf{P}$erturbation $\\textbf{A}$nalysis ($\\texttt{PT-LiRPA}$), a novel framework that combines over-approximation techniques from LiRPA-based approaches with a sampling-based method to compute tight intermediate reachable sets. In detail, we show that with negligible computational overhead, $\\texttt{PT-LiRPA}$ exploiting the estimated reachable sets, significantly tightens the lower and upper linear bounds of a neural network's output, reducing the computational cost of formal verification tools while providing probabilistic guarantees on verification soundness. Extensive experiments on standard formal verification benchmarks, including the International Verification of Neural Networks Competition, show that our $\\texttt{PT-LiRPA}$-based verifier improves robustness certificates by up to 3.31X and 2.26X compared to related work. Importantly, our probabilistic approach results in a valuable solution for challenging competition entries where state-of-the-art formal verification methods fail, allowing us to provide answers with high confidence (i.e., at least 99%). △ Less",
      "url": "https://arxiv.org/abs/2507.05405"
    },
    {
      "title": "Observatory Science with eXTP",
      "abstract": "Scheduled for launch in 2030, the enhanced X-ray Timing and Polarization (eXTP) telescope is a Chinese space-based mission aimed at studying extreme conditions and phenomena in astrophysics. eXTP will feature three main payloads: Spectroscopy Focusing Arrays (SFAs), Polarimetry Focusing Arrays (PFAs), and a Wide-field Camera (W2C). This white paper outlines observatory science, incorporating key scientific advances and instrumental changes since the publication of the previous white paper [1]. We will discuss perspectives of eXTP on the research domains of flare stars, supernova remnants, pulsar wind nebulae, cataclysmic variables, X-ray binaries, ultraluminous X-ray sources, AGN, and pulsar-based positioning and timekeeping. △ Less",
      "url": "https://arxiv.org/abs/2506.08367"
    },
    {
      "title": "Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation",
      "abstract": "Traditional methods for formal verification (FV) of deep neural networks (DNNs) are constrained by a binary encoding of safety properties, where a model is classified as either safe or unsafe (robust or not robust). This binary encoding fails to capture the nuanced safety levels within a model, often resulting in either overly restrictive or too permissive requirements. In this paper, we introduce a novel problem formulation called Abstract DNN-Verification, which verifies a hierarchical structure of unsafe outputs, providing a more granular analysis of the safety aspect for a given DNN. Crucially, by leveraging abstract interpretation and reasoning about output reachable sets, our approach enables assessing multiple safety levels during the FV process, requiring the same (in the worst case) or even potentially less computational effort than the traditional binary verification approach. Specifically, we demonstrate how this formulation allows rank adversarial inputs according to their abstract safety level violation, offering a more detailed evaluation of the model's safety and robustness. Our contributions include a theoretical exploration of the relationship between our novel abstract safety formulation and existing approaches that employ abstract interpretation for robustness verification, complexity analysis of the novel problem introduced, and an empirical evaluation considering both a complex deep reinforcement learning task (based on Habitat 3.0) and standard DNN-Verification benchmarks. △ Less",
      "url": "https://arxiv.org/abs/2505.05235"
    },
    {
      "title": "Learning Symbolic Persistent Macro-Actions for POMDP Solving Over Time",
      "abstract": "This paper proposes an integration of temporal logical reasoning and Partially Observable Markov Decision Processes (POMDPs) to achieve interpretable decision-making under uncertainty with macro-actions. Our method leverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus (EC) to generate \\emph{persistent} (i.e., constant) macro-actions, which guide Monte Carlo Tree Search (MCTS)-based POMDP solvers over a time horizon, significantly reducing inference time while ensuring robust performance. Such macro-actions are learnt via Inductive Logic Programming (ILP) from a few traces of execution (belief-action pairs), thus eliminating the need for manually designed heuristics and requiring only the specification of the POMDP transition model. In the Pocman and Rocksample benchmark scenarios, our learned macro-actions demonstrate increased expressiveness and generality when compared to time-independent heuristics, indeed offering substantial computational efficiency improvements. △ Less",
      "url": "https://arxiv.org/abs/2505.03668"
    },
    {
      "title": "Designing Control Barrier Function via Probabilistic Enumeration for Safe Reinforcement Learning Navigation",
      "abstract": "Achieving safe autonomous navigation systems is critical for deploying robots in dynamic and uncertain real-world environments. In this paper, we propose a hierarchical control framework leveraging neural network verification techniques to design control barrier functions (CBFs) and policy correction mechanisms that ensure safe reinforcement learning navigation policies. Our approach relies on probabilistic enumeration to identify unsafe regions of operation, which are then used to construct a safe CBF-based control layer applicable to arbitrary policies. We validate our framework both in simulation and on a real robot, using a standard mobile robot benchmark and a highly dynamic aquatic environmental monitoring task. These experiments demonstrate the ability of the proposed solution to correct unsafe actions while preserving efficient navigation behavior. Our results show the promise of developing hierarchical verification-based systems to enable safe and robust navigation behaviors in complex scenarios. △ Less",
      "url": "https://arxiv.org/abs/2504.21643"
    },
    {
      "title": "Depth-Constrained ASV Navigation with Deep RL and Limited Sensing",
      "abstract": "Autonomous Surface Vehicles (ASVs) play a crucial role in maritime operations, yet their navigation in shallow-water environments remains challenging due to dynamic disturbances and depth constraints. Traditional navigation strategies struggle with limited sensor information, making safe and efficient operation difficult. In this paper, we propose a reinforcement learning (RL) framework for ASV navigation under depth constraints, where the vehicle must reach a target while avoiding unsafe areas with only a single depth measurement per timestep from a downward-facing Single Beam Echosounder (SBES). To enhance environmental awareness, we integrate Gaussian Process (GP) regression into the RL framework, enabling the agent to progressively estimate a bathymetric depth map from sparse sonar readings. This approach improves decision-making by providing a richer representation of the environment. Furthermore, we demonstrate effective sim-to-real transfer, ensuring that trained policies generalize well to real-world aquatic conditions. Experimental results validate our method's capability to improve ASV navigation performance while maintaining safety in challenging shallow-water environments. △ Less",
      "url": "https://arxiv.org/abs/2504.18253"
    },
    {
      "title": "Sentinel: Multi-Patch Transformer with Temporal and Channel Attention for Time Series Forecasting",
      "abstract": "Transformer-based time series forecasting has recently gained strong interest due to the ability of transformers to model sequential data. Most of the state-of-the-art architectures exploit either temporal or inter-channel dependencies, limiting their effectiveness in multivariate time-series forecasting where both types of dependencies are crucial. We propose Sentinel, a full transformer-based architecture composed of an encoder able to extract contextual information from the channel dimension, and a decoder designed to capture causal relations and dependencies across the temporal dimension. Additionally, we introduce a multi-patch attention mechanism, which leverages the patching process to structure the input sequence in a way that can be naturally integrated into the transformer architecture, replacing the multi-head splitting process. Extensive experiments on standard benchmarks demonstrate that Sentinel, because of its ability to \"monitor\" both the temporal and the inter-channel dimension, achieves better or comparable performance with respect to state-of-the-art approaches. △ Less",
      "url": "https://arxiv.org/abs/2503.17658"
    },
    {
      "title": "Seldonian Reinforcement Learning for Ad Hoc Teamwork",
      "abstract": "Most offline RL algorithms return optimal policies but do not provide statistical guarantees on desirable behaviors. This could generate reliability issues in safety-critical applications, such as in some multiagent domains where agents, and possibly humans, need to interact to reach their goals without harming each other. In this work, we propose a novel offline RL approach, inspired by Seldonian optimization, which returns policies with good performance and statistically guaranteed properties with respect to predefined desirable behaviors. In particular, our focus is on Ad Hoc Teamwork settings, where agents must collaborate with new teammates without prior coordination. Our method requires only a pre-collected dataset, a set of candidate policies for our agent, and a specification about the possible policies followed by the other players -- it does not require further interactions, training, or assumptions on the type and architecture of the policies. We test our algorithm in Ad Hoc Teamwork problems and show that it consistently finds reliable policies while improving sample efficiency with respect to standard ML baselines. △ Less",
      "url": "https://arxiv.org/abs/2503.03885"
    },
    {
      "title": "Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments",
      "abstract": "Online motion planning is a challenging problem for intelligent robots moving in dense environments with dynamic obstacles, e.g., crowds. In this work, we propose a novel approach for optimal and safe online motion planning with minimal information about dynamic obstacles. Specifically, our approach requires only the current position of the obstacles and their maximum speed, but it does not need any information about their exact trajectories or dynamic model. The proposed methodology combines Monte Carlo Tree Search (MCTS), for online optimal planning via model simulations, with Velocity Obstacles (VO), for obstacle avoidance. We perform experiments in a cluttered simulated environment with walls, and up to 40 dynamic obstacles moving with random velocities and directions. With an ablation study, we show the key contribution of VO in scaling up the efficiency of MCTS, selecting the safest and most rewarding actions in the tree of simulations. Moreover, we show the superiority of our methodology with respect to state-of-the-art planners, including Non-linear Model Predictive Control (NMPC), in terms of improved collision rate, computational and task performance. △ Less",
      "url": "https://arxiv.org/abs/2501.09649"
    },
    {
      "title": "Online inductive learning from answer sets for efficient reinforcement learning exploration",
      "abstract": "This paper presents a novel approach combining inductive logic programming with reinforcement learning to improve training performance and explainability. We exploit inductive learning of answer set programs from noisy examples to learn a set of logical rules representing an explainable approximation of the agent policy at each batch of experience. We then perform answer set reasoning on the learned rules to guide the exploration of the learning agent at the next batch, without requiring inefficient reward shaping and preserving optimality with soft bias. The entire procedure is conducted during the online execution of the reinforcement learning algorithm. We preliminarily validate the efficacy of our approach by integrating it into the Q-learning algorithm for the Pac-Man scenario in two maps of increasing complexity. Our methodology produces a significant boost in the discounted return achieved by the agent, even in the first batches of training. Moreover, inductive learning does not compromise the computational time required by Q-learning and learned rules quickly converge to an explanation of the agent policy. △ Less",
      "url": "https://arxiv.org/abs/2501.07445"
    },
    {
      "title": "Collaborative Instance Object Navigation: Leveraging Uncertainty-Awareness to Minimize Human-Agent Dialogues",
      "abstract": "Language-driven instance object navigation assumes that human users initiate the task by providing a detailed description of the target instance to the embodied agent. While this description is crucial for distinguishing the target from visually similar instances in a scene, providing it prior to navigation can be demanding for human. To bridge this gap, we introduce Collaborative Instance object Navigation (CoIN), a new task setting where the agent actively resolve uncertainties about the target instance during navigation in natural, template-free, open-ended dialogues with human. We propose a novel training-free method, Agent-user Interaction with UncerTainty Awareness (AIUTA), which operates independently from the navigation policy, and focuses on the human-agent interaction reasoning with Vision-Language Models (VLMs) and Large Language Models (LLMs). First, upon object detection, a Self-Questioner model initiates a self-dialogue within the agent to obtain a complete and accurate observation description with a novel uncertainty estimation technique. Then, an Interaction Trigger module determines whether to ask a question to the human, continue or halt navigation, minimizing user input. For evaluation, we introduce CoIN-Bench, with a curated dataset designed for challenging multi-instance scenarios. CoIN-Bench supports both online evaluation with humans and reproducible experiments with simulated user-agent interactions. On CoIN-Bench, we show that AIUTA serves as a competitive baseline, while existing language-driven instance navigation methods struggle in complex multi-instance scenes. Code and benchmark will be available upon acceptance at https://intelligolabs.github.io/CoIN/ △ Less",
      "url": "https://arxiv.org/abs/2412.01250"
    },
    {
      "title": "The IXPE View of Neutron Star Low-Mass X-ray Binaries",
      "abstract": "Low-mass X-ray binaries hosting weakly magnetized neutron stars (NS-LMXBs) are among the brightest sources in the X-ray sky. Since 2021, the Imaging X-ray Polarimetry Explorer (IXPE) has provided new measurements of the X-ray polarization of these sources. IXPE observations have revealed that most NS-LMXBs are significantly polarized in the X-rays, providing unprecedented insight into the geometry of their accretion flow. In this review paper, we summarize the first results obtained by IXPE on NS-LMXBs, the emerging trends within each class of sources (atoll/Z), and possible physical interpretations. △ Less",
      "url": "https://arxiv.org/abs/2409.07161"
    },
    {
      "title": "Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations",
      "abstract": "We study the problem of assessing the robustness of counterfactual explanations for deep learning models. We focus on $\\textit{plausible model shifts}$ altering model parameters and propose a novel framework to reason about the robustness property in this setting. To motivate our solution, we begin by showing for the first time that computing the robustness of counterfactuals with respect to plausible model shifts is NP-complete. As this (practically) rules out the existence of scalable algorithms for exactly computing robustness, we propose a novel probabilistic approach which is able to provide tight estimates of robustness with strong guarantees while preserving scalability. Remarkably, and differently from existing solutions targeting plausible model shifts, our approach does not impose requirements on the network to be analyzed, thus enabling robustness analysis on a wider range of architectures. Experiments on four binary classification datasets indicate that our method improves the state of the art in generating robust explanations, outperforming existing methods on a range of metrics. △ Less",
      "url": "https://arxiv.org/abs/2407.07482"
    },
    {
      "title": "I2EDL: Interactive Instruction Error Detection and Localization",
      "abstract": "In the Vision-and-Language Navigation in Continuous Environments (VLN-CE) task, the human user guides an autonomous agent to reach a target goal via a series of low-level actions following a textual instruction in natural language. However, most existing methods do not address the likely case where users may make mistakes when providing such instruction (e.g. \"turn left\" instead of \"turn right\"). In this work, we address a novel task of Interactive VLN in Continuous Environments (IVLN-CE), which allows the agent to interact with the user during the VLN-CE navigation to verify any doubts regarding the instruction errors. We propose an Interactive Instruction Error Detector and Localizer (I2EDL) that triggers the user-agent interaction upon the detection of instruction errors during the navigation. We leverage a pre-trained module to detect instruction errors and pinpoint them in the instruction by cross-referencing the textual input and past observations. In such way, the agent is able to query the user for a timely correction, without demanding the user's cognitive load, as we locate the probable errors to a precise part of the instruction. We evaluate the proposed I2EDL on a dataset of instructions containing errors, and further devise a novel metric, the Success weighted by Interaction Number (SIN), to reflect both the navigation performance and the interaction effectiveness. We show how the proposed method can ask focused requests for corrections to the user, which in turn increases the navigation success, while minimizing the interactions. △ Less",
      "url": "https://arxiv.org/abs/2406.05080"
    },
    {
      "title": "Aquatic Navigation: A Challenging Benchmark for Deep Reinforcement Learning",
      "abstract": "An exciting and promising frontier for Deep Reinforcement Learning (DRL) is its application to real-world robotic systems. While modern DRL approaches achieved remarkable successes in many robotic scenarios (including mobile robotics, surgical assistance, and autonomous driving) unpredictable and non-stationary environments can pose critical challenges to such methods. These features can significantly undermine fundamental requirements for a successful training process, such as the Markovian properties of the transition model. To address this challenge, we propose a new benchmarking environment for aquatic navigation using recent advances in the integration between game engines and DRL. In more detail, we show that our benchmarking environment is problematic even for state-of-the-art DRL approaches that may struggle to generate reliable policies in terms of generalization power and safety. Specifically, we focus on PPO, one of the most widely accepted algorithms, and we propose advanced training techniques (such as curriculum learning and learnable hyperparameters). Our extensive empirical evaluation shows that a well-designed combination of these ingredients can achieve promising results. Our simulation environment and training baselines are freely available to facilitate further research on this open problem and encourage collaboration in the field. △ Less",
      "url": "https://arxiv.org/abs/2405.20534"
    },
    {
      "title": "Mind the Error! Detection and Localization of Instruction Errors in Vision-and-Language Navigation",
      "abstract": "Vision-and-Language Navigation in Continuous Environments (VLN-CE) is one of the most intuitive yet challenging embodied AI tasks. Agents are tasked to navigate towards a target goal by executing a set of low-level actions, following a series of natural language instructions. All VLN-CE methods in the literature assume that language instructions are exact. However, in practice, instructions given by humans can contain errors when describing a spatial environment due to inaccurate memory or confusion. Current VLN-CE benchmarks do not address this scenario, making the state-of-the-art methods in VLN-CE fragile in the presence of erroneous instructions from human users. For the first time, we propose a novel benchmark dataset that introduces various types of instruction errors considering potential human causes. This benchmark provides valuable insight into the robustness of VLN systems in continuous environments. We observe a noticeable performance drop (up to -25%) in Success Rate when evaluating the state-of-the-art VLN-CE methods on our benchmark. Moreover, we formally define the task of Instruction Error Detection and Localization, and establish an evaluation protocol on top of our benchmark dataset. We also propose an effective method, based on a cross-modal transformer architecture, that achieves the best performance in error detection and localization, compared to baselines. Surprisingly, our proposed method has revealed errors in the validation set of the two commonly used datasets for VLN-CE, i.e., R2R-CE and RxR-CE, demonstrating the utility of our technique in other tasks. Code and dataset available at https://intelligolabs.github.io/R2RIE-CE △ Less",
      "url": "https://arxiv.org/abs/2403.10700"
    },
    {
      "title": "Planning and Inverse Kinematics of Hyper-Redundant Manipulators with VO-FABRIK",
      "abstract": "Hyper-redundant Robotic Manipulators (HRMs) offer great dexterity and flexibility of operation, but solving Inverse Kinematics (IK) is challenging. In this work, we introduce VO-FABRIK, an algorithm combining Forward and Backward Reaching Inverse Kinematics (FABRIK) for repeatable deterministic IK computation, and an approach inspired from velocity obstacles to perform path planning under collision and joint limits constraints. We show preliminary results on an industrial HRM with 19 actuated joints. Our algorithm achieves good performance where a state-of-the-art IK solver fails. △ Less",
      "url": "https://arxiv.org/abs/2403.05399"
    },
    {
      "title": "Learning Logic Specifications for Policy Guidance in POMDPs: an Inductive Logic Programming Approach",
      "abstract": "Partially Observable Markov Decision Processes (POMDPs) are a powerful framework for planning under uncertainty. They allow to model state uncertainty as a belief probability distribution. Approximate solvers based on Monte Carlo sampling show great success to relax the computational demand and perform online planning. However, scaling to complex realistic domains with many actions and long planning horizons is still a major challenge, and a key point to achieve good performance is guiding the action-selection process with domain-dependent policy heuristics which are tailored for the specific application domain. We propose to learn high-quality heuristics from POMDP traces of executions generated by any solver. We convert the belief-action pairs to a logical semantics, and exploit data- and time-efficient Inductive Logic Programming (ILP) to generate interpretable belief-based policy specifications, which are then used as online heuristics. We evaluate thoroughly our methodology on two notoriously challenging POMDP problems, involving large action spaces and long planning horizons, namely, rocksample and pocman. Considering different state-of-the-art online POMDP solvers, including POMCP, DESPOT and AdaOPS, we show that learned heuristics expressed in Answer Set Programming (ASP) yield performance superior to neural networks and similar to optimal handcrafted task-specific heuristics within lower computational time. Moreover, they well generalize to more challenging scenarios not experienced in the training phase (e.g., increasing rocks and grid size in rocksample, incrementing the size of the map and the aggressivity of ghosts in pocman). △ Less",
      "url": "https://arxiv.org/abs/2402.19265"
    },
    {
      "title": "Analyzing Adversarial Inputs in Deep Reinforcement Learning",
      "abstract": "In recent years, Deep Reinforcement Learning (DRL) has become a popular paradigm in machine learning due to its successful applications to real-world and complex systems. However, even the state-of-the-art DRL models have been shown to suffer from reliability concerns -- for example, their susceptibility to adversarial inputs, i.e., small and abundant input perturbations that can fool the models into making unpredictable and potentially dangerous decisions. This drawback limits the deployment of DRL systems in safety-critical contexts, where even a small error cannot be tolerated. In this work, we present a comprehensive analysis of the characterization of adversarial inputs, through the lens of formal verification. Specifically, we introduce a novel metric, the Adversarial Rate, to classify models based on their susceptibility to such perturbations, and present a set of tools and algorithms for its computation. Our analysis empirically demonstrates how adversarial inputs can affect the safety of a given DRL system with respect to such perturbations. Moreover, we analyze the behavior of these configurations to suggest several useful practices and guidelines to help mitigate the vulnerability of trained DRL networks. △ Less",
      "url": "https://arxiv.org/abs/2402.05284"
    },
    {
      "title": "Scaling #DNN-Verification Tools with Efficient Bound Propagation and Parallel Computing",
      "abstract": "Deep Neural Networks (DNNs) are powerful tools that have shown extraordinary results in many scenarios, ranging from pattern recognition to complex robotic problems. However, their intricate designs and lack of transparency raise safety concerns when applied in real-world applications. In this context, Formal Verification (FV) of DNNs has emerged as a valuable solution to provide provable guarantees on the safety aspect. Nonetheless, the binary answer (i.e., safe or unsafe) could be not informative enough for direct safety interventions such as safety model ranking or selection. To address this limitation, the FV problem has recently been extended to the counting version, called #DNN-Verification, for the computation of the size of the unsafe regions in a given safety property's domain. Still, due to the complexity of the problem, existing solutions struggle to scale on real-world robotic scenarios, where the DNN can be large and complex. To address this limitation, inspired by advances in FV, in this work, we propose a novel strategy based on reachability analysis combined with Symbolic Linear Relaxation and parallel computing to enhance the efficiency of existing exact and approximate FV for DNN counters. The empirical evaluation on standard FV benchmarks and realistic robotic scenarios shows a remarkable improvement in scalability and efficiency, enabling the use of such techniques even for complex robotic applications. △ Less",
      "url": "https://arxiv.org/abs/2312.05890"
    },
    {
      "title": "Highly Significant Detection of X-Ray Polarization from the Brightest Accreting Neutron Star Sco X-1",
      "abstract": "The Imaging X-ray Polarimetry Explorer (IXPE) measured with high significance the X-ray polarization of the brightest Z-source Scorpius X-1, resulting in the nominal 2-8 keV energy band in a polarization degree of 1.0(0.2)% and a polarization angle of 8(6)° at 90% of confidence level. This observation was strictly simultaneous with observations performed by NICER, NuSTAR, and Insight-HXMT, which allowed for a precise characterization of its broad-band spectrum from soft to hard X-rays. The source has been observed mainly in its soft state, with short periods of flaring. We also observed low-frequency quasi-periodic oscillations. From a spectro-polarimetric analysis, we associate a polarization to the accretion disk at <3.2% at 90% of confidence level, compatible with expectations for an electron-scattering dominated optically thick atmosphere at the Sco X-1 inclination of 44°; for the higher-energy Comptonized component, we obtain a polarization of 1.3(0.4)%, in agreement with expectations for a slab of Thomson optical depth of ~7 and an electron temperature of ~3 keV. A polarization rotation with respect to previous observations by OSO-8 and PolarLight, and also with respect to the radio-jet position angle, is observed. This result may indicate a variation of the polarization with the source state that can be related to relativistic precession or to a change in the corona geometry with the accretion flow. △ Less",
      "url": "https://arxiv.org/abs/2311.06359"
    },
    {
      "title": "X-Ray Polarized View on the Accretion Geometry in the X-Ray Binary Circinus X-1",
      "abstract": "Cir X-1 is a neutron star X-ray binary characterized by strong variations in flux during its eccentric $\\sim$16.6 days orbit. There are also strong variations in the spectral state, and historically it has shown both atoll and Z state properties. We observed the source with the Imaging X-ray Polarimetry Explorer during two orbital segments, 6 days apart, for a total of 263~ks. We find an X-ray polarization degree in these segments of $1.6\\%\\pm0.3\\%$ and $1.4\\%\\pm0.3\\%$ at polarization angles of $37^\\circ\\pm5^\\circ$ and $-12^\\circ\\pm7^\\circ$, respectively. Thus we observed a rotation of the polarization angle by $49^\\circ\\pm8^\\circ$ along the orbit. Because variations of accretion flow, and then of the hardness ratio, are expected during the orbit, we also studied the polarization binned in hardness ratio, and found the polarization angle differing by $67^\\circ\\pm11^\\circ$ between the lowest and highest values of the hardness ratio. We discuss possible interpretations of this result that could indicate a possible misalignment between the symmetry axes of the accretion disk and the Comptonizing region caused by the misalignment of the neutron star's angular momentum with respect to the orbital one. △ Less",
      "url": "https://arxiv.org/abs/2311.04632"
    },
    {
      "title": "Normalizing flows as approximations of optimal transport maps via linear-control neural ODEs",
      "abstract": "In this paper, we consider the problem of recovering the $W_2$-optimal transport map T between absolutely continuous measures $μ,ν\\in\\mathcal{P}(\\mathbb{R}^n)$ as the flow of a linear-control neural ODE, where the control depends only on the time variable and takes values in a finite-dimensional space. We first show that, under suitable assumptions on $μ,ν$ and on the controlled vector fields governing the neural ODE, the optimal transport map is contained in the $C^0_c$-closure of the flows generated by the system. Then, we tackle the problem under the assumption that only discrete approximations of $μ_N,ν_N$ of the original measures $μ,ν$ are available: we formulate approximated optimal control problems, and we show that their solutions give flows that approximate the original optimal transport map $T$. In the framework of generative models, the approximating flow constructed here can be seen as a `Normalizing Flow', which usually refers to the task of providing invertible transport maps between probability measures by means of deep neural networks. We propose an iterative numerical scheme based on the Pontryagin Maximum Principle for the resolution of the optimal control problem, resulting in a method for the practical computation of the approximated optimal transport map, and we test it on a two-dimensional example. △ Less",
      "url": "https://arxiv.org/abs/2311.01404"
    },
    {
      "title": "Discovery of a variable energy-dependent X-ray polarization in the accreting neutron star GX 5-1",
      "abstract": "We report on the coordinated observations of the neutron star low-mass X-ray binary (NS-LMXB) \\gx in X-rays (IXPE, NICER, Nustar and INTEGRAL), optical (REM and LCO), near-infrared (REM), mid-infrared (VLT VISIR), and radio (ATCA). This Z-source was observed by \\IXPE twice in March-April 2023 (Obs. 1 and 2). In the radio band, the source was detected, but only upper-limits to the linear polarization were obtained at a $3σ$ level of $6.1\\%$ at 5.5 GHz and $5.9\\%$ at 9 GHz in Obs.~1 and $12.5\\%$ at 5.5~GHz and $20\\%$ at 9~GHz in Obs.~2. The mid-IR, near-IR and optical observations suggest the presence of a compact jet which peaks in the mid- or far-IR. The X-ray polarization degree was found to be $3.7\\% \\pm 0.4 \\%$ (at $90\\%$ confidence level) during Obs.~1 when the source was in the horizontal branch of the Z-track and $1.8\\% \\pm 0.4 \\%$ during Obs.~2 when the source was in the normal-flaring branch. These results confirm the variation of polarization degree as a function of the position of the source in the color-color diagram as for previously observed Z-track sources (Cyg~X-2 and XTE~1701$-$462). Evidence for a variation of the polarization angle $\\sim 20^\\circ$ with energy is found in both observations, likely related to the different, non-orthogonal polarization angles of the disk and Comptonization components which peak at different energies. △ Less",
      "url": "https://arxiv.org/abs/2310.06788"
    },
    {
      "title": "Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees",
      "abstract": "Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs. △ Less",
      "url": "https://arxiv.org/abs/2308.09842"
    },
    {
      "title": "Language-enhanced RNR-Map: Querying Renderable Neural Radiance Field maps with natural language",
      "abstract": "We present Le-RNR-Map, a Language-enhanced Renderable Neural Radiance map for Visual Navigation with natural language query prompts. The recently proposed RNR-Map employs a grid structure comprising latent codes positioned at each pixel. These latent codes, which are derived from image observation, enable: i) image rendering given a camera pose, since they are converted to Neural Radiance Field; ii) image navigation and localization with astonishing accuracy. On top of this, we enhance RNR-Map with CLIP-based embedding latent codes, allowing natural language search without additional label data. We evaluate the effectiveness of this map in single and multi-object searches. We also investigate its compatibility with a Large Language Model as an \"affordance query resolver\". Code and videos are available at https://intelligolabs.github.io/Le-RNR-Map/ △ Less",
      "url": "https://arxiv.org/abs/2308.08854"
    },
    {
      "title": "Discovery of strongly variable X-ray polarization in the neutron star low-mass X-ray binary transient XTE J1701$-$462",
      "abstract": "After about 16 years since its first outburst, the transient neutron star low-mass X-ray binary XTE J1701$-$462 turned on again in September 2022, allowing for the first study of its X-ray polarimetric characteristics by a dedicated observing program with the Imaging X-ray Polarimeter Explorer (IXPE). Polarimetric studies of XTE J1701$-$462 have been expected to improve our understanding of accreting weakly magnetized neutron stars, in particular, the physics and the geometry of the hot inner regions close to the compact object. The IXPE data of two triggered observations were analyzed using time-resolved spectroscopic and polarimetric techniques, following the source along its Z-track of the color-color diagram. During the first pointing on 2022 September 29, an average 2-8 keV polarization degree of 4.6$\\pm$ 0.4\\% was measured, the highest value found up to now for this class of sources. Conversely, only a $\\sim$0.6\\% average degree was obtained during the second pointing ten days later. The polarimetric signal appears to be strictly related to the higher energy blackbody component associated with the boundary layer (BL) emission and its reflection from the inner accretion disk, and it is as strong as 6.1\\% and 1.2\\% ($>95\\%$ significant) above 3-4 keV for the two measurements, respectively. The variable polarimetric signal is apparently related to the spectral characteristics of XTE J1701$-$462, which is the strongest when the source was in the horizontal branch of its Z-track and the weakest in the normal branch. These IXPE results provide new important observational constraints on the physical models and geometry of the Z-sources. Here, we discuss the possible reasons for the presence of strong and variable polarization among these sources. △ Less",
      "url": "https://arxiv.org/abs/2306.10965"
    },
    {
      "title": "First detection of X-ray polarization from the accreting neutron star 4U 1820-303",
      "abstract": "This paper reports the first detection of polarization in the X-rays for atoll-source 4U 1820-303, obtained with the Imaging X-ray Polarimetry Explorer (IXPE) at 99.999% confidence level (CL). Simultaneous polarimetric measurements were also performed in the radio with the Australia Telescope Compact Array (ATCA). The IXPE observations of 4U 1820-303 were coordinated with Swift-XRT, NICER, and NuSTAR aiming to obtain an accurate X-ray spectral model covering a broad energy interval. The source shows a significant polarization above 4 keV, with a polarization degree of 2.0(0.5)% and a polarization angle of -55(7) deg in the 4-7 keV energy range, and a polarization degree of 10(2)% and a polarization angle of -67(7) deg in the 7-8 keV energy bin. This polarization also shows a clear energy trend with polarization degree increasing with energy and a hint for a position-angle change of about 90 deg at 96% CL around 4 keV. The spectro-polarimetric fit indicates that the accretion disk is polarized orthogonally to the hard spectral component, which is presumably produced in the boundary/spreading layer. We do not detect linear polarization from the radio counterpart, with a 99.97% upper limit of 50% at 7.25 GHz. △ Less",
      "url": "https://arxiv.org/abs/2306.08476"
    },
    {
      "title": "Learning Logic Specifications for Soft Policy Guidance in POMCP",
      "abstract": "Partially Observable Monte Carlo Planning (POMCP) is an efficient solver for Partially Observable Markov Decision Processes (POMDPs). It allows scaling to large state spaces by computing an approximation of the optimal policy locally and online, using a Monte Carlo Tree Search based strategy. However, POMCP suffers from sparse reward function, namely, rewards achieved only when the final goal is reached, particularly in environments with large state spaces and long horizons. Recently, logic specifications have been integrated into POMCP to guide exploration and to satisfy safety requirements. However, such policy-related rules require manual definition by domain experts, especially in real-world scenarios. In this paper, we use inductive logic programming to learn logic specifications from traces of POMCP executions, i.e., sets of belief-action pairs generated by the planner. Specifically, we learn rules expressed in the paradigm of answer set programming. We then integrate them inside POMCP to provide soft policy bias toward promising actions. In the context of two benchmark scenarios, rocksample and battery, we show that the integration of learned rules from small task instances can improve performance with fewer Monte Carlo simulations and in larger task instances. We make our modified version of POMCP publicly available at https://github.com/GiuMaz/pomcp_clingo.git. △ Less",
      "url": "https://arxiv.org/abs/2303.09172"
    },
    {
      "title": "Constrained Reinforcement Learning and Formal Verification for Safe Colonoscopy Navigation",
      "abstract": "The field of robotic Flexible Endoscopes (FEs) has progressed significantly, offering a promising solution to reduce patient discomfort. However, the limited autonomy of most robotic FEs results in non-intuitive and challenging manoeuvres, constraining their application in clinical settings. While previous studies have employed lumen tracking for autonomous navigation, they fail to adapt to the presence of obstructions and sharp turns when the endoscope faces the colon wall. In this work, we propose a Deep Reinforcement Learning (DRL)-based navigation strategy that eliminates the need for lumen tracking. However, the use of DRL methods poses safety risks as they do not account for potential hazards associated with the actions taken. To ensure safety, we exploit a Constrained Reinforcement Learning (CRL) method to restrict the policy in a predefined safety regime. Moreover, we present a model selection strategy that utilises Formal Verification (FV) to choose a policy that is entirely safe before deployment. We validate our approach in a virtual colonoscopy environment and report that out of the 300 trained policies, we could identify three policies that are entirely safe. Our work demonstrates that CRL, combined with model selection through FV, can improve the robustness and safety of robotic behaviour in surgical applications. △ Less",
      "url": "https://arxiv.org/abs/2303.03207"
    },
    {
      "title": "Unsupervised Active Visual Search with Monte Carlo planning under Uncertain Detections",
      "abstract": "We propose a solution for Active Visual Search of objects in an environment, whose 2D floor map is the only known information. Our solution has three key features that make it more plausible and robust to detector failures compared to state-of-the-art methods: (i) it is unsupervised as it does not need any training sessions. (ii) During the exploration, a probability distribution on the 2D floor map is updated according to an intuitive mechanism, while an improved belief update increases the effectiveness of the agent's exploration. (iii) We incorporate the awareness that an object detector may fail into the aforementioned probability modelling by exploiting the success statistics of a specific detector. Our solution is dubbed POMP-BE-PD (Pomcp-based Online Motion Planning with Belief by Exploration and Probabilistic Detection). It uses the current pose of an agent and an RGB-D observation to learn an optimal search policy, exploiting a POMDP solved by a Monte-Carlo planning approach. On the Active Vision Database benchmark, we increase the average success rate over all the environments by a significant 35% while decreasing the average path length by 4% with respect to competing methods. Thus, our results are state-of-the-art, even without using any training procedure. △ Less",
      "url": "https://arxiv.org/abs/2303.03155"
    },
    {
      "title": "Safe Deep Reinforcement Learning by Verifying Task-Level Properties",
      "abstract": "Cost functions are commonly employed in Safe Deep Reinforcement Learning (DRL). However, the cost is typically encoded as an indicator function due to the difficulty of quantifying the risk of policy decisions in the state space. Such an encoding requires the agent to visit numerous unsafe states to learn a cost-value function to drive the learning process toward safety. Hence, increasing the number of unsafe interactions and decreasing sample efficiency. In this paper, we investigate an alternative approach that uses domain knowledge to quantify the risk in the proximity of such states by defining a violation metric. This metric is computed by verifying task-level properties, shaped as input-output conditions, and it is used as a penalty to bias the policy away from unsafe states without learning an additional value function. We investigate the benefits of using the violation metric in standard Safe DRL benchmarks and robotic mapless navigation tasks. The navigation experiments bridge the gap between Safe DRL and robotics, introducing a framework that allows rapid testing on real robots. Our experiments show that policies trained with the violation penalty achieve higher performance over Safe DRL baselines and significantly reduce the number of visited unsafe states. △ Less",
      "url": "https://arxiv.org/abs/2302.10030"
    },
    {
      "title": "Online Safety Property Collection and Refinement for Safe Deep Reinforcement Learning in Mapless Navigation",
      "abstract": "Safety is essential for deploying Deep Reinforcement Learning (DRL) algorithms in real-world scenarios. Recently, verification approaches have been proposed to allow quantifying the number of violations of a DRL policy over input-output relationships, called properties. However, such properties are hard-coded and require task-level knowledge, making their application intractable in challenging safety-critical tasks. To this end, we introduce the Collection and Refinement of Online Properties (CROP) framework to design properties at training time. CROP employs a cost signal to identify unsafe interactions and use them to shape safety properties. Hence, we propose a refinement strategy to combine properties that model similar unsafe interactions. Our evaluation compares the benefits of computing the number of violations using standard hard-coded properties and the ones generated with CROP. We evaluate our approach in several robotic mapless navigation tasks and demonstrate that the violation metric computed with CROP allows higher returns and lower violations over previous Safe DRL approaches. △ Less",
      "url": "https://arxiv.org/abs/2302.06695"
    },
    {
      "title": "The #DNN-Verification Problem: Counting Unsafe Inputs for Deep Neural Networks",
      "abstract": "Deep Neural Networks are increasingly adopted in critical tasks that require a high level of safety, e.g., autonomous driving. While state-of-the-art verifiers can be employed to check whether a DNN is unsafe w.r.t. some given property (i.e., whether there is at least one unsafe input configuration), their yes/no output is not informative enough for other purposes, such as shielding, model selection, or training improvements. In this paper, we introduce the #DNN-Verification problem, which involves counting the number of input configurations of a DNN that result in a violation of a particular safety property. We analyze the complexity of this problem and propose a novel approach that returns the exact count of violations. Due to the #P-completeness of the problem, we also propose a randomized, approximate method that provides a provable probabilistic bound of the correct count while significantly reducing computational requirements. We present experimental results on a set of safety-critical benchmarks that demonstrate the effectiveness of our approximate method and evaluate the tightness of the bound. △ Less",
      "url": "https://arxiv.org/abs/2301.07068"
    },
    {
      "title": "Polarization properties of the weakly magnetized neutron star X-ray binary GS 1826-238 in the high soft state",
      "abstract": "The launch of the Imaging X-ray Polarimetry Explorer (IXPE) on 2021 December 9 has opened a new window in X-ray astronomy. We report here the results of the first IXPE observation of a weakly magnetized neutron star, GS 1826-238, performed on 2022 March 29-31 when the source was in a high soft state. An upper limit (99.73% confidence level) of 1.3% for the linear polarization degree is obtained over the IXPE 2-8 keV energy range. Coordinated INTEGRAL and NICER observations were carried out simultaneously with IXPE. The spectral parameters obtained from the fits to the broad-band spectrum were used as inputs for Monte Carlo simulations considering different possible geometries of the X-ray emitting region. Comparing the IXPE upper limit with these simulations, we can put constraints on the geometry and inclination angle of GS 1826-238. △ Less",
      "url": "https://arxiv.org/abs/2212.12472"
    },
    {
      "title": "Constrained Reinforcement Learning for Robotics via Scenario-Based Programming",
      "abstract": "Deep reinforcement learning (DRL) has achieved groundbreaking successes in a wide variety of robotic applications. A natural consequence is the adoption of this paradigm for safety-critical tasks, where human safety and expensive hardware can be involved. In this context, it is crucial to optimize the performance of DRL-based agents while providing guarantees about their behavior. This paper presents a novel technique for incorporating domain-expert knowledge into a constrained DRL training loop. Our technique exploits the scenario-based programming paradigm, which is designed to allow specifying such knowledge in a simple and intuitive way. We validated our method on the popular robotic mapless navigation problem, in simulation, and on the actual platform. Our experiments demonstrate that using our approach to leverage expert knowledge dramatically improves the safety and the performance of the agent. △ Less",
      "url": "https://arxiv.org/abs/2206.09603"
    },
    {
      "title": "Verifying Learning-Based Robotic Navigation Systems",
      "abstract": "Deep reinforcement learning (DRL) has become a dominant deep-learning paradigm for tasks where complex policies are learned within reactive systems. Unfortunately, these policies are known to be susceptible to bugs. Despite significant progress in DNN verification, there has been little work demonstrating the use of modern verification tools on real-world, DRL-controlled systems. In this case study, we attempt to begin bridging this gap, and focus on the important task of mapless robotic navigation -- a classic robotics problem, in which a robot, usually controlled by a DRL agent, needs to efficiently and safely navigate through an unknown arena towards a target. We demonstrate how modern verification engines can be used for effective model selection, i.e., selecting the best available policy for the robot in question from a pool of candidate policies. Specifically, we use verification to detect and rule out policies that may demonstrate suboptimal behavior, such as collisions and infinite loops. We also apply verification to identify models with overly conservative behavior, thus allowing users to choose superior policies, which might be better at finding shorter paths to a target. To validate our work, we conducted extensive experiments on an actual robot, and confirmed that the suboptimal policies detected by our method were indeed flawed. We also demonstrate the superiority of our verification-driven approach over state-of-the-art, gradient attacks. Our work is the first to establish the usefulness of DNN verification in identifying and filtering out suboptimal DRL policies in real-world robots, and we believe that the methods presented here are applicable to a wide range of systems that incorporate deep-learning-based agents. △ Less",
      "url": "https://arxiv.org/abs/2205.13536"
    },
    {
      "title": "An attention model for the formation of collectives in real-world domains",
      "abstract": "We consider the problem of forming collectives of agents for real-world applications aligned with Sustainable Development Goals (e.g., shared mobility, cooperative learning). We propose a general approach for the formation of collectives based on a novel combination of an attention model and an integer linear program (ILP). In more detail, we propose an attention encoder-decoder model that transforms a collective formation instance to a weighted set packing problem, which is then solved by an ILP. Results on two real-world domains (i.e., ridesharing and team formation for cooperative learning) show that our approach provides solutions that are comparable (in terms of quality) to the ones produced by state-of-the-art approaches specific to each domain. Moreover, our solution outperforms the most recent general approach for forming collectives based on Monte Carlo tree search. △ Less",
      "url": "https://arxiv.org/abs/2205.00215"
    },
    {
      "title": "Curriculum Learning for Safe Mapless Navigation",
      "abstract": "This work investigates the effects of Curriculum Learning (CL)-based approaches on the agent's performance. In particular, we focus on the safety aspect of robotic mapless navigation, comparing over a standard end-to-end (E2E) training strategy. To this end, we present a CL approach that leverages Transfer of Learning (ToL) and fine-tuning in a Unity-based simulation with the Robotnik Kairos as a robotic agent. For a fair comparison, our evaluation considers an equal computational demand for every learning approach (i.e., the same number of interactions and difficulty of the environments) and confirms that our CL-based method that uses ToL outperforms the E2E methodology. In particular, we improve the average success rate and the safety of the trained policy, resulting in 10% fewer collisions in unseen testing scenarios. To further confirm these results, we employ a formal verification tool to quantify the number of correct behaviors of Reinforcement Learning policies over desired specifications. △ Less",
      "url": "https://arxiv.org/abs/2112.12490"
    },
    {
      "title": "Benchmarking Safe Deep Reinforcement Learning in Aquatic Navigation",
      "abstract": "We propose a novel benchmark environment for Safe Reinforcement Learning focusing on aquatic navigation. Aquatic navigation is an extremely challenging task due to the non-stationary environment and the uncertainties of the robotic platform, hence it is crucial to consider the safety aspect of the problem, by analyzing the behavior of the trained network to avoid dangerous situations (e.g., collisions). To this end, we consider a value-based and policy-gradient Deep Reinforcement Learning (DRL) and we propose a crossover-based strategy that combines gradient-based and gradient-free DRL to improve sample-efficiency. Moreover, we propose a verification strategy based on interval analysis that checks the behavior of the trained models over a set of desired properties. Our results show that the crossover-based training outperforms prior DRL approaches, while our verification allows us to quantify the number of configurations that violate the behaviors that are described by the properties. Crucially, this will serve as a benchmark for future research in this domain of applications. △ Less",
      "url": "https://arxiv.org/abs/2112.10593"
    },
    {
      "title": "Centralizing State-Values in Dueling Networks for Multi-Robot Reinforcement Learning Mapless Navigation",
      "abstract": "We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep Reinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint action-value function into individual ones, to favor cooperation and achieve decentralized execution. Such factorization involves constraints (e.g., monotonicity) that limit the emergence of novel behaviors in an individual as each agent is trained starting from a joint action-value. In contrast, we propose a novel architecture for CTDE that uses a centralized state-value network to compute a joint state-value, which is used to inject global state information in the value-based updates of the agents. Consequently, each model computes its gradient update for the weights, considering the overall state of the environment. Our idea follows the insights of Dueling Networks as a separate estimation of the joint state-value has both the advantage of improving sample efficiency, while providing each robot information whether the global state is (or is not) valuable. Experiments in a robotic navigation task with 2 4, and 8 robots, confirm the superior performance of our approach over prior CTDE methods (e.g., VDN, QMIX). △ Less",
      "url": "https://arxiv.org/abs/2112.09012"
    },
    {
      "title": "Safe Reinforcement Learning using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery",
      "abstract": "Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon's cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety criteria as they maximise cumulative rewards without considering the risks associated with the actions performed. Due to this limitation, the application of DRL in the safety-critical paradigm of robot-assisted Minimally Invasive Surgery (MIS) has been constrained. In this work, we introduce a Safe-DRL framework that incorporates safety constraints for the automation of surgical subtasks via DRL training. We validate our approach in a virtual scene that replicates a tissue retraction task commonly occurring in multiple phases of an MIS. Furthermore, to evaluate the safe behaviour of the robotic arms, we formulate a formal verification tool for DRL methods that provides the probability of unsafe configurations. Our results indicate that a formal analysis guarantees safety with high confidence such that the robotic instruments operate within the safe workspace and avoid hazardous interaction with other anatomical structures. △ Less",
      "url": "https://arxiv.org/abs/2109.02323"
    },
    {
      "title": "POMP++: Pomcp-based Active Visual Search in unknown indoor environments",
      "abstract": "In this paper we focus on the problem of learning online an optimal policy for Active Visual Search (AVS) of objects in unknown indoor environments. We propose POMP++, a planning strategy that introduces a novel formulation on top of the classic Partially Observable Monte Carlo Planning (POMCP) framework, to allow training-free online policy learning in unknown environments. We present a new belief reinvigoration strategy which allows to use POMCP with a dynamically growing state space to address the online generation of the floor map. We evaluate our method on two public benchmark datasets, AVD that is acquired by real robotic platforms and Habitat ObjectNav that is rendered from real 3D scene scans, achieving the best success rate with an improvement of >10% over the state-of-the-art methods. △ Less",
      "url": "https://arxiv.org/abs/2107.00914"
    },
    {
      "title": "Rule-based Shielding for Partially Observable Monte-Carlo Planning",
      "abstract": "Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders policy interpretability and makes policy verification very complex. In this work, we propose two contributions. The first is a method for identifying unexpected actions selected by POMCP with respect to expert prior knowledge of the task. The second is a shielding approach that prevents POMCP from selecting unexpected actions. The first method is based on Satisfiability Modulo Theory (SMT). It inspects traces (i.e., sequences of belief-action-observation triplets) generated by POMCP to compute the parameters of logical formulas about policy properties defined by the expert. The second contribution is a module that uses online the logical formulas to identify anomalous actions selected by POMCP and substitutes those actions with actions that satisfy the logical formulas fulfilling expert knowledge. We evaluate our approach on Tiger, a standard benchmark for POMDPs, and a real-world problem related to velocity regulation in mobile robot navigation. Results show that the shielded POMCP outperforms the standard POMCP in a case study in which a wrong parameter of POMCP makes it select wrong actions from time to time. Moreover, we show that the approach keeps good performance also if the parameters of the logical formula are optimized using trajectories containing some wrong actions. △ Less",
      "url": "https://arxiv.org/abs/2104.13791"
    },
    {
      "title": "Towards Hierarchical Task Decomposition using Deep Reinforcement Learning for Pick and Place Subtasks",
      "abstract": "Deep Reinforcement Learning (DRL) is emerging as a promising approach to generate adaptive behaviors for robotic platforms. However, a major drawback of using DRL is the data-hungry training regime that requires millions of trial and error attempts, which is impractical when running experiments on robotic systems. Learning from Demonstrations (LfD) has been introduced to solve this issue by cloning the behavior of expert demonstrations. However, LfD requires a large number of demonstrations that are difficult to be acquired since dedicated complex setups are required. To overcome these limitations, we propose a multi-subtask reinforcement learning methodology where complex pick and place tasks can be decomposed into low-level subtasks. These subtasks are parametrized as expert networks and learned via DRL methods. Trained subtasks are then combined by a high-level choreographer to accomplish the intended pick and place task considering different initial configurations. As a testbed, we use a pick and place robotic simulator to demonstrate our methodology and show that our method outperforms a benchmark methodology based on LfD in terms of sample-efficiency. We transfer the learned policy to the real robotic system and demonstrate robust grasping using various geometric-shaped objects. △ Less",
      "url": "https://arxiv.org/abs/2102.04022"
    },
    {
      "title": "Identification of Unexpected Decisions in Partially Observable Monte-Carlo Planning: a Rule-Based Approach",
      "abstract": "Partially Observable Monte-Carlo Planning (POMCP) is a powerful online algorithm able to generate approximate policies for large Partially Observable Markov Decision Processes. The online nature of this method supports scalability by avoiding complete policy representation. The lack of an explicit representation however hinders interpretability. In this work, we propose a methodology based on Satisfiability Modulo Theory (SMT) for analyzing POMCP policies by inspecting their traces, namely sequences of belief-action-observation triplets generated by the algorithm. The proposed method explores local properties of policy behavior to identify unexpected decisions. We propose an iterative process of trace analysis consisting of three main steps, i) the definition of a question by means of a parametric logical formula describing (probabilistic) relationships between beliefs and actions, ii) the generation of an answer by computing the parameters of the logical formula that maximize the number of satisfied clauses (solving a MAX-SMT problem), iii) the analysis of the generated logical formula and the related decision boundaries for identifying unexpected decisions made by POMCP with respect to the original question. We evaluate our approach on Tiger, a standard benchmark for POMDPs, and a real-world problem related to mobile robot navigation. Results show that the approach can exploit human knowledge on the domain, outperforming state-of-the-art anomaly detection methods in identifying unexpected decisions. An improvement of the Area Under Curve up to 47\\% has been achieved in our tests. △ Less",
      "url": "https://arxiv.org/abs/2012.12732"
    },
    {
      "title": "Evaluating the Safety of Deep Reinforcement Learning Models using Semi-Formal Verification",
      "abstract": "Groundbreaking successes have been achieved by Deep Reinforcement Learning (DRL) in solving practical decision-making problems. Robotics, in particular, can involve high-cost hardware and human interactions. Hence, scrupulous evaluations of trained models are required to avoid unsafe behaviours in the operational environment. However, designing metrics to measure the safety of a neural network is an open problem, since standard evaluation parameters (e.g., total reward) are not informative enough. In this paper, we present a semi-formal verification approach for decision-making tasks, based on interval analysis, that addresses the computational demanding of previous verification frameworks and design metrics to measure the safety of the models. Our method obtains comparable results over standard benchmarks with respect to formal verifiers, while drastically reducing the computation time. Moreover, our approach allows to efficiently evaluate safety properties for decision-making models in practical applications such as mapless navigation for mobile robots and trajectory generation for manipulators. △ Less",
      "url": "https://arxiv.org/abs/2010.09387"
    },
    {
      "title": "POMP: Pomcp-based Online Motion Planning for active visual search in indoor environments",
      "abstract": "In this paper we focus on the problem of learning an optimal policy for Active Visual Search (AVS) of objects in known indoor environments with an online setup. Our POMP method uses as input the current pose of an agent (e.g. a robot) and a RGB-D frame. The task is to plan the next move that brings the agent closer to the target object. We model this problem as a Partially Observable Markov Decision Process solved by a Monte-Carlo planning approach. This allows us to make decisions on the next moves by iterating over the known scenario at hand, exploring the environment and searching for the object at the same time. Differently from the current state of the art in Reinforcement Learning, POMP does not require extensive and expensive (in time and computation) labelled data so being very agile in solving AVS in small and medium real scenarios. We only require the information of the floormap of the environment, an information usually available or that can be easily extracted from an a priori single exploration run. We validate our method on the publicly available AVD benchmark, achieving an average success rate of 0.76 with an average path length of 17.1, performing close to the state of the art but without any training needed. Additionally, we show experimentally the robustness of our method when the quality of the object detection goes from ideal to faulty. △ Less",
      "url": "https://arxiv.org/abs/2009.08140"
    },
    {
      "title": "A possible simultaneous fit to the available $e^+e^- \\rightarrow Λ^+_c \\barΛ^-_c$ cross section data nearby $ψ(4660)$ by means of a strong correction to the Coulomb enhancement factor",
      "abstract": "There are two available set of data on the $e^+e^- \\rightarrow Λ^+_c \\barΛ_c^-$ cross section above threshold. The BELLE measurement, with ISR return, is compatible with the presence of a resonant state, called $ψ(4660)$ (formerly known as $Y(4660)$), observed also in other final states. The BESIII dataset has shown a different trend, with a flat cross section. We propose a new solution to fit both datasets by means of a strong correction to the Coulomb enhancement factor. Mass and width of the resonant state is extracted. △ Less",
      "url": "https://arxiv.org/abs/2005.06306"
    },
    {
      "title": "A QUBO Model for Gaussian Process Variance Reduction",
      "abstract": "Gaussian Processes are used in many applications to model spatial phenomena. Within this context, a key issue is to decide the set of locations where to take measurements so as to obtain a better approximation of the underlying function. Current state of the art techniques select such set to minimize the posterior variance of the Gaussian process. We explore the feasibility of solving this problem by proposing a novel Quadratic Unconstrained Binary Optimization (QUBO) model. In recent years this QUBO formulation has gained increasing attention since it represents the input for the specialized quantum annealer D-Wave machines. Hence, our contribution takes an important first step towards the sampling optimization of Gaussian processes in the context of quantum computation. Results of our empirical evaluation shows that the optimum of the QUBO objective function we derived represents a good solution for the above mentioned problem. In fact we are able to obtain comparable and in some cases better results than the widely used submodular technique. △ Less",
      "url": "https://arxiv.org/abs/1901.10982"
    }
  ]
}