{
  "author": "Chao Ma",
  "results": [
    {
      "title": "LongCat-Flash Technical Report",
      "abstract": "We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE) language model designed for both computational efficiency and advanced agentic capabilities. Stemming from the need for scalable efficiency, LongCat-Flash adopts two novel designs: (a) Zero-computation Experts, which enables dynamic computational budget allocation and activates 18.6B-31.3B (27B on average) per token depending on contextual demands, optimizing resource usage. (b) Shortcut-connected MoE, which enlarges the computation-communication overlap window, demonstrating notable gains in inference efficiency and throughput compared to models of a comparable scale. We develop a comprehensive scaling framework for large models that combines hyperparameter transfer, model-growth initialization, a multi-pronged stability suite, and deterministic computation to achieve stable and reproducible training. Notably, leveraging the synergy among scalable architectural design and infrastructure efforts, we complete model training on more than 20 trillion tokens within 30 days, while achieving over 100 tokens per second (TPS) for inference at a cost of \\$0.70 per million output tokens. To cultivate LongCat-Flash towards agentic intelligence, we conduct a large-scale pre-training on optimized mixtures, followed by targeted mid- and post-training on reasoning, code, and instructions, with further augmentation from synthetic data and tool use tasks. Comprehensive evaluations demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers highly competitive performance among other leading models, with exceptional strengths in agentic tasks. The model checkpoint of LongCat-Flash is open-sourced to foster community research. LongCat Chat: https://longcat.ai Hugging Face: https://huggingface.co/meituan-longcat GitHub: https://github.com/meituan-longcat △ Less",
      "url": "https://arxiv.org/abs/2509.01322"
    },
    {
      "title": "High-efficiency Weak-trace-free Counterfactual Communication via Quantum Zeno Effect",
      "abstract": "The quantum Zeno effect, which inhibits quantum state evolution via repeated weak measurements, significantly enhances the efficiency of interaction-free measurement (IFM). This fundamental mechanism facilitates high-efficiency counterfactual quantum communication, enabling information delivery without particle transmission through the channel. However, the transmission time of the counterfactual communication requires minutes for bit and suffers the bit error when transmitting an image. Applying the quantum Zeno effect, we experimentally demonstrate high-efficiency weak-trace-free counterfactual communication on a quantum photonic chip, achieving a transmission probability of $74.2 \\pm 1.6\\%$ for bit 0 and $85.1 \\pm 1.3\\%$ for bit 1. Furthermore, we successfully transmit our group's logo --Quanta-- through counterfactual communication, and reduce the time cost from minutes to seconds for bit, with zero bit errors after information processing. Our study provides a promising approach for secure and efficient communication using integrated silicon quantum photonics. △ Less",
      "url": "https://arxiv.org/abs/2509.01074"
    },
    {
      "title": "Helicity amplitude and branching fraction measurement of $χ_{cJ} \\rightarrow Λ\\barΛ $",
      "abstract": "Utilizing $2712.4 \\pm 14.3$ million $ψ(3686)$ events accumulated by the BESIII experiment, we perform a partial wave analysis of $ψ(3686)\\rightarrowγχ_{cJ}\\rightarrowγΛ\\barΛ$ decay ($J=0,1,2$). The ratio of the helicity amplitudes with same (++) and opposite (+-) helicity for $χ_{c2}\\rightarrowΛ\\barΛ$ decay is determined for the first time to be $R_{χ_{c2}}=0.575 \\pm 0.048 \\pm 0.018 $, with a relative phase angle $ΔΦ_{χ_{c2}} = 0.37 \\pm 0.15 \\pm 0.05 $~rad. The parameters of the angular distribution of $χ_{c2}$ are determined to be $α_{χ_{c2}} = -0.211 \\pm 0.100 \\pm 0.050 $ and $β_{χ_{c2}} = -0.039 \\pm 0.089 \\pm 0.033 $, based on the distribution $dN / d\\cosθ= 1 + α_{χ_{c2}} \\cos^2θ+ β_{χ_{c2}} \\cos^4θ$. The width of $χ_{c0}$ is determined to be $12.31 \\pm 0.26 \\pm 0.12 $~MeV. Additionally, the branching fractions for $χ_{cJ} \\rightarrow Λ\\barΛ$ are measured to be $(3.662 \\pm 0.048 \\pm 0.111) \\times 10^{-4}$, $(1.182 \\pm 0.026 \\pm 0.042) \\times 10^{-4}$, and $(1.704 \\pm 0.035 \\pm 0.057) \\times 10^{-4}$ for $χ_{c0}$, $χ_{c1}$ and $χ_{c2}$, respectively, where the first uncertainty is statistical and the second systematic. △ Less",
      "url": "https://arxiv.org/abs/2509.00289"
    },
    {
      "title": "Homological Bounds of Gentle algebras",
      "abstract": "This paper studies the homological bounds of gentle algebras, i.e., the upper bounds for the sum of the projective and injective dimensions of indecomposable modules over gentle algebras. We provide conditions under which this sum is strictly less than twice the global dimension, and as an application, we give a characterization of quasi-tilted gentle algebras. △ Less",
      "url": "https://arxiv.org/abs/2508.19763"
    },
    {
      "title": "SoccerNet 2025 Challenges Results",
      "abstract": "The SoccerNet 2025 Challenges mark the fifth annual edition of the SoccerNet open benchmarking effort, dedicated to advancing computer vision research in football video understanding. This year's challenges span four vision-based tasks: (1) Team Ball Action Spotting, focused on detecting ball-related actions in football broadcasts and assigning actions to teams; (2) Monocular Depth Estimation, targeting the recovery of scene geometry from single-camera broadcast clips through relative depth estimation for each pixel; (3) Multi-View Foul Recognition, requiring the analysis of multiple synchronized camera views to classify fouls and their severity; and (4) Game State Reconstruction, aimed at localizing and identifying all players from a broadcast video to reconstruct the game state on a 2D top-view of the field. Across all tasks, participants were provided with large-scale annotated datasets, unified evaluation protocols, and strong baselines as starting points. This report presents the results of each challenge, highlights the top-performing solutions, and provides insights into the progress made by the community. The SoccerNet Challenges continue to serve as a driving force for reproducible, open research at the intersection of computer vision, artificial intelligence, and sports. Detailed information about the tasks, challenges, and leaderboards can be found at https://www.soccer-net.org, with baselines and development kits available at https://github.com/SoccerNet. △ Less",
      "url": "https://arxiv.org/abs/2508.19182"
    },
    {
      "title": "Measurement of the branching fraction of $\\psip \\to ωηη$",
      "abstract": "Using a sample of (2.712 $\\pm$ 0.014)$\\times 10^{9}$ $\\psip$ events collected with the BESIII detector at the BEPCII collider in 2009, 2012, and 2021, the decay $\\psip \\to ωηη$ is observed for the first time. The branching fraction of the $ψ(3686)\\toωηη$ decay is measured to be (1.65 $\\pm$ 0.02 $\\pm$ 0.21)$\\times 10^{-5}$, where the first uncertainty is statistical and the second systematic. Clear structures associated with the well-established $ω(1420)$ and $f_{0}(1710)$ resonances are observed in the $ωη$ and $ηη$ invariant-mass spectra, respectively. △ Less",
      "url": "https://arxiv.org/abs/2508.19092"
    },
    {
      "title": "APT-LLM: Exploiting Arbitrary-Precision Tensor Core Computing for LLM Acceleration",
      "abstract": "Large language models (LLMs) have revolutionized AI applications, yet their enormous computational demands severely limit deployment and real-time performance. Quantization methods can help reduce computational costs, however, attaining the extreme efficiency associated with ultra-low-bit quantized LLMs at arbitrary precision presents challenges on GPUs. This is primarily due to the limited support for GPU Tensor Cores, inefficient memory management, and inflexible kernel optimizations. To tackle these challenges, we propose a comprehensive acceleration scheme for arbitrary precision LLMs, namely APT-LLM. Firstly, we introduce a novel data format, bipolar-INT, which allows for efficient and lossless conversion with signed INT, while also being more conducive to parallel computation. We also develop a matrix multiplication (MatMul) method allowing for arbitrary precision by dismantling and reassembling matrices at the bit level. This method provides flexible precision and optimizes the utilization of GPU Tensor Cores. In addition, we propose a memory management system focused on data recovery, which strategically employs fast shared memory to substantially increase kernel execution speed and reduce memory access latency. Finally, we develop a kernel mapping method that dynamically selects the optimal configurable hyperparameters of kernels for varying matrix sizes, enabling optimal performance across different LLM architectures and precision settings. In LLM inference, APT-LLM achieves up to a 3.99$\\times$ speedup compared to FP16 baselines and a 2.16$\\times$ speedup over NVIDIA CUTLASS INT4 acceleration on RTX 3090. On RTX 4090 and H800, APT-LLM achieves up to 2.44$\\times$ speedup over FP16 and 1.65$\\times$ speedup over CUTLASS integer baselines. △ Less",
      "url": "https://arxiv.org/abs/2508.19087"
    },
    {
      "title": "Study of the $χ_{cJ}\\rightarrowΛ\\barΛη^\\prime$ decays",
      "abstract": "Using a data sample of $(2.712\\pm0.014)\\times10^{9}$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we investigate the decays $χ_{cJ} \\rightarrow Λ\\barΛ η^\\prime$ for $J=0,~1,~2$ via the radiative transition $ψ(3686) \\rightarrow γχ_{cJ}$. The decays $χ_{c0,2}\\rightarrowΛ\\barΛη^\\prime$ are observed for the first time, with statistical significances of 6.7$\\,σ$ and 6.4$\\,σ$, respectively. Evidence for the decay $χ_{c1}\\rightarrowΛ\\barΛη^\\prime$ is found with a statistical significance of 3.3$\\,σ$. The corresponding branching fractions are measured to be $\\mathscr{B}(χ_{c0}\\rightarrowΛ\\barΛη^\\prime)=(7.56\\pm1.42\\pm0.90)\\times10^{-5}$, $\\mathscr{B}(χ_{c1}\\rightarrowΛ\\barΛη^\\prime)=(1.54\\pm0.51\\pm0.16)\\times10^{-5}$, and $\\mathscr{B}(χ_{c2}\\rightarrowΛ\\barΛη^\\prime)=(3.03\\pm0.61\\pm0.29)\\times10^{-5}$, where the first uncertainties are statistical and the second systematic. No significant excited $Λ$ baryon states or $Λ\\barΛ$ near-threshold enhancements are observed. △ Less",
      "url": "https://arxiv.org/abs/2508.18761"
    },
    {
      "title": "Search for $χ_{c1}\\to π^{+}π^{-}η_c$ via $ψ(3686)\\toγχ_{c1}$",
      "abstract": "Utilizing $(2712.4 \\pm 14.3) \\times 10^6$ $ψ(3686)$ events collected with the BESIII detector at the BEPCII collider, we search for the hadronic transition process $χ_{c1} \\to π^+π^-η_c$ following the decay $ψ(3686)\\to γχ_{c1}$. No significant signal is observed, and an upper limit of $\\mathcal{B}(χ_{c1}\\toπ^+π^-η_c)$ is determined to be $3.1 times 10^{-4}$~at 90\\% confidence level, which is one order of magnitude more stringent than the previous measurement. △ Less",
      "url": "https://arxiv.org/abs/2508.18601"
    },
    {
      "title": "Search for a bound state of $Λ_{c}\\barΣ_{c}$ near threshold",
      "abstract": "We search for a possible $Λ_{c} \\bar{Σ}_{c}$ bound state, denoted as $H_{c}^{\\pm}$, via the $ e^{+}e^{-} \\to π^{+} π^{-} Λ_{c}^{+}\\barΛ_{c}^{-}$ process for the first time. This analysis utilizes 207.8 and 159.3 pb$^{-1}$ of $e^{+}e^{-}$ annihilation data at the center-of-mass energies of 4918.02 and 4950.93 MeV, respectively, collected with the BESIII detector at the BEPCII collider. No statistically significant signal is observed. The upper limits of the product of Born cross section and branching fraction $σ(e^{+}e^{-} \\to π^{+} H_c^{-} + c.c.) \\times \\mathcal{B}(H_c^{-} \\rightarrow π^{-}Λ_{c}^{+}\\barΛ_{c}^{-})$ at a 90\\% confidence level are reported at each energy point and for various $H_{c}$ mass hypotheses (4715, 4720, 4725, 4730, and 4735 MeV/$c^{2}$) and widths (5, 10, or 20 MeV), with the upper limits ranging from 1.1 pb to 6.4 pb. △ Less",
      "url": "https://arxiv.org/abs/2508.18594"
    },
    {
      "title": "Asymmetric stress engineering of dense dislocations in brittle superconductors for strong vortex pinning",
      "abstract": "Large lossless currents in high-temperature superconductors (HTS) critically rely on dense defects with suitable size and dimensionality to pin vortices, with dislocations being particularly effective due to their one-dimensional geometry to interact extensively with vortex lines. However, in non-metallic compounds such as HTS with rigid lattices, conventional deformation methods typically lead to catastrophic fracture rather than dislocation-mediated plasticity, making it a persistent challenge to introduce dislocations at high density. Here, we propose an asymmetric stress field strategy using extrusion to directly nucleate a high-density of dislocations in HTS by activating shear-driven lattice slip and twisting under superimposed hydrostatic compression. As demonstrated in iron-based superconductors (IBS), atomic displacements of nearly one angstrom trigger the formation of tilted dislocation lines with a density approaching that of metals. With further structural refinement, these dislocations serve as strong pinning centers that lead to a fivefold enhancement in the current-carrying capacity of IBS at 33 T, along with low anisotropy and a large irreversibility field. This work not only establishes a scalable route to engineer pinning landscapes in HTS, but also offers a generalizable framework for manipulating dislocation structures in rigid crystalline systems. △ Less",
      "url": "https://arxiv.org/abs/2508.18138"
    },
    {
      "title": "GWTC-4.0: Methods for Identifying and Characterizing Gravitational-wave Transients",
      "abstract": "The Gravitational-Wave Transient Catalog (GWTC) is a collection of candidate gravitational-wave transient signals identified and characterized by the LIGO-Virgo-KAGRA Collaboration. Producing the contents of the GWTC from detector data requires complex analysis methods. These comprise techniques to model the signal; identify the transients in the data; evaluate the quality of the data and mitigate possible instrumental issues; infer the parameters of each transient; compare the data with the waveform models for compact binary coalescences; and handle the large amount of results associated with all these different analyses. In this paper, we describe the methods employed to produce the catalog's fourth release, GWTC-4.0, focusing on the analysis of the first part of the fourth observing run of Advanced LIGO, Advanced Virgo and KAGRA. △ Less",
      "url": "https://arxiv.org/abs/2508.18081"
    },
    {
      "title": "GWTC-4.0: An Introduction to Version 4.0 of the Gravitational-Wave Transient Catalog",
      "abstract": "The Gravitational-Wave Transient Catalog (GWTC) is a collection of short-duration (transient) gravitational wave signals identified by the LIGO-Virgo-KAGRA Collaboration in gravitational-wave data produced by the eponymous detectors. The catalog provides information about the identified candidates, such as the arrival time and amplitude of the signal and properties of the signal's source as inferred from the observational data. GWTC is the data release of this dataset and version 4.0 extends the catalog to include observations made during the first part of the fourth LIGO-Virgo-KAGRA observing run up until 2024 January 31. This paper marks an introduction to a collection of articles related to this version of the catalog, GWTC-4.0. The collection of articles accompanying the catalog provides documentation of the methods used to analyze the data, summaries of the catalog of events, observational measurements drawn from the population, and detailed discussions of selected candidates △ Less",
      "url": "https://arxiv.org/abs/2508.18080"
    },
    {
      "title": "Search for CP violation in e+e- -> psi(3770) -> DDbar via D -> KsPi0",
      "abstract": "Utilizing data sample of electron-positron collisions recorded with the BESIII detector at the center-of-mass energies of 3.773~GeV, corresponding to an integrated luminosity of 20.28~fb$^{-1}$, we report the first search for the CP forbidden process $e^+e^- \\to ψ(3773) \\to D^0\\bar{D}^0 \\to (K^0_Sπ^0)(K^0_Sπ^0)$. No significant signal is observed. We set the upper limit on the observed cross section to be 7.37~fb, and the upper limit on the joint branching fraction of the C-odd correlated neutral $D$ pair $\\mathcal{B}[(D^0\\bar{D}^0)_{\\text{C-odd}} \\to (K^0_Sπ^0)(K^0_Sπ^0)]$ to be $2.04 \\times 10^{-6}$ at the 90\\% confidence level. △ Less",
      "url": "https://arxiv.org/abs/2508.17819"
    },
    {
      "title": "Skyrmions based on optical anisotropy for topological encoding",
      "abstract": "The observation of skyrmions across diverse physical domains suggests that they are universal features of S$^{2}$-valued fields, reflecting the ubiquity of topology in the study of the natural world. In this paper, we develop an abstract technique of parameter space dimensionality reduction that extends the skyrmion framework to fields taking values in manifolds of dimension greater than 2, thereby broadening the range of systems that can support skyrmions. To prove that this is more than just a mathematical abstraction, we apply our technique to light-matter interactions, directly encoding skyrmionic structures into the optical anisotropy of spatially varying structured matter by selecting a distinguished axis, which is fundamentally different from the more commonly known skyrmions formed by director fields in liquid crystals. We experimentally realize such skyrmions using a liquid-crystal-based tunable elliptical retarder array as a proof-of-concept platform and demonstrate complex, reconfigurable skyrmionic states exhibiting topological robustness under artificially introduced stochastic perturbations. Exploiting this robustness, we demonstrate a promising application of skyrmions in topologically protected information storage and show, both theoretically and experimentally, that the physically realized S$^{2}$-valued field can differ from the designed field everywhere by a large margin of error (up to 60°) without affecting the underlying topological charge. △ Less",
      "url": "https://arxiv.org/abs/2508.16483"
    },
    {
      "title": "Intern-S1: A Scientific Multimodal Foundation Model",
      "abstract": "In recent years, a plethora of open-source foundation models have emerged, achieving remarkable progress in some widely attended fields, with performance being quite close to that of closed-source models. However, in high-value but more challenging scientific professional fields, either the fields still rely on expert models, or the progress of general foundation models lags significantly compared to those in popular areas, far from sufficient for transforming scientific research and leaving substantial gap between open-source models and closed-source models in these scientific domains. To mitigate this gap and explore a step further toward Artificial General Intelligence (AGI), we introduce Intern-S1, a specialized generalist equipped with general understanding and reasoning capabilities with expertise to analyze multiple science modal data. Intern-S1 is a multimodal Mixture-of-Experts (MoE) model with 28 billion activated parameters and 241 billion total parameters, continually pre-trained on 5T tokens, including over 2.5T tokens from scientific domains. In the post-training stage, Intern-S1 undergoes offline and then online reinforcement learning (RL) in InternBootCamp, where we propose Mixture-of-Rewards (MoR) to synergize the RL training on more than 1000 tasks simultaneously. Through integrated innovations in algorithms, data, and training systems, Intern-S1 achieved top-tier performance in online RL training. On comprehensive evaluation benchmarks, Intern-S1 demonstrates competitive performance on general reasoning tasks among open-source models and significantly outperforms open-source models in scientific domains, surpassing closed-source state-of-the-art models in professional tasks, such as molecular synthesis planning, reaction condition prediction, predicting thermodynamic stabilities for crystals. Our models are available at https://huggingface.co/internlm/Intern-S1. △ Less",
      "url": "https://arxiv.org/abs/2508.15763"
    },
    {
      "title": "AnchorSync: Global Consistency Optimization for Long Video Editing",
      "abstract": "Editing long videos remains a challenging task due to the need for maintaining both global consistency and temporal coherence across thousands of frames. Existing methods often suffer from structural drift or temporal artifacts, particularly in minute-long sequences. We introduce AnchorSync, a novel diffusion-based framework that enables high-quality, long-term video editing by decoupling the task into sparse anchor frame editing and smooth intermediate frame interpolation. Our approach enforces structural consistency through a progressive denoising process and preserves temporal dynamics via multimodal guidance. Extensive experiments show that AnchorSync produces coherent, high-fidelity edits, surpassing prior methods in visual quality and temporal stability. △ Less",
      "url": "https://arxiv.org/abs/2508.14609"
    },
    {
      "title": "Anomalous Nernst Effect and Its Implications for Time-Reversal Symmetry Breaking in Kagome Metal ScV6Sn6",
      "abstract": "The nonmagnetic kagome metal ScV6Sn6 displays an unconventional charge order (CO) accompanied by signatures of an anomalous Hall effect, hidden magnetism, and multiple lattice instabilities. In this study, we report the observation of unconventional anomalous thermoelectric properties. Notably, unexpected anomalous transverse Nernst signals reach a peak value of ~4 μV/K near the TCDW ~92 K in ScV6Sn6, and these signals persist in the charge-ordered state as the temperature decreases to 10 K. Furthermore, both thermopower and thermal conductivity exhibit significant changes under magnetic fields, even in the nonmagnetic ground state. These observations strongly suggest the emergence of time-reversal symmetry breaking in ScV6Sn6, as supported by muon spin relaxation (μSR) measurements. While hidden magnetism represents the most plausible origin, alternative mechanisms involving orbital currents and chiral charge order remain possible. △ Less",
      "url": "https://arxiv.org/abs/2508.12667"
    },
    {
      "title": "Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection",
      "abstract": "This paper investigates multi-scale feature approximation and transferable features for object detection from point clouds. Multi-scale features are critical for object detection from point clouds. However, multi-scale feature learning usually involves multiple neighborhood searches and scale-aware layers, which can hinder efforts to achieve lightweight models and may not be conducive to research constrained by limited computational resources. This paper approximates point-based multi-scale features from a single neighborhood based on knowledge distillation. To compensate for the loss of constructive diversity in a single neighborhood, this paper designs a transferable feature embedding mechanism. Specifically, class-aware statistics are employed as transferable features given the small computational cost. In addition, this paper introduces the central weighted intersection over union for localization to alleviate the misalignment brought by the center offset in optimization. Note that the method presented in this paper saves computational costs. Extensive experiments on public datasets demonstrate the effectiveness of the proposed method. △ Less",
      "url": "https://arxiv.org/abs/2508.11951"
    },
    {
      "title": "INFNet: A Task-aware Information Flow Network for Large-Scale Recommendation Systems",
      "abstract": "Feature interaction has long been a cornerstone of ranking models in large-scale recommender systems due to its proven effectiveness in capturing complex dependencies among features. However, existing feature interaction strategies face two critical challenges in industrial applications: (1) The vast number of categorical and sequential features makes exhaustive interaction computationally prohibitive, often resulting in optimization difficulties. (2) Real-world recommender systems typically involve multiple prediction objectives, yet most current approaches apply feature interaction modules prior to the multi-task learning layers. This late-fusion design overlooks task-specific feature dependencies and inherently limits the capacity of multi-task modeling. To address these limitations, we propose the Information Flow Network (INFNet), a task-aware architecture designed for large-scale recommendation scenarios. INFNet distinguishes features into three token types, categorical tokens, sequence tokens, and task tokens, and introduces a novel dual-flow design comprising heterogeneous and homogeneous alternating information blocks. For heterogeneous information flow, we employ a cross-attention mechanism with proxy that facilitates efficient cross-modal token interaction with balanced computational cost. For homogeneous flow, we design type-specific Proxy Gated Units (PGUs) to enable fine-grained intra-type feature processing. Extensive experiments on multiple offline benchmarks confirm that INFNet achieves state-of-the-art performance. Moreover, INFNet has been successfully deployed in a commercial online advertising system, yielding significant gains of +1.587% in Revenue (REV) and +1.155% in Click-Through Rate (CTR). △ Less",
      "url": "https://arxiv.org/abs/2508.11565"
    },
    {
      "title": "The Production and Decay Dynamics of the Charmed Baryon $Λ_c^+$ in $e^+e^-$ Annihilations near Threshold",
      "abstract": "The study of the charmed baryons is crucial for investigating the strong and weak interactions in the Standard Model and for gaining insights into the internal structure of baryons. In an $e^+e^-$ experiment the lightest charmed baryon, $Λ_c^+$, can be produced in pairs through the single photon annihilation process. This process can be described by two complex electromagnetic form factors. The presence of a non-zero relative phase between these form factors gives rise to a transverse polarization of the charmed baryon and provides additional constraints on the dynamic parameters in the decays. In this article, we present the first observation of the transverse polarization of $Λ_{c}^{+}$ in the reaction $e^+e^- \\to Λ_c^{+}\\barΛ_c^-$, based on $6.4~\\text{fb}^{-1}$ of $e^{+}e^{-}$ annihilation data collected at center-of-mass energies between 4600 MeV and 4951 MeV with the BESIII detector. The decay asymmetry parameters and strong phase shift in the decays $Λ_c^+ \\to pK_S^0$, $Λπ^+$, $Σ^0π^+$, $Σ^+π^0$ are also simultaneously extracted from the joint angular distributions. These results are vital for understanding CP violation and its role in the matter-antimatter asymmetry of the Universe. △ Less",
      "url": "https://arxiv.org/abs/2508.11400"
    },
    {
      "title": "Measurement of the Born cross section for $e^+e^- \\to p K^- K^- \\barΞ^+$ at $\\sqrt{s} =$ 3.5-4.9 GeV",
      "abstract": "Using $e^+ e^-$ collision data corresponding to a total integrated luminosity of 20 ${\\rm fb}^{-1}$ collected with the BESIII detector at the BEPCII collider, we present a measurement of the Born cross section for the process $e^+e^- \\to p K^-K^-\\barΞ^{+}$ at 39 center-of-mass energies between 3.5 and 4.9 GeV with a partial reconstruction technique. By performing a fit to the dressed cross section of $e^{+}e^{-}\\to p K^- K^-\\barΞ^{+}$ with a power law function for continuum production and one resonance at a time for the $ψ(3770)$, $ψ(4040)$, $ψ(4160)$, $ψ(4230)$, $ψ(4360)$, $ψ(4415)$ or $ψ(4660)$, respectively, the upper limits for the product of partial electronic width and branching fraction into the final state $p K^- K^- \\barΞ^+$ for these resonances are determined at the $90\\%$ confidence level. △ Less",
      "url": "https://arxiv.org/abs/2508.11276"
    },
    {
      "title": "LLM-based Multi-Agent Copilot for Quantum Sensor",
      "abstract": "Large language models (LLM) exhibit broad utility but face limitations in quantum sensor development, stemming from interdisciplinary knowledge barriers and involving complex optimization processes. Here we present QCopilot, an LLM-based multi-agent framework integrating external knowledge access, active learning, and uncertainty quantification for quantum sensor design and diagnosis. Comprising commercial LLMs with few-shot prompt engineering and vector knowledge base, QCopilot employs specialized agents to adaptively select optimization methods, automate modeling analysis, and independently perform problem diagnosis. Applying QCopilot to atom cooling experiments, we generated 10${}^{\\rm{8}}$ sub-$\\rmμ$K atoms without any human intervention within a few hours, representing $\\sim$100$\\times$ speedup over manual experimentation. Notably, by continuously accumulating prior knowledge and enabling dynamic modeling, QCopilot can autonomously identify anomalous parameters in multi-parameter experimental settings. Our work reduces barriers to large-scale quantum sensor deployment and readily extends to other quantum information systems. △ Less",
      "url": "https://arxiv.org/abs/2508.05421"
    },
    {
      "title": "Stacking-induced type-II quantum spin Hall insulators with high spin Chern number in unconventional magnetism",
      "abstract": "Generally, stacking two monolayer type-I quantum spin Hall insulators gives rise to a trivial insulator. However, whether or not stacking two type-II quantum spin Hall insulators results in a trivial insulator has not yet been explored. In this letter, based on the calculations of lattice model, we demonstrate that stacking two type-II quantum spin Hall insulators does not yield a trivial insulator, but instead forms a quantum spin Hall insulator with high spin Chern number. In this phase, there are two pairs of topological edge states with opposite chirality and polarization coexisting in the boundary. Our calculations further reveal that the quantized spin Hall conductance of the bilayer is twice that of the monolayer. When U(1) symmetry is present, the high spin Chern number phase remains stable; when U(1) symmetry is broken, it persists over a broad parameter range. Furthermore, based on the first-principles electronic structure calculations, we propose that bilayer Nb$_2$SeTeO is a type-II quantum spin Hall insulator with high spin Chern number. Finally, extending this strategy to multilayer stacks naturally leads to quantum spin Hall insulator with larger spin Chern number. Our work not only deepens the distinction between type-I and type-II quantum spin Hall insulators, but also offers a route toward realizing highly quantized spin Hall conductance. △ Less",
      "url": "https://arxiv.org/abs/2508.05365"
    },
    {
      "title": "Decoding Polyphenol-Protein Interactions with Deep Learning: From Molecular Mechanisms to Food Applications",
      "abstract": "Polyphenols and proteins are essential biomolecules that influence food functionality and, by extension, human health. Their interactions -- hereafter referred to as PhPIs (polyphenol-protein interactions) -- affect key processes such as nutrient bioavailability, antioxidant activity, and therapeutic efficacy. However, these interactions remain challenging due to the structural diversity of polyphenols and the dynamic nature of protein binding. Traditional experimental techniques like nuclear magnetic resonance (NMR) and mass spectrometry (MS), along with computational tools such as molecular docking and molecular dynamics (MD), have offered important insights but face constraints in scalability, throughput, and reproducibility. This review explores how deep learning (DL) is reshaping the study of PhPIs by enabling efficient prediction of binding sites, interaction affinities, and MD using high-dimensional bio- and chem-informatics data. While DL enhances prediction accuracy and reduces experimental redundancy, its effectiveness remains limited by data availability, quality, and representativeness, particularly in the context of natural products. We critically assess current DL frameworks for PhPIs analysis and outline future directions, including multimodal data integration, improved model generalizability, and development of domain-specific benchmark datasets. This synthesis offers guidance for researchers aiming to apply DL in unraveling structure-function relationships of polyphenols, accelerating discovery in nutritional science and therapeutic development. △ Less",
      "url": "https://arxiv.org/abs/2508.03456"
    },
    {
      "title": "Low-rankness and Smoothness Meet Subspace: A Unified Tensor Regularization for Hyperspectral Image Super-resolution",
      "abstract": "Hyperspectral image super-resolution (HSI-SR) has emerged as a challenging yet critical problem in remote sensing. Existing approaches primarily focus on regularization techniques that leverage low-rankness and local smoothness priors. Recently, correlated total variation has been introduced for tensor recovery, integrating these priors into a single regularization framework. Direct application to HSI-SR, however, is hindered by the high spectral dimensionality of hyperspectral data. In this paper, we propose a unified tensor regularizer, called JLRST, which jointly encodes low-rankness and local smoothness priors under a subspace framework. Specifically, we compute the gradients of the clustered coefficient tensors along all three tensor modes to fully exploit spectral correlations and nonlocal similarities in HSI. By enforcing priors on subspace coefficients rather than the entire HR-HSI data, the proposed method achieves improved computational efficiency and accuracy. Furthermore, to mitigate the bias introduced by the tensor nuclear norm (TNN), we introduce the mode-3 logarithmic TNN to process gradient tensors. An alternating direction method of multipliers with proven convergence is developed to solve the proposed model. Experimental results demonstrate that our approach significantly outperforms state-of-the-art methods in HSI-SR. △ Less",
      "url": "https://arxiv.org/abs/2508.03049"
    },
    {
      "title": "Tool-integrated Reinforcement Learning for Repo Deep Search",
      "abstract": "Issue localization, the process of identifying code locations that need modification to resolve software issues, is a critical yet challenging task in software development. The semantic gap between natural language issue descriptions and faulty code requires complex multi-hop reasoning through code dependencies. Existing LLM-based agents attempt to address this by integrating repository retrieval tools. However, this transforms issue localization into a demanding task we call Repo Deep Search, which requires the LLM to effectively utilize various repository retrieval tools throughout a multi-step reasoning and navigation process. To tackle this challenge, we present ToolTrain, a two-stage tool-integrated training framework combining rejection-sampled supervised fine-tuning and tool-integrated reinforcement learning to enhance LLMs' ability to use retrieval tools for issue localization. Experimental results show that ToolTrain-trained models achieve state-of-the-art performance, with our 32B model even surpassing Claude-3.7 on function-level localization. The results also show that improved localization performance translates to better end-to-end issue resolution performance. This further demonstrates that training for issue localization is a viable and effective strategy for improving automated software development. △ Less",
      "url": "https://arxiv.org/abs/2508.03012"
    },
    {
      "title": "Measurement of Born Cross Sections and Effective Form Factors of $e^+e^-\\to Ω^{-}\\barΩ^{+}$ from$\\sqrt{s}$ = 3.7 to 4.7 GeV",
      "abstract": "Using $e^+e^-$ collision data corresponding to an integrated luminosity of 22.7 fb$^{-1}$, collected at center-of-mass energies between 3.7 and 4.7 GeV with the BESIII detector at the BEPCII storage ring, we measure the energy-dependent Born cross sections of $e^+e^-\\to Ω^{-}\\barΩ^+$ and the effective form factors of the $Ω^-$ baryon. The analysis employs a single baryon tagging method, and the results are consistent with theoretical predictions, providing critical constraints on the electromagnetic structure of the $Ω^-$ hyperon. No significant signal of charmonium or charmonium-like states decaying to $Ω^{-}\\barΩ^+$ is observed in the investigated energy range.This paper supersedes the withdrawn work arXiv:2505.03180v1. △ Less",
      "url": "https://arxiv.org/abs/2508.01359"
    },
    {
      "title": "Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights",
      "abstract": "Developing reliable defenses against patch attacks on object detectors has attracted increasing interest. However, we identify that existing defense evaluations lack a unified and comprehensive framework, resulting in inconsistent and incomplete assessments of current methods. To address this issue, we revisit 11 representative defenses and present the first patch defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object detectors, and 4 diverse metrics. This leads to the large-scale adversarial patch dataset with 94 types of patches and 94,000 images. Our comprehensive analyses reveal new insights: (1) The difficulty in defending against naturalistic patches lies in the data distribution, rather than the commonly believed high frequencies. Our new dataset with diverse patch distributions can be used to improve existing defenses by 15.09% AP@0.5. (2) The average precision of the attacked object, rather than the commonly pursued patch detection accuracy, shows high consistency with defense performance. (3) Adaptive attacks can substantially bypass existing defenses, and defenses with complex/stochastic models or universal patch properties are relatively robust. We hope that our analyses will serve as guidance on properly evaluating patch attacks/defenses and advancing their design. Code and dataset are available at https://github.com/Gandolfczjh/APDE, where we will keep integrating new attacks/defenses. △ Less",
      "url": "https://arxiv.org/abs/2508.00649"
    },
    {
      "title": "RecGPT Technical Report",
      "abstract": "Recommender systems are among the most impactful applications of artificial intelligence, serving as critical infrastructure connecting users, merchants, and platforms. However, most current industrial systems remain heavily reliant on historical co-occurrence patterns and log-fitting objectives, i.e., optimizing for past user interactions without explicitly modeling user intent. This log-fitting approach often leads to overfitting to narrow historical preferences, failing to capture users' evolving and latent interests. As a result, it reinforces filter bubbles and long-tail phenomena, ultimately harming user experience and threatening the sustainability of the whole recommendation ecosystem. To address these challenges, we rethink the overall design paradigm of recommender systems and propose RecGPT, a next-generation framework that places user intent at the center of the recommendation pipeline. By integrating large language models (LLMs) into key stages of user interest mining, item retrieval, and explanation generation, RecGPT transforms log-fitting recommendation into an intent-centric process. To effectively align general-purpose LLMs to the above domain-specific recommendation tasks at scale, RecGPT incorporates a multi-stage training paradigm, which integrates reasoning-enhanced pre-alignment and self-training evolution, guided by a Human-LLM cooperative judge system. Currently, RecGPT has been fully deployed on the Taobao App. Online experiments demonstrate that RecGPT achieves consistent performance gains across stakeholders: users benefit from increased content diversity and satisfaction, merchants and the platform gain greater exposure and conversions. These comprehensive improvement results across all stakeholders validates that LLM-driven, intent-centric design can foster a more sustainable and mutually beneficial recommendation ecosystem. △ Less",
      "url": "https://arxiv.org/abs/2507.22879"
    },
    {
      "title": "Cross-Architecture Distillation Made Simple with Redundancy Suppression",
      "abstract": "We describe a simple method for cross-architecture knowledge distillation, where the knowledge transfer is cast into a redundant information suppression formulation. Existing methods introduce sophisticated modules, architecture-tailored designs, and excessive parameters, which impair their efficiency and applicability. We propose to extract the architecture-agnostic knowledge in heterogeneous representations by reducing the redundant architecture-exclusive information. To this end, we present a simple redundancy suppression distillation (RSD) loss, which comprises cross-architecture invariance maximisation and feature decorrelation objectives. To prevent the student from entirely losing its architecture-specific capabilities, we further design a lightweight module that decouples the RSD objective from the student's internal representations. Our method is devoid of the architecture-specific designs and complex operations in the pioneering method of OFA. It outperforms OFA on CIFAR-100 and ImageNet-1k benchmarks with only a fraction of their parameter overhead, which highlights its potential as a simple and strong baseline to the cross-architecture distillation community. △ Less",
      "url": "https://arxiv.org/abs/2507.21844"
    },
    {
      "title": "Inkjet Printed Liquid Crystal Droplet for Complex Beam Manipulation",
      "abstract": "The inkjet-fabricated liquid crystal (LC) droplet device not only capitalizes on the intrinsic birefringence properties of liquid crystals but also leverages the hemispherical shape of droplet devices on substrates. This configuration facilitates self-alignment of the LC director under the influence of surface tension. The LC droplet devices we fabricated are capable of intricate beam manipulation, encompassing both generation and analysis of light beams. Such devices possess substantial prospective applications in the fields of optical communications and light beam characterization, highlighting their significant potential for advancement in optical technologies. △ Less",
      "url": "https://arxiv.org/abs/2507.21826"
    },
    {
      "title": "HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels",
      "abstract": "Creating immersive and playable 3D worlds from texts or images remains a fundamental challenge in computer vision and graphics. Existing world generation approaches typically fall into two categories: video-based methods that offer rich diversity but lack 3D consistency and rendering efficiency, and 3D-based methods that provide geometric consistency but struggle with limited training data and memory-inefficient representations. To address these limitations, we present HunyuanWorld 1.0, a novel framework that combines the best of both worlds for generating immersive, explorable, and interactive 3D scenes from text and image conditions. Our approach features three key advantages: 1) 360° immersive experiences via panoramic world proxies; 2) mesh export capabilities for seamless compatibility with existing computer graphics pipelines; 3) disentangled object representations for augmented interactivity. The core of our framework is a semantically layered 3D mesh representation that leverages panoramic images as 360° world proxies for semantic-aware world decomposition and reconstruction, enabling the generation of diverse 3D worlds. Extensive experiments demonstrate that our method achieves state-of-the-art performance in generating coherent, explorable, and interactive 3D worlds while enabling versatile applications in virtual reality, physical simulation, game development, and interactive content creation. △ Less",
      "url": "https://arxiv.org/abs/2507.21809"
    },
    {
      "title": "Precise Measurement of Chromo-Electric Dipole Moment of the Charm Quark",
      "abstract": "The combined symmetry of charge conjugation and parity ($C\\!P$) is tested in the hadronic transition $ψ(3686)\\toπ^+π^{-}J/ψ$, utilizing a dataset of 2.7 billion $ψ(3686)$ events collected by the BESIII detector at the BEPCII collider. The resulting asymmetry observable is $A_{cp} = (0.6\\pm1.8_{\\rm stat}\\pm0.1_{\\rm sys})\\times10^{-4}$ by combining the two channels $J/ψ\\to e^+e^-$ and $J/ψ\\toμ^+μ^-$ with unprecedented precision. Meanwhile, by considering the relationship between the chromo-electric dipole moment (CEDM) and the $A_{cp}$ observable derived from the quantum chromo-dynamics multipole expansion (QCDME) theory based on Chen-Kuang, as well as Cornell potential model, we yield the results of charm quark's CEDM with $d^{\\prime}_{c} = (2.6\\pm7.8_{\\rm stat}\\pm0.4_{\\rm sys}\\pm0.6_{\\rm theo})\\times10^{-16}$ $e\\cdot$cm, and $d^{\\prime}_{c} = (3.5\\pm10.5_{\\rm stat}\\pm0.6_{\\rm sys}\\pm0.5_{\\rm theo})\\times10^{-16}$ $e\\cdot$cm, respectively. These results correspond to an upper limit of $|d^{\\prime}_{c} |<2.1\\times10^{-15}\\ e\\cdot$cm at a 90\\% confidence level, an order of magnitude improvement in sensitivity compared to the previous direct bound using the same decay process. Our results provide insights into the dynamics of charmonium hadronic transitions, shedding light on their behavior in the context of $C\\!P$ violation. △ Less",
      "url": "https://arxiv.org/abs/2507.20618"
    },
    {
      "title": "Kimi K2: Open Agentic Intelligence",
      "abstract": "We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token efficiency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments. Kimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding, mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints to facilitate future research and applications of agentic intelligence. △ Less",
      "url": "https://arxiv.org/abs/2507.20534"
    },
    {
      "title": "Alignment and Safety in Large Language Models: Safety Mechanisms, Training Paradigms, and Emerging Challenges",
      "abstract": "Due to the remarkable capabilities and growing impact of large language models (LLMs), they have been deeply integrated into many aspects of society. Thus, ensuring their alignment with human values and intentions has emerged as a critical challenge. This survey provides a comprehensive overview of practical alignment techniques, training protocols, and empirical findings in LLM alignment. We analyze the development of alignment methods across diverse paradigms, characterizing the fundamental trade-offs between core alignment objectives. Our analysis shows that while supervised fine-tuning enables basic instruction-following, preference-based methods offer more flexibility for aligning with nuanced human intent. We discuss state-of-the-art techniques, including Direct Preference Optimization (DPO), Constitutional AI, brain-inspired methods, and alignment uncertainty quantification (AUQ), highlighting their approaches to balancing quality and efficiency. We review existing evaluation frameworks and benchmarking datasets, emphasizing limitations such as reward misspecification, distributional robustness, and scalable oversight. We summarize strategies adopted by leading AI labs to illustrate the current state of practice. We conclude by outlining open problems in oversight, value pluralism, robustness, and continuous alignment. This survey aims to inform both researchers and practitioners navigating the evolving landscape of LLM alignment. △ Less",
      "url": "https://arxiv.org/abs/2507.19672"
    },
    {
      "title": "FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems",
      "abstract": "Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine interactions by allowing real-time user interruptions and backchanneling, compared to traditional SDS that rely on turn-taking. However, existing benchmarks lack metrics for FD scenes, e.g., evaluating model performance during user interruptions. In this paper, we present a comprehensive FD benchmarking pipeline utilizing LLMs, TTS, and ASR to address this gap. It assesses FDSDS's ability to handle user interruptions, manage delays, and maintain robustness in challenging scenarios with diverse novel metrics. We applied our benchmark to three open-source FDSDS (Moshi, Freeze-omni, and VITA-1.5) using over 40 hours of generated speech, with 293 simulated conversations and 1,200 interruptions. The results show that all models continue to face challenges, such as failing to respond to user interruptions, under frequent disruptions and noisy conditions. Demonstrations, data, and code will be released. △ Less",
      "url": "https://arxiv.org/abs/2507.19040"
    },
    {
      "title": "SafeWork-R1: Coevolving Safety and Intelligence under the AI-45$^{\\circ}$ Law",
      "abstract": "We introduce SafeWork-R1, a cutting-edge multimodal reasoning model that demonstrates the coevolution of capabilities and safety. It is developed by our proposed SafeLadder framework, which incorporates large-scale, progressive, safety-oriented reinforcement learning post-training, supported by a suite of multi-principled verifiers. Unlike previous alignment methods such as RLHF that simply learn human preferences, SafeLadder enables SafeWork-R1 to develop intrinsic safety reasoning and self-reflection abilities, giving rise to safety `aha' moments. Notably, SafeWork-R1 achieves an average improvement of $46.54\\%$ over its base model Qwen2.5-VL-72B on safety-related benchmarks without compromising general capabilities, and delivers state-of-the-art safety performance compared to leading proprietary models such as GPT-4.1 and Claude Opus 4. To further bolster its reliability, we implement two distinct inference-time intervention methods and a deliberative search mechanism, enforcing step-level verification. Finally, we further develop SafeWork-R1-InternVL3-78B, SafeWork-R1-DeepSeek-70B, and SafeWork-R1-Qwen2.5VL-7B. All resulting models demonstrate that safety and capability can co-evolve synergistically, highlighting the generalizability of our framework in building robust, reliable, and trustworthy general-purpose AI. △ Less",
      "url": "https://arxiv.org/abs/2507.18576"
    },
    {
      "title": "Silicon single-photon detector achieving over 84% photon detection efficiency with flexible operation modes",
      "abstract": "Silicon single-photon detectors (Si SPDs) play a crucial role in detecting single photons in the visible spectrum. For various applications, photon detection efficiency (PDE) is the most critical characteristic for effectively collecting photons. Here, we present a Si SPD with a remarkable PDE of up to 84.4% at 785 nm, supporting multiple operation modes. We design and fabricate a thick-junction Si single-photon avalanche diode (SPAD) that enhances the avalanche probability through a backside-illumination structure, while minimizing noise through the design of a doping-compensated avalanche region. To maximize PDE, we implement a readout circuit with a 50 V quenching voltage, enabling operation in free-running, gating, or hybrid modes. The SPAD, along with its readout circuits and affiliated circuits, is integrated into a compact SPD module. In free-running mode, the module achieves a maximum PDE of 84.4%, with a dark count rate of 260 cps, and an afterpulse probability of 2.9% at 268 K. This work provides a practical solution for applications requiring ultra-high-efficiency Si SPD with multiple operation modes. △ Less",
      "url": "https://arxiv.org/abs/2507.18172"
    },
    {
      "title": "Step-Audio 2 Technical Report",
      "abstract": "This paper presents Step-Audio 2, an end-to-end multi-modal large language model designed for industry-strength audio understanding and speech conversation. By integrating a latent audio encoder and reasoning-centric reinforcement learning (RL), Step-Audio 2 achieves promising performance in automatic speech recognition (ASR) and audio understanding. To facilitate genuine end-to-end speech conversation, Step-Audio 2 incorporates the generation of discrete audio tokens into language modeling, significantly enhancing its responsiveness to paralinguistic information such as speaking styles and emotions. To effectively leverage the rich textual and acoustic knowledge in real-world data, Step-Audio 2 integrates retrieval-augmented generation (RAG) and is able to call external tools such as web search to mitigate hallucination and audio search to switch timbres. Trained on millions of hours of speech and audio data, Step-Audio 2 delivers intelligence and expressiveness across diverse conversational scenarios. Evaluation results demonstrate that Step-Audio 2 achieves state-of-the-art performance on various audio understanding and conversational benchmarks compared to other open-source and commercial solutions. Please visit https://github.com/stepfun-ai/Step-Audio2 for more information. △ Less",
      "url": "https://arxiv.org/abs/2507.16632"
    },
    {
      "title": "Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models",
      "abstract": "New era has unlocked exciting possibilities for extending Large Language Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or segmenting independent objects to perform these tasks, which limits their spatial awareness due to insufficient representation of the richness inherent in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D MLLM specifically designed to enhance spatial awareness for 3D vision-language tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM integrates an LLM backbone with a progressive spatial awareness scheme that progressively captures spatial information as the perception field expands, generating location-enriched 3D scene embeddings to serve as visual prompts. Furthermore, we introduce two novel tasks: 3D object distance measurement and 3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate the model's spatial awareness capabilities. Experimental results demonstrate that Spatial 3D-LLM achieves state-of-the-art performance across a wide range of 3D vision-language tasks, revealing the improvements stemmed from our progressive spatial awareness scheme of mining more profound spatial information. Our code is available at https://github.com/bjshuyuan/Spatial-3D-LLM. △ Less",
      "url": "https://arxiv.org/abs/2507.16524"
    },
    {
      "title": "Lunar Orbital VLBI Experiment: motivation, scientific purposes and status",
      "abstract": "The Lunar Orbital VLBI Experiment (LOVEX) is a scientific component of the Chinese Lunar Exploration Project (CLEP) Chang'E-7. The spaceborne component of LOVEX is implemented onboard the relay satellite QueQiao-2, which was launched on 2024 March 20, and later placed into an elliptical selenocentric orbit. The LOVEX-specific payload consists of an X-band cryogenic receiver, a hydrogen maser frequency standard, and VLBI data formatting and acquisition electronics. Several components of the QueQiao-2 nominal onboard instrumentation, such as the 4.2-meter antenna, the data storage device, and the downlink communication system, contribute to the overall spaceborne VLBI instrumentation. This allows us to form a space radio telescope capable of co-observing with Earth-based radio telescopes in VLBI mode. In this space VLBI system, the length of the baseline extends up to approximately 380,000 km. This paper presents the LOVEX scientific objectives, architecture, instrumentation, pre-launch tests, in-flight verification and calibration, and the first in-flight detections of interferometric response (''fringes'') achieved through observations of the quasar AO 0235+164 and the Chang'E-6 orbital module, positioned at the Sun-Earth Lagrange point L2. These initial results demonstrate the successful performance of LOVEX, verifying its capability for both astronomical and spacecraft tracking observations at ultra-long VLBI baselines. △ Less",
      "url": "https://arxiv.org/abs/2507.16317"
    },
    {
      "title": "X-Intelligence 3.0: Training and Evaluating Reasoning LLM for Semiconductor Display",
      "abstract": "Large language models (LLMs) have recently achieved significant advances in reasoning and demonstrated their advantages in solving challenging problems. Yet, their effectiveness in the semiconductor display industry remains limited due to a lack of domain-specific training and expertise. To bridge this gap, we present X-Intelligence 3.0, the first high-performance reasoning model specifically developed for the semiconductor display industry. This model is designed to deliver expert-level understanding and reasoning for the industry's complex challenges. Leveraging a carefully curated industry knowledge base, the model undergoes supervised fine-tuning and reinforcement learning to enhance its reasoning and comprehension capabilities. To further accelerate development, we implemented an automated evaluation framework that simulates expert-level assessments. We also integrated a domain-specific retrieval-augmented generation (RAG) mechanism, resulting in notable performance gains on benchmark datasets. Despite its relatively compact size of 32 billion parameters, X-Intelligence 3.0 outperforms SOTA DeepSeek-R1-671B across multiple evaluations. This demonstrates its exceptional efficiency and establishes it as a powerful solution to the longstanding reasoning challenges faced by the semiconductor display industry. △ Less",
      "url": "https://arxiv.org/abs/2507.14430"
    },
    {
      "title": "A Disentangled Representation Learning Framework for Low-altitude Network Coverage Prediction",
      "abstract": "The expansion of the low-altitude economy has underscored the significance of Low-Altitude Network Coverage (LANC) prediction for designing aerial corridors. While accurate LANC forecasting hinges on the antenna beam patterns of Base Stations (BSs), these patterns are typically proprietary and not readily accessible. Operational parameters of BSs, which inherently contain beam information, offer an opportunity for data-driven low-altitude coverage prediction. However, collecting extensive low-altitude road test data is cost-prohibitive, often yielding only sparse samples per BS. This scarcity results in two primary challenges: imbalanced feature sampling due to limited variability in high-dimensional operational parameters against the backdrop of substantial changes in low-dimensional sampling locations, and diminished generalizability stemming from insufficient data samples. To overcome these obstacles, we introduce a dual strategy comprising expert knowledge-based feature compression and disentangled representation learning. The former reduces feature space complexity by leveraging communications expertise, while the latter enhances model generalizability through the integration of propagation models and distinct subnetworks that capture and aggregate the semantic representations of latent features. Experimental evaluation confirms the efficacy of our framework, yielding a 7% reduction in error compared to the best baseline algorithm. Real-network validations further attest to its reliability, achieving practical prediction accuracy with MAE errors at the 5dB level. △ Less",
      "url": "https://arxiv.org/abs/2507.14186"
    },
    {
      "title": "Apple Intelligence Foundation Language Models: Tech Report 2025",
      "abstract": "We introduce two multilingual, multimodal foundation language models that power Apple Intelligence features across Apple devices and services: i a 3B-parameter on-device model optimized for Apple silicon through architectural innovations such as KV-cache sharing and 2-bit quantization-aware training; and ii a scalable server model built on a novel Parallel-Track Mixture-of-Experts PT-MoE transformer that combines track parallelism, mixture-of-experts sparse computation, and interleaved global-local attention to deliver high quality with competitive cost on Apple's Private Cloud Compute platform. Both models are trained on large-scale multilingual and multimodal datasets sourced via responsible web crawling, licensed corpora, and high-quality synthetic data, then further refined with supervised fine-tuning and reinforcement learning on a new asynchronous platform. The resulting models support several additional languages while understanding images and executing tool calls. In public benchmarks and human evaluations, both the server model and the on-device model match or surpass comparably sized open baselines. A new Swift-centric Foundation Models framework exposes guided generation, constrained tool calling, and LoRA adapter fine-tuning, allowing developers to integrate these capabilities with a few lines of code. The latest advancements in Apple Intelligence models are grounded in our Responsible AI approach with safeguards like content filtering and locale-specific evaluation, as well as our commitment to protecting our users' privacy with innovations like Private Cloud Compute. △ Less",
      "url": "https://arxiv.org/abs/2507.13575"
    },
    {
      "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only",
      "abstract": "The advent of neural machine translation (NMT) has revolutionized cross-lingual communication, yet preserving stylistic nuances remains a significant challenge. While existing approaches often require parallel corpora for style preservation, we introduce Babel, a novel framework that enhances stylistic fidelity in NMT using only monolingual corpora. Babel employs two key components: (1) a style detector based on contextual embeddings that identifies stylistic disparities between source and target texts, and (2) a diffusion-based style applicator that rectifies stylistic inconsistencies while maintaining semantic integrity. Our framework integrates with existing NMT systems as a post-processing module, enabling style-aware translation without requiring architectural modifications or parallel stylistic data. Extensive experiments on five diverse domains (law, literature, scientific writing, medicine, and educational content) demonstrate Babel's effectiveness: it identifies stylistic inconsistencies with 88.21% precision and improves stylistic preservation by 150% while maintaining a high semantic similarity score of 0.92. Human evaluation confirms that translations refined by Babel better preserve source text style while maintaining fluency and adequacy. △ Less",
      "url": "https://arxiv.org/abs/2507.13395"
    },
    {
      "title": "Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models",
      "abstract": "Advancements in foundation models have made it possible to conduct applications in various downstream tasks. Especially, the new era has witnessed a remarkable capability to extend Large Language Models (LLMs) for tackling tasks of 3D scene understanding. Current methods rely heavily on 3D point clouds, but the 3D point cloud reconstruction of an indoor scene often results in information loss. Some textureless planes or repetitive patterns are prone to omission and manifest as voids within the reconstructed 3D point clouds. Besides, objects with complex structures tend to introduce distortion of details caused by misalignments between the captured images and the dense reconstructed point clouds. 2D multi-view images present visual consistency with 3D point clouds and provide more detailed representations of scene components, which can naturally compensate for these deficiencies. Based on these insights, we propose Argus, a novel 3D multimodal framework that leverages multi-view images for enhanced 3D scene understanding with LLMs. In general, Argus can be treated as a 3D Large Multimodal Foundation Model (3D-LMM) since it takes various modalities as input(text instructions, 2D multi-view images, and 3D point clouds) and expands the capability of LLMs to tackle 3D tasks. Argus involves fusing and integrating multi-view images and camera poses into view-as-scene features, which interact with the 3D features to create comprehensive and detailed 3D-aware scene embeddings. Our approach compensates for the information loss while reconstructing 3D point clouds and helps LLMs better understand the 3D world. Extensive experiments demonstrate that our method outperforms existing 3D-LMMs in various downstream tasks. △ Less",
      "url": "https://arxiv.org/abs/2507.12916"
    },
    {
      "title": "BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training",
      "abstract": "Large Language Models (LLMs) have become a cornerstone of modern AI, driving breakthroughs in natural language processing and expanding into multimodal jobs involving images, audio, and video. As with most computational software, it is important to distinguish between ordinary runtime performance and startup overhead. Prior research has focused on runtime performance: improving training efficiency and stability. This work focuses instead on the increasingly critical issue of startup overhead in training: the delay before training jobs begin execution. Startup overhead is particularly important in large, industrial-scale LLMs, where failures occur more frequently and multiple teams operate in iterative update-debug cycles. In one of our training clusters, more than 3.5% of GPU time is wasted due to startup overhead alone. In this work, we present the first in-depth characterization of LLM training startup overhead based on real production data. We analyze the components of startup cost, quantify its direct impact, and examine how it scales with job size. These insights motivate the design of Bootseer, a system-level optimization framework that addresses three primary startup bottlenecks: (a) container image loading, (b) runtime dependency installation, and (c) model checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and (c) striped HDFS-FUSE. Bootseer has been deployed in a production environment and evaluated on real LLM training workloads, demonstrating a 50% reduction in startup overhead. △ Less",
      "url": "https://arxiv.org/abs/2507.12619"
    },
    {
      "title": "Observation of the electromagnetic radiative decays of the \\boldmath{$Λ(1520)$} and \\boldmath{$Λ(1670)$} to \\boldmath{$γΣ^0$}",
      "abstract": "Using $(10087\\pm 44)\\times10^6$ $J/ψ$ events collected with the BESIII detector, we report the first observation of the electromagnetic radiative decays of the $Λ(1520)$ and $Λ(1670)$ to $γΣ^0$, with a statistical significance of $16.6σ$ and $23.5σ$, respectively. The ratio of the branching fractions $\\frac{\\mathcal{B}(Λ(1520)\\toγΛ)}{\\mathcal{B}(Λ(1520)\\toγΣ^0)}$ is determined to be $2.88\\pm0.27(\\text{stat.})\\pm0.21(\\text{syst.})$, which is in good agreement with flavor SU(3) symmetry. The branching fraction of $Λ(1520)\\toγΣ^0$ is measured to be $\\mathcal{B}(Λ(1520)\\toγΣ^0)=(2.95\\pm0.28(\\text{stat.})\\pm0.56(\\text{syst.}))\\times 10^{-3}$, corresponding to a partial width of $Γ(Λ(1520)\\toγΣ^0)=(47.2\\pm4.5(\\text{stat.})\\pm9.0(\\text{syst.}))$ keV, which is inconsistent with predictions from the relativized constituent quark model and the Algebraic model. Additionally, we observe a clear resonant structure in the $γΣ^0$ mass spectrum around 1.67 GeV/$c^2$, attributed to the $Λ(1670)$. The product branching fraction $\\mathcal{B}(J/ψ\\to\\barΛΛ(1670)+c.c.)\\times\\mathcal{B}(Λ(1670)\\toγΣ^0)$ is measured for the first time as $(5.39\\pm0.29(\\text{stat.})\\pm 0.44(\\text{syst.}))\\times 10^{-6}$. However, no corresponding structure is seen in the $γΛ$ mass spectrum, so an upper limit on the product branching fraction $\\mathcal{B}(J/ψ\\to\\barΛΛ(1670)+c.c.)\\times\\mathcal{B}(Λ(1670)\\toγΛ)$ is determined to be $5.97\\times10^{-7}$ at the 90\\% confidence level. △ Less",
      "url": "https://arxiv.org/abs/2507.11145"
    },
    {
      "title": "Search for the charged lepton flavor violating decay $ψ(3686)\\to e^{\\pm}μ^{\\mp}$",
      "abstract": "By analyzing $(2367.0\\pm11.1)\\times10^6$ $ψ(3686)$ events collected in $e^+e^-$ collisions at $\\sqrt{s}=3.686~\\rm GeV$ with the BESIII detector at the BEPCII collider, we report the first search for the charged lepton flavor violating decay $ψ(3686)\\to e^{\\pm}μ^{\\mp}$. No signal is found. An upper limit on the branching fraction $\\mathcal{B}(ψ(3686)\\to e^{\\pm}μ^{\\mp})$ is determined to be $1.4\\times10^{-8}$ at the 90\\% confidence level. △ Less",
      "url": "https://arxiv.org/abs/2507.10331"
    }
  ]
}