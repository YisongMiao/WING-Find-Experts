{
  "author": "Saif Mohammad",
  "results": [
    {
      "title": "Hybrid Quantum-Classical Generative Adversarial Networks with Transfer Learning",
      "abstract": "Generative Adversarial Networks (GANs) have demonstrated immense potential in synthesizing diverse and high-fidelity images. However, critical questions remain unanswered regarding how quantum principles might best enhance their representational and computational capacity. In this paper, we investigate hybrid quantum-classical GAN architectures supplemented by transfer learning to systematically examine whether incorporating Variational Quantum Circuits (VQCs) into the generator, the discriminator, or both improves performance over a fully classical baseline. Our findings indicate that fully hybrid models, which incorporate VQCs in both the generator and the discriminator, consistently produce images of higher visual quality and achieve more favorable quantitative metrics compared to their fully classical counterparts. In particular, VQCs in the generator accelerate early feature learning, whereas those in the discriminator, despite exhibiting slower initial convergence, ultimately facilitate more refined synthetic outputs. Moreover, the model sustains near-comparable performance even when the dataset size is drastically reduced, suggesting that transfer learning and quantum enhancements mitigate the problem of data scarcity. Overall, the results underscore that carefully integrating quantum computing with classical adversarial training and pretrained feature extraction can considerably enrich GAN-based image synthesis. These insights open avenues for future work on higher-resolution tasks, alternative quantum circuit designs, and experimentation with emerging quantum hardware. △ Less",
      "url": "https://arxiv.org/abs/2507.09706"
    },
    {
      "title": "Quantum Approximate Optimization Algorithm for Spatiotemporal Forecasting of HIV Clusters",
      "abstract": "HIV epidemiological data is increasingly complex, requiring advanced computation for accurate cluster detection and forecasting. We employed quantum-accelerated machine learning to analyze HIV prevalence at the ZIP-code level using AIDSVu and synthetic SDoH data for 2022. Our approach compared classical clustering (DBSCAN, HDBSCAN) with a quantum approximate optimization algorithm (QAOA), developed a hybrid quantum-classical neural network for HIV prevalence forecasting, and used quantum Bayesian networks to explore causal links between SDoH factors and HIV incidence. The QAOA-based method achieved 92% accuracy in cluster detection within 1.6 seconds, outperforming classical algorithms. Meanwhile, the hybrid quantum-classical neural network predicted HIV prevalence with 94% accuracy, surpassing a purely classical counterpart. Quantum Bayesian analysis identified housing instability as a key driver of HIV cluster emergence and expansion, with stigma exerting a geographically variable influence. These quantum-enhanced methods deliver greater precision and efficiency in HIV surveillance while illuminating critical causal pathways. This work can guide targeted interventions, optimize resource allocation for PrEP, and address structural inequities fueling HIV transmission. △ Less",
      "url": "https://arxiv.org/abs/2507.00848"
    },
    {
      "title": "Quantum Variational Transformer Model for Enhanced Cancer Classification",
      "abstract": "Accurate prediction of cancer type and primary tumor site is critical for effective diagnosis, personalized treatment, and improved outcomes. Traditional models struggle with the complexity of genomic and clinical data, but quantum computing offers enhanced computational capabilities. This study develops a hybrid quantum-classical transformer model, incorporating quantum attention mechanisms via variational quantum circuits (VQCs) to improve prediction accuracy. Using 30,000 anonymized cancer samples from the Genome Warehouse (GWH), data preprocessing included cleaning, encoding, and feature selection. Classical self-attention modules were replaced with quantum attention layers, with classical data encoded into quantum states via amplitude encoding. The model, trained using hybrid backpropagation and quantum gradient calculations, outperformed the classical transformer model, achieving 92.8% accuracy and an AUC of 0.96 compared to 87.5% accuracy and an AUC of 0.89. It also demonstrated 35% faster training and 25% fewer parameters, highlighting computational efficiency. These findings showcase the potential of quantum-enhanced transformers to advance biomedical data analysis, enabling more accurate diagnostics and personalized medicine. △ Less",
      "url": "https://arxiv.org/abs/2506.21641"
    },
    {
      "title": "Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links",
      "abstract": "Entanglement-based quantum key distribution (QKD) protocols, such as E91 and BBM92, offer strong information-theoretic security and are naturally suited for satellite-to-satellite QKD (SatQKD) links. However, implementing these protocols over long-distance inter-satellite free-space optical (FSO) channels poses critical physical-layer challenges that are not addressed in the existing literature. In particular, photon losses due to beam divergence, pointing errors, and background noise can severely degrade the key generation rate and quantum bit error rate (QBER), especially under narrow receiver field-of-view (FoV) constraints. This paper presents a comprehensive performance analysis of entanglement-based inter-satellite QKD, focusing on photon-level modeling and the impact of practical impairments. We develop analytical expressions for signal detection probabilities, background photon influence, multi-pair emissions, and QBER, incorporating key parameters such as link distance, transmitter tracking jitter, receiver misalignment, and photon pair generation rate. Simulation results reveal the nonlinear sensitivity of system performance to tracking error and FoV limitations, and highlight optimal parameter regimes that jointly maximize secret key rate while maintaining QBER below acceptable thresholds. The proposed model provides actionable design insights for reliable and efficient deployment of entanglement-based SatQKD systems. △ Less",
      "url": "https://arxiv.org/abs/2506.20798"
    },
    {
      "title": "A Unified Framework for UAV-Based Free-Space Quantum Links: Beam Shaping and Adaptive Field-of-View Control",
      "abstract": "This paper develops a comprehensive analytical framework for modeling and performance evaluation of unmanned aerial vehicles (UAVs)-to-ground quantum communication links, incorporating key physical impairments such as beam divergence, pointing errors at both transmitter and receiver, atmospheric attenuation, turbulence-induced fading, narrow field-of-view (FoV) filtering, and background photon noise. To overcome the limitations of conventional wide-beam assumptions, we introduce a grid-based approximation for photon capture probability that remains accurate under tightly focused beams. Analytical expressions are derived for the quantum key generation rate and quantum bit error rate (QBER), enabling fast and reliable system-level evaluation. Our results reveal that secure quantum key distribution (QKD) over UAV-based free-space optical (FSO) links requires beam waists below 10 cm and sub-milliradian tracking precision to achieve Mbps-level key rates and QBER below $10^{-3}$. Additionally, we highlight the critical role of receiver FoV in balancing background noise rejection and misalignment tolerance, and propose adaptive FoV tuning strategies under varying illumination and alignment conditions. The proposed framework provides a tractable and accurate tool for the design, optimization, and deployment of next-generation airborne quantum communication systems. △ Less",
      "url": "https://arxiv.org/abs/2506.20336"
    },
    {
      "title": "Words of Warmth: Trust and Sociability Norms for over 26k English Words",
      "abstract": "Social psychologists have shown that Warmth (W) and Competence (C) are the primary dimensions along which we assess other people and groups. These dimensions impact various aspects of our lives from social competence and emotion regulation to success in the work place and how we view the world. More recent work has started to explore how these dimensions develop, why they have developed, and what they constitute. Of particular note, is the finding that warmth has two distinct components: Trust (T) and Sociability (S). In this work, we introduce Words of Warmth, the first large-scale repository of manually derived word--warmth (as well as word--trust and word--sociability) associations for over 26k English words. We show that the associations are highly reliable. We use the lexicons to study the rate at which children acquire WCTS words with age. Finally, we show that the lexicon enables a wide variety of bias and stereotype research through case studies on various target entities. Words of Warmth is freely available at: http://saifmohammad.com/warmth.html △ Less",
      "url": "https://arxiv.org/abs/2506.03993"
    },
    {
      "title": "Beyond Specialization: Benchmarking LLMs for Transliteration of Indian Languages",
      "abstract": "Transliteration, the process of mapping text from one script to another, plays a crucial role in multilingual natural language processing, especially within linguistically diverse contexts such as India. Despite significant advancements through specialized models like IndicXlit, recent developments in large language models suggest a potential for general-purpose models to excel at this task without explicit task-specific training. The current work systematically evaluates the performance of prominent LLMs, including GPT-4o, GPT-4.5, GPT-4.1, Gemma-3-27B-it, and Mistral-Large against IndicXlit, a state-of-the-art transliteration model, across ten major Indian languages. Experiments utilized standard benchmarks, including Dakshina and Aksharantar datasets, with performance assessed via Top-1 Accuracy and Character Error Rate. Our findings reveal that while GPT family models generally outperform other LLMs and IndicXlit for most instances. Additionally, fine-tuning GPT-4o improves performance on specific languages notably. An extensive error analysis and robustness testing under noisy conditions further elucidate strengths of LLMs compared to specialized models, highlighting the efficacy of foundational models for a wide spectrum of specialized applications with minimal overhead. △ Less",
      "url": "https://arxiv.org/abs/2505.19851"
    },
    {
      "title": "Coherence, Transport, and Chaos in 1D Bose-Hubbard Model: Disorder vs. Stark Potential",
      "abstract": "We study quantum coherence and phase transitions in a finite-size one-dimensional Bose-Hubbard model using exact numerical diagonalization. The system is investigated under the competing effects of thermal fluctuations, a Stark potential, and a disorder term. We compute several observables, including the condensate fraction, superfluid fraction, visibility, number fluctuations, and the $\\ell_1$-norm of quantum coherence, to characterize the transition from the Mott insulator to the superfluid phase. In the standard Bose-Hubbard model, ground-state properties exhibit signatures of a quantum phase transition under open boundary conditions. While finite-size effects preclude an exact realization of the thermodynamic transition, our findings serve as indicators of the underlying quantum critical behavior of the disordered Bose-Hubbard model. At finite temperatures, this critical point shifts to a smooth crossover, reflecting the suppression of long-range coherence typical of larger systems. A nonzero Stark potential delays this crossover, promoting localization and the formation of non-superfluid condensates. In contrast, thermal fluctuations can induce unexpected coherence through fluctuation-driven tunneling. Disorder disrupts superfluidity but preserves local coherence, with thermal states exhibiting an enhanced $\\ell_1$-norm of coherence within the Bose glass regime. Our results highlight how disorder, tilt, and temperature jointly reshape the coherence landscape, and offer valuable insights for quantum simulation and the characterization of quantum phases in strongly correlated systems. Non-ergodic behavior is observed in the clean system where the mean gap ratio stays below Poisson and Gaussian orthogonal ensemble (GOE) values. With a Stark potential, level statistics shift from Poisson-like to near-GOE as tunneling increases, which indicates a crossover to semi-ergodic dynamics. △ Less",
      "url": "https://arxiv.org/abs/2505.19071"
    },
    {
      "title": "What Media Frames Reveal About Stance: A Dataset and Study about Memes in Climate Change Discourse",
      "abstract": "Media framing refers to the emphasis on specific aspects of perceived reality to shape how an issue is defined and understood. Its primary purpose is to shape public perceptions often in alignment with the authors' opinions and stances. However, the interaction between stance and media frame remains largely unexplored. In this work, we apply an interdisciplinary approach to conceptualize and computationally explore this interaction with internet memes on climate change. We curate CLIMATEMEMES, the first dataset of climate-change memes annotated with both stance and media frames, inspired by research in communication science. CLIMATEMEMES includes 1,184 memes sourced from 47 subreddits, enabling analysis of frame prominence over time and communities, and sheds light on the framing preferences of different stance holders. We propose two meme understanding tasks: stance detection and media frame detection. We evaluate LLaVA-NeXT and Molmo in various setups, and report the corresponding results on their LLM backbone. Human captions consistently enhance performance. Synthetic captions and human-corrected OCR also help occasionally. Our findings highlight that VLMs perform well on stance, but struggle on frames, where LLMs outperform VLMs. Finally, we analyze VLMs' limitations in handling nuanced frames and stance expressions on climate change internet memes. △ Less",
      "url": "https://arxiv.org/abs/2505.16592"
    },
    {
      "title": "The Language of Interoception: Examining Embodiment and Emotion Through a Corpus of Body Part Mentions",
      "abstract": "This paper is the first investigation of the connection between emotion, embodiment, and everyday language in a large sample of natural language data. We created corpora of body part mentions (BPMs) in online English text (blog posts and tweets). This includes a subset featuring human annotations for the emotions of the person whose body part is mentioned in the text. We show that BPMs are common in personal narratives and tweets (~5% to 10% of posts include BPMs) and that their usage patterns vary markedly by time and %geographic location. Using word-emotion association lexicons and our annotated data, we show that text containing BPMs tends to be more emotionally charged, even when the BPM is not explicitly used to describe a physical reaction to the emotion in the text. Finally, we discover a strong and statistically significant correlation between body-related language and a variety of poorer health outcomes. In sum, we argue that investigating the role of body-part related words in language can open up valuable avenues of future research at the intersection of NLP, the affective sciences, and the study of human wellbeing. △ Less",
      "url": "https://arxiv.org/abs/2505.16189"
    },
    {
      "title": "NRC VAD Lexicon v2: Norms for Valence, Arousal, and Dominance for over 55k English Terms",
      "abstract": "Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D) (also referred to in social cognition research as Competence (C)). These dimensions impact various aspects of our lives from social competence and emotion regulation to success in the work place and how we view the world. We present here the NRC VAD Lexicon v2, which has human ratings of valence, arousal, and dominance for more than 55,000 English words and phrases. Notably, it adds entries for $\\sim$25k additional words to v1.0. It also now includes for the first time entries for common multi-word phrases (~10k). We show that the associations are highly reliable. The lexicon enables a wide variety of research in psychology, NLP, public health, digital humanities, and social sciences. The NRC VAD Lexicon v2 is made freely available for research through our project webpage. △ Less",
      "url": "https://arxiv.org/abs/2503.23547"
    },
    {
      "title": "Zero-Shot LLMs in Human-in-the-Loop RL: Replacing Human Feedback for Reward Shaping",
      "abstract": "Reinforcement learning often faces challenges with reward misalignment, where agents optimize for given rewards but fail to exhibit the desired behaviors. This occurs when the reward function incentivizes proxy behaviors that diverge from the true objective. While human-in-the-loop (HIL) methods can help, they may exacerbate the problem, as humans are prone to biases that lead to inconsistent, subjective, or misaligned feedback, complicating the learning process. To address these issues, we propose two key contributions. First, we extend the use of zero-shot, off-the-shelf large language models (LLMs) for reward shaping beyond natural language processing (NLP) to continuous control tasks. By leveraging LLMs as direct feedback providers, we replace surrogate models trained on human feedback, which often suffer from the bias inherent in the feedback data it is trained on. Second, we introduce a hybrid framework (LLM-HFBF) that enables LLMs to identify and correct biases in human feedback while incorporating this feedback into the reward shaping process. The LLM-HFBF framework creates a more balanced and reliable system by addressing both the limitations of LLMs (e.g., lack of domain-specific knowledge) and human supervision (e.g., inherent biases). By enabling human feedback bias flagging and correction, our approach improves reinforcement learning performance and reduces reliance on potentially biased human guidance. Empirical experiments show that biased human feedback significantly reduces performance, with average episodic reward (AER) dropping from 28.472 in (unbiased approaches) to 7.039 (biased with conservative bias). In contrast, LLM-based approaches maintain a matching AER like unbiased feedback, even in custom edge case scenarios. △ Less",
      "url": "https://arxiv.org/abs/2503.22723"
    },
    {
      "title": "SemEval-2025 Task 11: Bridging the Gap in Text-Based Emotion Detection",
      "abstract": "We present our shared task on text-based emotion detection, covering more than 30 languages from seven distinct language families. These languages are predominantly low-resource and are spoken across various continents. The data instances are multi-labeled with six emotional classes, with additional datasets in 11 languages annotated for emotion intensity. Participants were asked to predict labels in three tracks: (a) multilabel emotion detection, (b) emotion intensity score detection, and (c) cross-lingual emotion detection. The task attracted over 700 participants. We received final submissions from more than 200 teams and 93 system description papers. We report baseline results, along with findings on the best-performing systems, the most common approaches, and the most effective methods across different tracks and languages. The datasets for this task are publicly available. The dataset is available at SemEval2025 Task 11 https://brighter-dataset.github.io △ Less",
      "url": "https://arxiv.org/abs/2503.07269"
    },
    {
      "title": "BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages",
      "abstract": "People worldwide use language in subtle and complex ways to express emotions. Although emotion recognition--an umbrella term for several NLP tasks--impacts various applications within NLP and beyond, most work in this area has focused on high-resource languages. This has led to significant disparities in research efforts and proposed solutions, particularly for under-resourced languages, which often lack high-quality annotated datasets. In this paper, we present BRIGHTER--a collection of multi-labeled, emotion-annotated datasets in 28 different languages and across several domains. BRIGHTER primarily covers low-resource languages from Africa, Asia, Eastern Europe, and Latin America, with instances labeled by fluent speakers. We highlight the challenges related to the data collection and annotation processes, and then report experimental results for monolingual and crosslingual multi-label emotion identification, as well as emotion intensity recognition. We analyse the variability in performance across languages and text domains, both with and without the use of LLMs, and show that the BRIGHTER datasets represent a meaningful step towards addressing the gap in text-based emotion recognition. △ Less",
      "url": "https://arxiv.org/abs/2502.11926"
    },
    {
      "title": "State-of-the-art AI-based Learning Approaches for Deepfake Generation and Detection, Analyzing Opportunities, Threading through Pros, Cons, and Future Prospects",
      "abstract": "The rapid advancement of deepfake technologies, specifically designed to create incredibly lifelike facial imagery and video content, has ignited a remarkable level of interest and curiosity across many fields, including forensic analysis, cybersecurity and the innovative creation of digital characters. By harnessing the latest breakthroughs in deep learning methods, such as Generative Adversarial Networks, Variational Autoencoders, Few-Shot Learning Strategies, and Transformers, the outcomes achieved in generating deepfakes have been nothing short of astounding and transformative. Also, the ongoing evolution of detection technologies is being developed to counteract the potential for misuse associated with deepfakes, effectively addressing critical concerns that range from political manipulation to the dissemination of fake news and the ever-growing issue of cyberbullying. This comprehensive review paper meticulously investigates the most recent developments in deepfake generation and detection, including around 400 publications, providing an in-depth analysis of the cutting-edge innovations shaping this rapidly evolving landscape. Starting with a thorough examination of systematic literature review methodologies, we embark on a journey that delves into the complex technical intricacies inherent in the various techniques used for deepfake generation, comprehensively addressing the challenges faced, potential solutions available, and the nuanced details surrounding manipulation formulations. Subsequently, the paper is dedicated to accurately benchmarking leading approaches against prominent datasets, offering thorough assessments of the contributions that have significantly impacted these vital domains. Ultimately, we engage in a thoughtful discussion of the existing challenges, paving the way for continuous advancements in this critical and ever-dynamic study area. △ Less",
      "url": "https://arxiv.org/abs/2501.01029"
    },
    {
      "title": "WorryWords: Norms of Anxiety Association for over 44k English Words",
      "abstract": "Anxiety, the anticipatory unease about a potential negative outcome, is a common and beneficial human emotion. However, there is still much that is not known, such as how anxiety relates to our body and how it manifests in language. This is especially pertinent given the increasing impact of anxiety-related disorders. In this work, we introduce WorryWords, the first large-scale repository of manually derived word--anxiety associations for over 44,450 English words. We show that the anxiety associations are highly reliable. We use WorryWords to study the relationship between anxiety and other emotion constructs, as well as the rate at which children acquire anxiety words with age. Finally, we show that using WorryWords alone, one can accurately track the change of anxiety in streams of text. The lexicon enables a wide variety of anxiety-related research in psychology, NLP, public health, and social sciences. WorryWords (and its translations to over 100 languages) is freely available. http://saifmohammad.com/worrywords.html △ Less",
      "url": "https://arxiv.org/abs/2411.03966"
    },
    {
      "title": "Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce",
      "abstract": "Language is a form of symbolic capital that affects people's lives in many ways (Bourdieu1977,1991). As a powerful means of communication, it reflects identities, cultures, traditions, and societies more broadly. Therefore, data in a given language should be regarded as more than just a collection of tokens. Rigorous data collection and labeling practices are essential for developing more human-centered and socially aware technologies. Although there has been growing interest in under-resourced languages within the NLP community, work in this area faces unique challenges, such as data scarcity and limited access to qualified annotators. In this paper, we collect feedback from individuals directly involved in and impacted by NLP artefacts for medium- and low-resource languages. We conduct both quantitative and qualitative analyses of their responses and highlight key issues related to: (1) data quality, including linguistic and cultural appropriateness; and (2) the ethics of common annotation practices, such as the misuse of participatory research. Based on these findings, we make several recommendations for creating high-quality language artefacts that reflect the cultural milieu of their speakers, while also respecting the dignity and labor of data workers. △ Less",
      "url": "https://arxiv.org/abs/2410.12691"
    },
    {
      "title": "Uni-polarized RIS Beamforming for Improving Connectivity of Multi-RIS-Assisted D2D Networks",
      "abstract": "This paper introduces a novel method to enhance the connectivity of multi-reconfigurable intelligent surface-assisted device-to-device networks, referred to as multi-RIS-assisted D2D networks, through a unique phase shift determination. The proposed method aims to optimize the power-domain array factor (PDAF), targeting specific azimuth angles of reliable user equipments (UEs) and enhancing network connectivity. We formulate an optimization problem that jointly optimizes RIS beamforming design, RIS-aided link selection, and RIS positioning. This problem is a mixed-integer non-binary programming. The optimization problem is divided into two sub-problems, which are solved individually and iteratively. The first sub-problem of RIS-aided link selection is solved using an efficient perturbation method while developing genetic algorithm (GA) to obtain RIS beamforming design. The GA optimizes the RIS phase shift to generate multiple RIS-aided narrowbeams that exhibit significant PDAF towards azimuth angles of interest while minimizing PDAF towards undesired azimuth angles. The second sub-problem of RIS positioning is addressed using the Adam optimizer. Numerical simulations verify the superiority of the proposed scheme in improving network connectivity compared to other schemes, including those utilizing distributed small RISs, each generating one RIS-aided link. △ Less",
      "url": "https://arxiv.org/abs/2410.04687"
    },
    {
      "title": "Transforming Scholarly Landscapes: Influence of Large Language Models on Academic Fields beyond Computer Science",
      "abstract": "Large Language Models (LLMs) have ushered in a transformative era in Natural Language Processing (NLP), reshaping research and extending NLP's influence to other fields of study. However, there is little to no work examining the degree to which LLMs influence other research fields. This work empirically and systematically examines the influence and use of LLMs in fields beyond NLP. We curate $106$ LLMs and analyze $\\sim$$148k$ papers citing LLMs to quantify their influence and reveal trends in their usage patterns. Our analysis reveals not only the increasing prevalence of LLMs in non-CS fields but also the disparities in their usage, with some fields utilizing them more frequently than others since 2018, notably Linguistics and Engineering together accounting for $\\sim$$45\\%$ of LLM citations. Our findings further indicate that most of these fields predominantly employ task-agnostic LLMs, proficient in zero or few-shot learning without requiring further fine-tuning, to address their domain-specific problems. This study sheds light on the cross-disciplinary impact of NLP through LLMs, providing a better understanding of the opportunities and challenges. △ Less",
      "url": "https://arxiv.org/abs/2409.19508"
    },
    {
      "title": "The Nature of NLP: Analyzing Contributions in NLP Papers",
      "abstract": "Natural Language Processing (NLP) is an established and dynamic field. Despite this, what constitutes NLP research remains debated. In this work, we address the question by quantitatively examining NLP research papers. We propose a taxonomy of research contributions and introduce NLPContributions, a dataset of nearly $2k$ NLP research paper abstracts, carefully annotated to identify scientific contributions and classify their types according to this taxonomy. We also introduce a novel task of automatically identifying contribution statements and classifying their types from research papers. We present experimental results for this task and apply our model to $\\sim$$29k$ NLP research papers to analyze their contributions, aiding in the understanding of the nature of NLP research. We show that NLP research has taken a winding path -- with the focus on language and human-centric studies being prominent in the 1970s and 80s, tapering off in the 1990s and 2000s, and starting to rise again since the late 2010s. Alongside this revival, we observe a steady rise in dataset and methodological contributions since the 1990s, such that today, on average, individual NLP papers contribute in more ways than ever before. Our dataset and analyses offer a powerful lens for tracing research trends and offer potential for generating informed, data-driven literature surveys. △ Less",
      "url": "https://arxiv.org/abs/2409.19505"
    },
    {
      "title": "Broad and Spectral-Efficient Beamforming for the Uni-polarized Reconfigurable Intelligent Surfaces",
      "abstract": "A reconfigurable intelligent surface (RIS) is composed of low-cost elements that manipulate the propagation environment from a transmitter by intelligently applying phase shifts to incoming signals before they are reflected. This paper explores a uni-polarized RIS with linear shape aimed at transmitting a common signal to multiple user equipments (UEs) spread across a wide angular region. To achieve uniform coverage, the uni-polarized RIS is designed to emit a broad and spectral-efficient beam featuring a spatially flat-like array factor, diverging from the conventional narrow beam approach. To achieve this objective, we start by deriving probabilistic lower and upper bounds for the average spectral efficiency (SE) delivered to the UEs. Leveraging the insights from the lower bound, we focus on optimizing the minimum value of the power domain array factor (PDAF) across a range of azimuth angles from \\(-\\fracπ{2}\\) to \\(\\fracπ{2}\\). We employ the continuous genetic algorithm (CGA) for this optimization task, aiming to improve the SE delivered to the UEs while also creating a wide beam. Extensive simulation experiments are carried out to assess the performance of the proposed code, focusing on key metrics such as the minimum and average values of the PDAF and the SE delivered to the UEs. Our findings demonstrate that the proposed code enhances the minimum SE delivered to the UEs while maintaining the desired attribute of a broad beam. This performance is notably superior to that of established codes, including the Barker, Frank, and Chu codes. △ Less",
      "url": "https://arxiv.org/abs/2407.15752"
    },
    {
      "title": "SemEval-2024 Task 1: Semantic Textual Relatedness for African and Asian Languages",
      "abstract": "We present the first shared task on Semantic Textual Relatedness (STR). While earlier shared tasks primarily focused on semantic similarity, we instead investigate the broader phenomenon of semantic relatedness across 14 languages: Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Punjabi, Spanish, and Telugu. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by the relatively limited availability of NLP resources. Each instance in the datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. Participating systems were asked to rank sentence pairs by their closeness in meaning (i.e., their degree of semantic relatedness) in the 14 languages in three main tracks: (a) supervised, (b) unsupervised, and (c) crosslingual. The task attracted 163 participants. We received 70 submissions in total (across all tasks) from 51 different teams, and 38 system description papers. We report on the best-performing systems as well as the most common and the most effective approaches for the three different tracks. △ Less",
      "url": "https://arxiv.org/abs/2403.18933"
    },
    {
      "title": "The Emotion Dynamics of Literary Novels",
      "abstract": "Stories are rich in the emotions they exhibit in their narratives and evoke in the readers. The emotional journeys of the various characters within a story are central to their appeal. Computational analysis of the emotions of novels, however, has rarely examined the variation in the emotional trajectories of the different characters within them, instead considering the entire novel to represent a single story arc. In this work, we use character dialogue to distinguish between the emotion arcs of the narration and the various characters. We analyze the emotion arcs of the various characters in a dataset of English literary novels using the framework of Utterance Emotion Dynamics. Our findings show that the narration and the dialogue largely express disparate emotions through the course of a novel, and that the commonalities or differences in the emotional arcs of stories are more accurately captured by those associated with individual characters. △ Less",
      "url": "https://arxiv.org/abs/2403.02474"
    },
    {
      "title": "Emotion Granularity from Text: An Aggregate-Level Indicator of Mental Health",
      "abstract": "We are united in how emotions are central to shaping our experiences; and yet, individuals differ greatly in how we each identify, categorize, and express emotions. In psychology, variation in the ability of individuals to differentiate between emotion concepts is called emotion granularity (determined through self-reports of one's emotions). High emotion granularity has been linked with better mental and physical health; whereas low emotion granularity has been linked with maladaptive emotion regulation strategies and poor health outcomes. In this work, we propose computational measures of emotion granularity derived from temporally-ordered speaker utterances in social media (in lieu of self-reports that suffer from various biases). We then investigate the effectiveness of such text-derived measures of emotion granularity in functioning as markers of various mental health conditions (MHCs). We establish baseline measures of emotion granularity derived from textual utterances, and show that, at an aggregate level, emotion granularities are significantly lower for people self-reporting as having an MHC than for the control population. This paves the way towards a better understanding of the MHCs, and specifically the role emotions play in our well-being. △ Less",
      "url": "https://arxiv.org/abs/2403.02281"
    },
    {
      "title": "Citation Amnesia: On The Recency Bias of NLP and Other Academic Fields",
      "abstract": "This study examines the tendency to cite older work across 20 fields of study over 43 years (1980--2023). We put NLP's propensity to cite older work in the context of these 20 other fields to analyze whether NLP shows similar temporal citation patterns to these other fields over time or whether differences can be observed. Our analysis, based on a dataset of approximately 240 million papers, reveals a broader scientific trend: many fields have markedly declined in citing older works (e.g., psychology, computer science). We term this decline a 'citation age recession', analogous to how economists define periods of reduced economic activity. The trend is strongest in NLP and ML research (-12.8% and -5.5% in citation age from previous peaks). Our results suggest that citing more recent works is not directly driven by the growth in publication rates (-3.4% across fields; -5.2% in humanities; -5.5% in formal sciences) -- even when controlling for an increase in the volume of papers. Our findings raise questions about the scientific community's engagement with past literature, particularly for NLP, and the potential consequences of neglecting older but relevant research. The data and a demo showcasing our results are publicly available. △ Less",
      "url": "https://arxiv.org/abs/2402.12046"
    },
    {
      "title": "SemRel2024: A Collection of Semantic Textual Relatedness Datasets for 13 Languages",
      "abstract": "Exploring and quantifying semantic relatedness is central to representing language and holds significant implications across various NLP tasks. While earlier NLP research primarily focused on semantic similarity, often within the English language context, we instead investigate the broader phenomenon of semantic relatedness. In this paper, we present \\textit{SemRel}, a new semantic relatedness dataset collection annotated by native speakers across 13 languages: \\textit{Afrikaans, Algerian Arabic, Amharic, English, Hausa, Hindi, Indonesian, Kinyarwanda, Marathi, Moroccan Arabic, Modern Standard Arabic, Spanish,} and \\textit{Telugu}. These languages originate from five distinct language families and are predominantly spoken in Africa and Asia -- regions characterised by a relatively limited availability of NLP resources. Each instance in the SemRel datasets is a sentence pair associated with a score that represents the degree of semantic textual relatedness between the two sentences. The scores are obtained using a comparative annotation framework. We describe the data collection and annotation processes, challenges when building the datasets, baseline experiments, and their impact and utility in NLP. △ Less",
      "url": "https://arxiv.org/abs/2402.08638"
    },
    {
      "title": "Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers",
      "abstract": "Research in psychopathology has shown that, at an aggregate level, the patterns of emotional change over time -- emotion dynamics -- are indicators of one's mental health. One's patterns of emotion change have traditionally been determined through self-reports of emotions; however, there are known issues with accuracy, bias, and ease of data collection. Recent approaches to determining emotion dynamics from one's everyday utterances addresses many of these concerns, but it is not yet known whether these measures of utterance emotion dynamics (UED) correlate with mental health diagnoses. Here, for the first time, we study the relationship between tweet emotion dynamics and mental health disorders. We find that each of the UED metrics studied varied by the user's self-disclosed diagnosis. For example: average valence was significantly higher (i.e., more positive text) in the control group compared to users with ADHD, MDD, and PTSD. Valence variability was significantly lower in the control group compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but not PPD. Rise and recovery rates of valence also exhibited significant differences from the control. This work provides important early evidence for how linguistic cues pertaining to emotion dynamics can play a crucial role as biosocial markers for mental illnesses and aid in the understanding, diagnosis, and management of mental health disorders. △ Less",
      "url": "https://arxiv.org/abs/2310.17369"
    },
    {
      "title": "We are Who We Cite: Bridges of Influence Between Natural Language Processing and Other Academic Fields",
      "abstract": "Natural Language Processing (NLP) is poised to substantially influence the world. However, significant progress comes hand-in-hand with substantial risks. Addressing them requires broad engagement with various fields of study. Yet, little empirical work examines the state of such engagement (past or current). In this paper, we quantify the degree of influence between 23 fields of study and NLP (on each other). We analyzed ~77k NLP papers, ~3.1m citations from NLP papers to other papers, and ~1.8m citations from other papers to NLP papers. We show that, unlike most fields, the cross-field engagement of NLP, measured by our proposed Citation Field Diversity Index (CFDI), has declined from 0.58 in 1980 to 0.31 in 2022 (an all-time low). In addition, we find that NLP has grown more insular -- citing increasingly more NLP papers and having fewer papers that act as bridges between fields. NLP citations are dominated by computer science; Less than 8% of NLP citations are to linguistics, and less than 3% are to math and psychology. These findings underscore NLP's urgent need to reflect on its engagement with various fields. △ Less",
      "url": "https://arxiv.org/abs/2310.14870"
    },
    {
      "title": "Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across Age",
      "abstract": "Emerging psychopathology studies are showing that patterns of changes in emotional state -- emotion dynamics -- are associated with overall well-being and mental health. More recently, there has been some work in tracking emotion dynamics through one's utterances, allowing for data to be collected on a larger scale across time and people. However, several questions about how emotion dynamics change with age, especially in children, and when determined through children's writing, remain unanswered. In this work, we use both a lexicon and a machine learning based approach to quantify characteristics of emotion dynamics determined from poems written by children of various ages. We show that both approaches point to similar trends: consistent increasing intensities for some emotions (e.g., anger, fear, joy, sadness, arousal, and dominance) with age and a consistent decreasing valence with age. We also find increasing emotional variability, rise rates (i.e., emotional reactivity), and recovery rates (i.e., emotional regulation) with age. These results act as a useful baselines for further research in how patterns of emotions expressed by children change with age, and their association with mental health. △ Less",
      "url": "https://arxiv.org/abs/2306.05387"
    },
    {
      "title": "Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis",
      "abstract": "Emotion arcs capture how an individual (or a population) feels over time. They are widely used in industry and research; however, there is little work on evaluating the automatically generated arcs. This is because of the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. By running experiments on 18 diverse datasets in 9 languages, we show that despite being markedly poor at instance level emotion classification, LexO methods are highly accurate at generating emotion arcs when aggregating information from hundreds of instances. We also show, through experiments on six indigenous African languages, as well as Arabic, and Spanish, that automatic translations of English emotion lexicons can be used to generate high-quality emotion arcs in less-resource languages. This opens up avenues for work on emotions in languages from around the world; which is crucial for commerce, public policy, and health research in service of speakers often left behind. Code and resources: https://github.com/dteodore/EmotionArcs △ Less",
      "url": "https://arxiv.org/abs/2306.02213"
    },
    {
      "title": "Forgotten Knowledge: Examining the Citational Amnesia in NLP",
      "abstract": "Citing papers is the primary method through which modern scientific writing discusses and builds on past work. Collectively, citing a diverse set of papers (in time and area of study) is an indicator of how widely the community is reading. Yet, there is little work looking at broad temporal patterns of citation. This work systematically and empirically examines: How far back in time do we tend to go to cite papers? How has that changed over time, and what factors correlate with this citational attention/amnesia? We chose NLP as our domain of interest and analyzed approximately 71.5K papers to show and quantify several key trends in citation. Notably, around 62% of cited papers are from the immediate five years prior to publication, whereas only about 17% are more than ten years old. Furthermore, we show that the median age and age diversity of cited papers were steadily increasing from 1990 to 2014, but since then, the trend has reversed, and current NLP papers have an all-time low temporal citation diversity. Finally, we show that unlike the 1990s, the highly cited papers in the last decade were also papers with the least citation diversity, likely contributing to the intense (and arguably harmful) recency focus. Code, data, and a demo are available on the project homepage. △ Less",
      "url": "https://arxiv.org/abs/2305.18554"
    },
    {
      "title": "A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?",
      "abstract": "Understanding the fundamental concepts and trends in a scientific field is crucial for keeping abreast of its continuous advancement. In this study, we propose a systematic framework for analyzing the evolution of research topics in a scientific field using causal discovery and inference techniques. We define three variables to encompass diverse facets of the evolution of research topics within NLP and utilize a causal discovery algorithm to unveil the causal connections among these variables using observational data. Subsequently, we leverage this structure to measure the intensity of these relationships. By conducting extensive experiments on the ACL Anthology corpus, we demonstrate that our framework effectively uncovers evolutionary trends and the underlying causes for a wide range of NLP research topics. Specifically, we show that tasks and methods are primary drivers of research in NLP, with datasets following, while metrics have minimal impact. △ Less",
      "url": "https://arxiv.org/abs/2305.12920"
    },
    {
      "title": "The Elephant in the Room: Analyzing the Presence of Big Tech in Natural Language Processing Research",
      "abstract": "Recent advances in deep learning methods for natural language processing (NLP) have created new business opportunities and made NLP research critical for industry development. As one of the big players in the field of NLP, together with governments and universities, it is important to track the influence of industry on research. In this study, we seek to quantify and characterize industry presence in the NLP community over time. Using a corpus with comprehensive metadata of 78,187 NLP publications and 701 resumes of NLP publication authors, we explore the industry presence in the field since the early 90s. We find that industry presence among NLP authors has been steady before a steep increase over the past five years (180% growth from 2017 to 2022). A few companies account for most of the publications and provide funding to academic researchers through grants and internships. Our study shows that the presence and impact of the industry on natural language processing research are significant and fast-growing. This work calls for increased transparency of industry influence in the field. △ Less",
      "url": "https://arxiv.org/abs/2305.02797"
    },
    {
      "title": "SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)",
      "abstract": "We present the first Africentric SemEval Shared task, Sentiment Analysis for African Languages (AfriSenti-SemEval) - The dataset is available at https://github.com/afrisenti-semeval/afrisent-semeval-2023. AfriSenti-SemEval is a sentiment classification challenge in 14 African languages: Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and Yorùbá (Muhammad et al., 2023), using data labeled with 3 sentiment classes. We present three subtasks: (1) Task A: monolingual classification, which received 44 submissions; (2) Task B: multilingual classification, which received 32 submissions; and (3) Task C: zero-shot classification, which received 34 submissions. The best performance for tasks A and B was achieved by NLNDE team with 71.31 and 75.06 weighted F1, respectively. UCAS-IIE-NLP achieved the best average score for task C with 58.15 weighted F1. We describe the various approaches adopted by the top 10 systems and their approaches. △ Less",
      "url": "https://arxiv.org/abs/2304.06845"
    },
    {
      "title": "Assessing Language Model Deployment with Risk Cards",
      "abstract": "This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by providing a generic framework for assessing the use of a given language model in a given scenario. Each RiskCard makes clear the routes for the risk to manifest harm, their placement in harm taxonomies, and example prompt-output pairs. While RiskCards are designed to be open-source, dynamic and participatory, we present a \"starter set\" of RiskCards taken from a broad literature survey, each of which details a concrete risk presentation. Language model RiskCards initiate a community knowledge base which permits the mapping of risks and harms to a specific model or its application scenario, ultimately contributing to a better, safer and shared understanding of the risk landscape. △ Less",
      "url": "https://arxiv.org/abs/2303.18190"
    },
    {
      "title": "AI Usage Cards: Responsibly Reporting AI-generated Content",
      "abstract": "Given AI systems like ChatGPT can generate content that is indistinguishable from human-made work, the responsible use of this technology is a growing concern. Although understanding the benefits and harms of using AI systems requires more time, their rapid and indiscriminate adoption in practice is a reality. Currently, we lack a common framework and language to define and report the responsible use of AI for content generation. Prior work proposed guidelines for using AI in specific scenarios (e.g., robotics or medicine) which are not transferable to conducting and reporting scientific research. Our work makes two contributions: First, we propose a three-dimensional model consisting of transparency, integrity, and accountability to define the responsible use of AI. Second, we introduce ``AI Usage Cards'', a standardized way to report the use of AI in scientific research. Our model and cards allow users to reflect on key principles of responsible AI usage. They also help the research community trace, compare, and question various forms of AI usage and support the development of accepted community norms. The proposed framework and reporting system aims to promote the ethical and responsible use of AI in scientific research and provide a standardized approach for reporting AI usage across different research fields. We also provide a free service to easily generate AI Usage Cards for scientific work via a questionnaire and export them in various machine-readable formats for inclusion in different work products at https://ai-cards.org. △ Less",
      "url": "https://arxiv.org/abs/2303.03886"
    },
    {
      "title": "AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages",
      "abstract": "Africa is home to over 2,000 languages from more than six language families and has the highest linguistic diversity among all continents. These include 75 languages with at least one million speakers each. Yet, there is little NLP research conducted on African languages. Crucial to enabling such research is the availability of high-quality annotated datasets. In this paper, we introduce AfriSenti, a sentiment analysis benchmark that contains a total of >110,000 tweets in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili, Tigrinya, Twi, Xitsonga, and Yorùbá) from four language families. The tweets were annotated by native speakers and used in the AfriSenti-SemEval shared task (The AfriSenti Shared Task had over 200 participants. See website at https://afrisenti-semeval.github.io). We describe the data collection methodology, annotation process, and the challenges we dealt with when curating each dataset. We further report baseline experiments conducted on the different datasets and discuss their usefulness. △ Less",
      "url": "https://arxiv.org/abs/2302.08956"
    },
    {
      "title": "Geographic Citation Gaps in NLP Research",
      "abstract": "In a fair world, people have equitable opportunities to education, to conduct scientific research, to publish, and to get credit for their work, regardless of where they live. However, it is common knowledge among researchers that a vast number of papers accepted at top NLP venues come from a handful of western countries and (lately) China; whereas, very few papers from Africa and South America get published. Similar disparities are also believed to exist for paper citation counts. In the spirit of \"what we do not measure, we cannot improve\", this work asks a series of questions on the relationship between geographical location and publication success (acceptance in top NLP venues and citation impact). We first created a dataset of 70,000 papers from the ACL Anthology, extracted their meta-information, and generated their citation network. We then show that not only are there substantial geographical disparities in paper acceptance and citation but also that these disparities persist even when controlling for a number of variables such as venue of publication and sub-field of NLP. Further, despite some steps taken by the NLP community to improve geographical diversity, we show that the disparity in publication metrics across locations is still on an increasing trend since the early 2000s. We release our code and dataset here: https://github.com/iamjanvijay/acl-cite-net △ Less",
      "url": "https://arxiv.org/abs/2210.14424"
    },
    {
      "title": "Frustratingly Easy Sentiment Analysis of Text Streams: Generating High-Quality Emotion Arcs Using Emotion Lexicons",
      "abstract": "Automatically generated emotion arcs -- that capture how an individual or a population feels over time -- are widely used in industry and research. However, there is little work on evaluating the generated arcs. This is in part due to the difficulty of establishing the true (gold) emotion arc. Our work, for the first time, systematically and quantitatively evaluates automatically generated emotion arcs. We also compare two common ways of generating emotion arcs: Machine-Learning (ML) models and Lexicon-Only (LexO) methods. Using a number of diverse datasets, we systematically study the relationship between the quality of an emotion lexicon and the quality of the emotion arc that can be generated with it. We also study the relationship between the quality of an instance-level emotion detection system (say from an ML model) and the quality of emotion arcs that can be generated with it. We show that despite being markedly poor at instance level, LexO methods are highly accurate at generating emotion arcs by aggregating information from hundreds of instances. This has wide-spread implications for commercial development, as well as research in psychology, public health, digital humanities, etc. that values simple interpretable methods and disprefers the need for domain-specific training data, programming expertise, and high-carbon-footprint models. △ Less",
      "url": "https://arxiv.org/abs/2210.07381"
    },
    {
      "title": "Best Practices in the Creation and Use of Emotion Lexicons",
      "abstract": "Words play a central role in how we express ourselves. Lexicons of word-emotion associations are widely used in research and real-world applications for sentiment analysis, tracking emotions associated with products and policies, studying health disorders, tracking emotional arcs of stories, and so on. However, inappropriate and incorrect use of these lexicons can lead to not just sub-optimal results, but also inferences that are directly harmful to people. This paper brings together ideas from Affective Computing and AI Ethics to present, some of the practical and ethical considerations involved in the creation and use of emotion lexicons -- best practices. The goal is to provide a comprehensive set of relevant considerations, so that readers (especially those new to work with emotions) can find relevant information in one place. We hope this work will facilitate more thoughtfulness when one is deciding on what emotions to work on, how to create an emotion lexicon, how to use an emotion lexicon, how to draw meaningful inferences, and how to judge success. △ Less",
      "url": "https://arxiv.org/abs/2210.07206"
    },
    {
      "title": "CS-Insights: A System for Analyzing Computer Science Research",
      "abstract": "This paper presents CS-Insights, an interactive web application to analyze computer science publications from DBLP through multiple perspectives. The dedicated interfaces allow its users to identify trends in research activity, productivity, accessibility, author's productivity, venues' statistics, topics of interest, and the impact of computer science research on other fields. CS-Insightsis publicly available, and its modular architecture can be easily adapted to domains other than computer science. △ Less",
      "url": "https://arxiv.org/abs/2210.06878"
    },
    {
      "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models",
      "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting. △ Less",
      "url": "https://arxiv.org/abs/2206.04615"
    },
    {
      "title": "D3: A Massive Dataset of Scholarly Metadata for Analyzing the State of Computer Science Research",
      "abstract": "DBLP is the largest open-access repository of scientific articles on computer science and provides metadata associated with publications, authors, and venues. We retrieved more than 6 million publications from DBLP and extracted pertinent metadata (e.g., abstracts, author affiliations, citations) from the publication texts to create the DBLP Discovery Dataset (D3). D3 can be used to identify trends in research activity, productivity, focus, bias, accessibility, and impact of computer science research. We present an initial analysis focused on the volume of computer science research (e.g., number of papers, authors, research activity), trends in topics of interest, and citation patterns. Our findings show that computer science is a growing research field (approx. 15% annually), with an active and collaborative researcher community. While papers in recent years present more bibliographical entries in comparison to previous decades, the average number of citations has been declining. Investigating papers' abstracts reveals that recent topic trends are clearly reflected in D3. Finally, we list further applications of D3 and pose supplemental research questions. The D3 dataset, our findings, and source code are publicly available for research purposes. △ Less",
      "url": "https://arxiv.org/abs/2204.13384"
    },
    {
      "title": "Tweet Emotion Dynamics: Emotion Word Usage in Tweets from US and Canada",
      "abstract": "Over the last decade, Twitter has emerged as one of the most influential forums for social, political, and health discourse. In this paper, we introduce a massive dataset of more than 45 million geo-located tweets posted between 2015 and 2021 from US and Canada (TUSC), especially curated for natural language analysis. We also introduce Tweet Emotion Dynamics (TED) -- metrics to capture patterns of emotions associated with tweets over time. We use TED and TUSC to explore the use of emotion-associated words across US and Canada; across 2019 (pre-pandemic), 2020 (the year the pandemic hit), and 2021 (the second year of the pandemic); and across individual tweeters. We show that Canadian tweets tend to have higher valence, lower arousal, and higher dominance than the US tweets. Further, we show that the COVID-19 pandemic had a marked impact on the emotional signature of tweets posted in 2020, when compared to the adjoining years. Finally, we determine metrics of TED for 170,000 tweeters to benchmark characteristics of TED metrics at an aggregate level. TUSC and the metrics for TED will enable a wide variety of research on studying how we use language to express ourselves, persuade, communicate, and influence, with particularly promising applications in public health, affective science, social science, and psychology. △ Less",
      "url": "https://arxiv.org/abs/2204.04862"
    },
    {
      "title": "Deep-Disaster: Unsupervised Disaster Detection and Localization Using Visual Data",
      "abstract": "Social media plays a significant role in sharing essential information, which helps humanitarian organizations in rescue operations during and after disaster incidents. However, developing an efficient method that can provide rapid analysis of social media images in the early hours of disasters is still largely an open problem, mainly due to the lack of suitable datasets and the sheer complexity of this task. In addition, supervised methods can not generalize well to novel disaster incidents. In this paper, inspired by the success of Knowledge Distillation (KD) methods, we propose an unsupervised deep neural network to detect and localize damages in social media images. Our proposed KD architecture is a feature-based distillation approach that comprises a pre-trained teacher and a smaller student network, with both networks having similar GAN architecture containing a generator and a discriminator. The student network is trained to emulate the behavior of the teacher on training input samples, which, in turn, contain images that do not include any damaged regions. Therefore, the student network only learns the distribution of no damage data and would have different behavior from the teacher network-facing damages. To detect damage, we utilize the difference between features generated by two networks using a defined score function that demonstrates the probability of damages occurring. Our experimental results on the benchmark dataset confirm that our approach outperforms state-of-the-art methods in detecting and localizing the damaged areas, especially for novel disaster types. △ Less",
      "url": "https://arxiv.org/abs/2202.00050"
    },
    {
      "title": "What Makes Sentences Semantically Related: A Textual Relatedness Dataset and Empirical Study",
      "abstract": "The degree of semantic relatedness of two units of language has long been considered fundamental to understanding meaning. Additionally, automatically determining relatedness has many applications such as question answering and summarization. However, prior NLP work has largely focused on semantic similarity, a subset of relatedness, because of a lack of relatedness datasets. In this paper, we introduce a dataset for Semantic Textual Relatedness, STR-2022, that has 5,500 English sentence pairs manually annotated using a comparative annotation framework, resulting in fine-grained scores. We show that human intuition regarding relatedness of sentence pairs is highly reliable, with a repeat annotation correlation of 0.84. We use the dataset to explore questions on what makes sentences semantically related. We also show the utility of STR-2022 for evaluating automatic methods of sentence representation and for various downstream NLP tasks. Our dataset, data statement, and annotation questionnaire can be found at: https://doi.org/10.5281/zenodo.7599667 △ Less",
      "url": "https://arxiv.org/abs/2110.04845"
    },
    {
      "title": "Ethics Sheet for Automatic Emotion Recognition and Sentiment Analysis",
      "abstract": "The importance and pervasiveness of emotions in our lives makes affective computing a tremendously important and vibrant line of work. Systems for automatic emotion recognition (AER) and sentiment analysis can be facilitators of enormous progress (e.g., in improving public health and commerce) but also enablers of great harm (e.g., for suppressing dissidents and manipulating voters). Thus, it is imperative that the affective computing community actively engage with the ethical ramifications of their creations. In this paper, I have synthesized and organized information from AI Ethics and Emotion Recognition literature to present fifty ethical considerations relevant to AER. Notably, the sheet fleshes out assumptions hidden in how AER is commonly framed, and in the choices often made regarding the data, method, and evaluation. Special attention is paid to the implications of AER on privacy and social groups. Along the way, key recommendations are made for responsible AER. The objective of the sheet is to facilitate and encourage more thoughtfulness on why to automate, how to automate, and how to judge success well before the building of AER systems. Additionally, the sheet acts as a useful introductory document on emotion recognition (complementing survey articles). △ Less",
      "url": "https://arxiv.org/abs/2109.08256"
    },
    {
      "title": "Ethics Sheets for AI Tasks",
      "abstract": "Several high-profile events, such as the mass testing of emotion recognition systems on vulnerable sub-populations and using question answering systems to make moral judgments, have highlighted how technology will often lead to more adverse outcomes for those that are already marginalized. At issue here are not just individual systems and datasets, but also the AI tasks themselves. In this position paper, I make a case for thinking about ethical considerations not just at the level of individual models and datasets, but also at the level of AI tasks. I will present a new form of such an effort, Ethics Sheets for AI Tasks, dedicated to fleshing out the assumptions and ethical considerations hidden in how a task is commonly framed and in the choices we make regarding the data, method, and evaluation. I will also present a template for ethics sheets with 50 ethical considerations, using the task of emotion recognition as a running example. Ethics sheets are a mechanism to engage with and document ethical considerations before building datasets and systems. Similar to survey articles, a small number of ethics sheets can serve numerous researchers and developers. △ Less",
      "url": "https://arxiv.org/abs/2107.01183"
    },
    {
      "title": "Ruddit: Norms of Offensiveness for English Reddit Comments",
      "abstract": "On social media platforms, hateful and offensive language negatively impact the mental well-being of users and the participation of people from diverse backgrounds. Automatic methods to detect offensive language have largely relied on datasets with categorical labels. However, comments can vary in their degree of offensiveness. We create the first dataset of English language Reddit comments that has fine-grained, real-valued scores between -1 (maximally supportive) and 1 (maximally offensive). The dataset was annotated using Best--Worst Scaling, a form of comparative annotation that has been shown to alleviate known biases of using rating scales. We show that the method produces highly reliable offensiveness scores. Finally, we evaluate the ability of widely-used neural models to predict offensiveness scores on this new dataset. △ Less",
      "url": "https://arxiv.org/abs/2106.05664"
    },
    {
      "title": "Emotion Dynamics in Movie Dialogues",
      "abstract": "Emotion dynamics is a framework for measuring how an individual's emotions change over time. It is a powerful tool for understanding how we behave and interact with the world. In this paper, we introduce a framework to track emotion dynamics through one's utterances. Specifically we introduce a number of utterance emotion dynamics (UED) metrics inspired by work in Psychology. We use this approach to trace emotional arcs of movie characters. We analyze thousands of such character arcs to test hypotheses that inform our broader understanding of stories. Notably, we show that there is a tendency for characters to use increasingly more negative words and become increasingly emotionally discordant with each other until about 90 percent of the narrative length. UED also has applications in behavior studies, social sciences, and public health. △ Less",
      "url": "https://arxiv.org/abs/2103.01345"
    }
  ]
}